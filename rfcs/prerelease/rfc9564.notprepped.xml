<?xml version="1.0" encoding="utf-8"?>
<?xml-model href="rfc7991bis.rnc"?>
<?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
<!DOCTYPE rfc [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">
]>
<rfc
  xmlns:xi="http://www.w3.org/2001/XInclude"
  category="info"
  number="9564"
  docName="draft-blanchet-flip-01"
  ipr="trust200902"
  obsoletes=""
  updates=""
  submissionType="independent"
  xml:lang="en"
  version="3"
  symRefs="true"
  sortRefs="true">
  <front>
    <title abbrev="FLIP">Faster Than Light Speed Protocol (FLIP)</title>
    <seriesInfo name="RFC" value="9564"/>
    <author fullname="Marc Blanchet" initials="M" surname="Blanchet">
        <organization>Viagenie</organization>
      <address>
        <email>marc.blanchet@viagenie.ca</email>  
      </address>
    </author>
    <date day="1" month="April" year="2024"/>

    <keyword>LLM</keyword>
    <keyword>IP</keyword>
    <abstract>
        <t>The recent advances in artificial intelligence (AI) such as large language models enable the design of the Faster than LIght speed Protocol (FLIP) for Internet. FLIP provides a way to avoid congestion, enhance security, and deliver faster packets on the Internet by using AI to predict future packets at the receiving peer before they arrive. This document describes the protocol, its various encapsulations, and some operational considerations.</t>
    </abstract>
  </front>
  <middle>
   <section>
      <name>Introduction</name>
      <t>ChatGPT was introduced to the public on 30 November 2022 <xref target="CHATGPT"/>. Since then, large language models (LLMs) have been used for a large variety of applications. It demonstrates the powerful ability to generate precise output based on the input and based on the appropriate training of the LLM. This protocol specification uses this ability to predict future packets before they arrive at the receiving peer, therefore achieving  faster-than-light-speed delivery, hence the protocol name: Faster than LIght speed Protocol (FLIP).</t>
      <t>Since FLIP can predict packets, frames, strings, or byte streams, it could be used at any layer of the IP protocol stack. Moreover, with proper training, FLIP can also predict future encrypted packets, as encryption is just strings of bytes. This specification shows FLIP as a Layer 2 shim as well as a transport shim layer. Since FLIP can be used at any layer, it is expected that additional specifications will be created, such as predicting HTTP requests and answers, email content, and more.</t>
      <t>Since communications in deep space are unfortunately limited to light speed, and given the very large distances between spacecrafts and Earth, the consequence is very long delays. By offering faster-than-light-speed delivery, FLIP is a key enabler and addition to deep-space IP networking <xref target="I-D.many-deepspace-ip-assessment"/>.</t>
    </section>
    <section>
      <name>Protocol Peer Preparation</name>
      <t>In order to successfully achieve faster than light speed, the peers of any protocol layer used by FLIP must prepare their side of the connection with the right model trained for the specific case. This document does not dictate any specific LLM, as the implementations may choose the one that best works for their use case and train them accordingly. As with any LLM, it is paramount to use a lot of training data, such as packet captures, in a variety of conditions to produce the best trained model. To avoid security, privacy, and legal issues, the specifics of which LLM is used, how it was trained, and what is the data set used, shall not be published nor disclosed in the protocol.</t>
      <t>As an example, an implementation may elect to collect a significant number of Packet Capture (PCAP) files from tcpdump wiretapping at various vantage points on the Internet. The fact that traffic may be encrypted is not an issue, since a well-trained LLM will be able to predict encrypted traffic as accurately as unencrypted traffic.</t>
    </section>
    <section>
        <name>FLIP Header</name>
        <t>Wherever FLIP is used (below IP, above IP or other transport, or at the application layer), a FLIP shim header is inserted.</t>
        <artwork type="ascii-art" name="FLIPheader.txt"><![CDATA[
   +----------+---------+----------------+----------------+
   |  Version | Command | Inner Protocol | Optional Data  |
   +----------+---------+----------------+----------------+
]]></artwork>
        <t>The header contains the following fields:</t>
            <dl>
                <dt>Version:</dt><dd>A field of variable and unspecified length that contains the SHA-256 hash of the model, used as the version, as described in <xref target="versioning"/>.</dd>
                <dt>Command:</dt><dd><t>The codepoint identifying the operation of this FLIP frame. Commands are described in <xref target="commands"/>. The initial list of valid FLIP commands is below.</t>

		<t>The maximum number size is infinite, given that artificial
        intelligence peers can support an infinite number of commands, by just
        updating their models without the need to update their protocol
        implementation.</t>
        <table>
          <thead>
            <tr><th>Command</th><th>Codepoint</th><th>Reference</th></tr>
          </thead>
          <tbody>
            <tr><td>model</td><td>0x01</td><td>RFC 9564</td></tr>
            <tr><td>data</td> <td>0x02</td><td>RFC 9564</td></tr>
          </tbody>
        </table>

</dd>
                <dt>Inner Protocol:</dt><dd> As the FLIP header is a shim header, the inner protocol is specified in this field. For example, for a FLIP shim header inserted between IP and TCP, the IP packet will contain the FLIP codepoint as the transport protocol. The FLIP inner protocol field will then contain the TCP codepoint that would otherwise be in the IP packet.</dd>
                <dt>Optional Data:</dt><dd> Some commands have additional data that are following the Command field.</dd>
            </dl>
        <t>The header length is variable and depends on which command is used. Given the use of artificial intelligence by implementations of this protocol, the actual length of the header, and the length of each of its fields, is not specified in the header. Instead, it is expected that the proper neural network on the receiver side will be able to find the actual header termination, thus saving many header bits.</t>

        <t>To properly signal the upper layer about the presence of the FLIP
        header, a specific codepoint is reserved at the layer below FLIP. 
        <xref target="IANA"/> lists the registrations for IP and transport codepoints for this use.</t>

    </section>
    <section anchor="commands">
        <name>Protocol Operation</name>
        <t>Prior to sending a first packet using FLIP, the sender and the receiver should be configured with the appropriate model trained as discussed before. It is left to the implementation to choose the right LLM and the right training data set.</t>
        <t>The following commands are defined:</t>
            <dl>
                <dt>Model:</dt><dd> (codepoint 0x01). This command provides a way for peers to send their model in-band of the FLIP protocol. The model itself is carried in the Optional Data field of the FLIP header. Prior to the actual model data, a MIME header is inserted with the proper media type. If the media type for the model does not exist, it should be registered in the IANA Media Type registry.</dd>
                <dt>Data:</dt><dd> (codepoint 0x02). This command tells the receiving peer that the data that follows can be predicted and therefore achieves faster-than-light-speed performance.</dd>
                </dl>
        <t>Sending the model in-band to the other peer is an operation that should be done rarely, as models may be large in size. Moreover, it actually discloses the model for any wiretapping adversary. Implementors may consider using a post-quantum cryptographic algorithm that is also immune to AI prediction, therefore a post-Quantum-AI cryptographic algorithm.</t>
    </section>
    <section anchor="versioning">
        <name>Versioning</name>
        <t>As described in <xref target="RFC6709"/>, most protocols should be designed to enable future enhancements, such as providing a way to signal a new version of the protocol. In the case of FLIP, trained models will always be enhanced by new training. A SHA-256 <xref target="RFC6234"/> hash of the trained model is used as a version number so each peer knows which FLIP version is being used. The SHA-256 hash is put in version field in the FLIP header as described previously. Given that new SHA-256 hashes are not sequential but fully random,  replay attacks of future predictions are prevented.</t>
    </section>
   <section>
     <name>Future Work</name>
     <t>This new protocol may revolutionize how we design Internet protocols and how we use the Internet. For example, it is envisioned that this protocol may be used for video streaming, augmented reality, virtual reality, and post-quantum cryptography to name a few. By predicting the future packets, all these protocols and applications can benefit the use of FLIP.</t>
     </section>
   <section anchor="IANA">
     <name>IANA Considerations</name>

     <t>For FLIP, codepoints could be registered in the following IANA registries.</t>
     <ul>
       <li>Protocol Numbers <xref target="IANA-PN"/>: 345, FLIP, Faster than LIght speed Protocol, RFC 9564</li>
       <li>
       Service Name and Transport Protocol Port Number Registry <xref target="IANA-SN"/>: FLIP, 68534, udp and tcp, RFC 9564</li>
     </ul>

   </section>
    <section>
        <name>Security Considerations</name>
        <t>The ability to predict future packets based on LLMs can be used by adversaries that are listening to the traffic via wiretapping. If they have access to the same model used by the destination peer, they could use it to predict the next packets and then initiate various attacks, including novel ones such as the "futureplay attack." Compared to the typical replay attack, this attack is where the adversary will predict future packets and then send them in advance to the destination. While it may not be obvious at this time, these novel attacks should be investigated before they become a problem. Therefore, further research in this field is suggested.</t>
        <t>The ability for a peer to predict future packets enhances the overall security of the Internet because adversaries will not be able to inject bad packets in a connection, as the destination will be able to compare the received bad packet with the calculated prediction and therefore will easily identify and deny any bad packets.</t>
    </section>
  </middle>
  <back>
<displayreference target="I-D.many-deepspace-ip-assessment" to="IP-DEEP-SPACE"/>
      <references>
        <name>Informative References</name>
        <reference anchor="CHATGPT" target="https://en.wikipedia.org/w/index.php?title=ChatGPT&amp;oldid=1214732037">
          <front>
            <title>ChatGPT</title>
            <author>
              <organization>Wikipedia</organization>
            </author>
	  <date day="20" month="March" year="2024"/>
          </front>
        </reference>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml3/reference.I-D.many-deepspace-ip-assessment.xml"/>
        <xi:include href="https://www.rfc-editor.org/refs/bibxml/reference.RFC.6234.xml"/>
        <xi:include href="https://www.rfc-editor.org/refs/bibxml/reference.RFC.6709.xml"/>
        <reference anchor="IANA-PN" target="https://www.iana.org/assignments/protocol-numbers/">
          <front>
            <title>Protocol Numbers</title>
            <author>
              <organization>IANA</organization>
            </author>
          </front>
        </reference>
        <reference anchor="IANA-SN" target="https://www.iana.org/assignments/service-names-port-numbers/">
          <front>
            <title>Service Name and Transport Protocol Port Number Registry</title>
            <author>
              <organization>IANA</organization>
            </author>
          </front>
        </reference>
      </references>
 
    <section anchor="Acknowledgements" numbered="false">
      <name>Acknowledgements</name>

      <t>Since this protocol specification is using artificial intelligence and large language models, it was deemed that dumb humans must not review this specification. Instead, the specification has been submitted to multiple LLM chat services and was enhanced by their comments and suggestions, hence acknowledged here. In fact, this specification may have been produced entirely by LLM chat services. Moreover, given the specifications being produced by the IETF relying upon human intelligence, using LLMs to produce specifications should be envisioned. Finally, given the difficulty to find experts for management positions such as in the IESG or IAB, the use of LLMs should be considered to replace those roles. Unfortunately, given privacy, security, and legal considerations, the LLM chat services used for this specification cannot be named here.</t>

    </section>
 </back>
</rfc>

