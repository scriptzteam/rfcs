<?xml version="1.0" encoding="UTF-8"?> 
<!DOCTYPE rfc [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">
]>

<rfc xmlns:xi="http://www.w3.org/2001/XInclude" ipr="trust200902" docName="draft-ietf-ippm-explicit-flow-measurements-07" number="9506" submissionType="IETF" category="info" consensus="true" tocDepth="6" tocInclude="true" sortRefs="true" symRefs="true" updates="" obsoletes="" xml:lang="en" version="3">

  <front>
    <title abbrev="Host-to-Network Flow Measurements">Explicit Host-to-Network Flow Measurements Techniques</title>
    <seriesInfo name="RFC" value="9506"/>
    <author initials="M." surname="Cociglio" fullname="Mauro Cociglio">
      <organization>Telecom Italia - TIM</organization>
      <address>
        <postal>
          <street>Via Reiss Romoli, 274</street>
          <city>Torino</city>
          <code>10148</code>
          <country>Italy</country>
        </postal>
        <email>mauro.cociglio@outlook.com</email>
      </address>
    </author>
    <author initials="A." surname="Ferrieux" fullname="Alexandre Ferrieux">
      <organization>Orange Labs</organization>
      <address>
        <email>alexandre.ferrieux@orange.com</email>
      </address>
    </author>
    <author initials="G." surname="Fioccola" fullname="Giuseppe Fioccola">
      <organization>Huawei Technologies</organization>
      <address>
        <postal>
          <street>Riesstrasse, 25</street>
          <city>Munich</city>
          <code>80992</code>
          <country>Germany</country>
        </postal>
        <email>giuseppe.fioccola@huawei.com</email>
      </address>
    </author>
    <author initials="I." surname="Lubashev" fullname="Igor Lubashev">
      <organization>Akamai Technologies</organization>
      <address>
        <email>ilubashe@akamai.com</email>
      </address>
    </author>
    <author initials="F." surname="Bulgarella" fullname="Fabio Bulgarella">
      <organization>Telecom Italia - TIM</organization>
      <address>
        <postal>
          <street>Via Reiss Romoli, 274</street>
          <city>Torino</city>
          <code>10148</code>
          <country>Italy</country>
        </postal>
        <email>fabio.bulgarella@guest.telecomitalia.it</email>
      </address>
    </author>
    <author initials="M." surname="Nilo" fullname="Massimo Nilo">
      <organization>Telecom Italia - TIM</organization>
      <address>
        <postal>
          <street>Via Reiss Romoli, 274</street>
          <city>Torino</city>
          <code>10148</code>
          <country>Italy</country>
        </postal>
        <email>massimo.nilo@telecomitalia.it</email>
      </address>
    </author>
    <author initials="I." surname="Hamchaoui" fullname="Isabelle Hamchaoui">
      <organization>Orange Labs</organization>
      <address>
        <email>isabelle.hamchaoui@orange.com</email>
      </address>
    </author>
    <author initials="R." surname="Sisto" fullname="Riccardo Sisto">
      <organization>Politecnico di Torino</organization>
      <address>
        <email>riccardo.sisto@polito.it</email>
      </address>
    </author>
    <date year="2023" month="October" />
    <area>tsv</area>
    <workgroup>ippm</workgroup>
    <keyword>Performance</keyword>
    <keyword>Monitoring</keyword>
    <keyword>Passive</keyword>
    <keyword>Hybrid</keyword>
    <keyword>Loss</keyword>
    <keyword>Delay</keyword>
    <keyword>Client</keyword>
    <keyword>Server</keyword>
    <keyword>On-path</keyword>
    <keyword>Observer</keyword>
    <keyword>Probe</keyword>
    <keyword>Alternate</keyword>
    <keyword>Marking</keyword>
    <keyword>Round</keyword>
    <keyword>Trip</keyword>
    <keyword>Latency</keyword>
    <keyword>Encrypted</keyword>
    <keyword>Protocol</keyword>
    <keyword>Bits</keyword>
    <abstract>

<t>This document describes protocol-independent methods called Explicit
Host-to-Network Flow Measurement Techniques that can be applicable to
transport-layer protocols between the client and server. These methods employ just a
few marking bits inside the header of each packet for performance measurements
and require the client and server to collaborate. Both endpoints cooperate by marking
packets and, possibly, mirroring the markings on the round-trip connection. The
techniques are especially valuable when applied to protocols that encrypt
transport headers since they enable loss and delay measurements by passive,
on-path network devices. This document describes several methods that can be
used separately or jointly depending of the availability of marking bits,
desired measurements, and properties of the protocol to which the methods are
applied.</t>
    </abstract>
  </front>
  <middle>
    <?line 123?>

<section anchor="introduction">
      <name>Introduction</name>
      <t>Packet loss and delay are hard and pervasive problems of day-to-day network
operation. Proactively detecting, measuring, and locating them is crucial to
maintaining high QoS and timely resolution of end-to-end throughput issues.</t>
      <t>Detecting and measuring packet loss and delay allows network operators to
independently confirm trouble reports and, ideally, be proactively notified of
developing problems on the network. Locating the cause of packet loss or
excessive delay is the first step to resolving problems and restoring QoS.</t>
      <t>Network operators wishing to perform quantitative measurement of
packet loss and delay have been heavily relying on information present in the
clear in transport-layer headers (e.g., TCP sequence and acknowledgment
numbers). By passively observing a network path at multiple points within one's
network, operators have been able to either quickly locate the source the
problem within their network or reliably attribute it to an upstream or
downstream network.</t>
      <t>With encrypted protocols, the transport-layer headers are encrypted and passive
packet loss and delay observations are not possible, as also noted in
<xref target="RFC9065"/>. Nevertheless, accurate measurement of packet loss and
delay experienced by encrypted transport-layer protocols is highly desired,
especially by network operators who own or control the infrastructure between the
client and server.</t>
      <t>The measurement of loss and delay experienced by connections using an encrypted
protocol cannot be based on a measurement of loss and delay experienced by
connections between the same or similar endpoints that use an unencrypted
protocol because different protocols may utilize the network differently and be
routed differently by the network. Therefore, it is necessary to directly
measure the packet loss and delay experienced by users of encrypted protocols.</t>
      <t>The Alternate-Marking method <xref target="RFC9341"/> defines a consolidated method to
perform packet loss, delay, and jitter measurements on live traffic. However,
as mentioned in <xref target="RFC9343"/>, <xref target="RFC9341"/> mainly applies to a network-layer-controlled 
domain managed with a Network Management System (NMS), where the Customer Premises Equipment (CPE)
or the Provider Edge (PE) routers are the starting or the ending nodes. <xref target="RFC9341"/> provides
measurement within a controlled domain in which the packets are
marked. Therefore, applying <xref target="RFC9341"/> to end-to-end transport-layer
connections is not easy because packet identification and marking by network
nodes is prevented when encrypted transport-layer headers (e.g., QUIC, TCP with
TLS) are being used.</t>
      <t>This document defines Explicit Host-to-Network Flow Measurement Techniques that
are specifically designed for encrypted transport protocols. According to the
definitions of <xref target="RFC7799"/>, these measurement methods can be classified as
Hybrid. They are to be embedded into a transport-layer protocol and are
explicitly intended for exposing delay and loss rate information to on-path
measurement devices. Unlike <xref target="RFC9341"/>, most of these methods require
collaborative endpoint nodes. Since these measurement techniques make performance
information directly visible to the path, they do not rely on an external NMS.</t>
      <t>The Explicit Host-to-Network Flow Measurement Techniques described in this
document are applicable to any transport-layer protocol connecting a client and a
server. In this document, the client and the server are also referred to as the
endpoints of the transport-layer protocol.</t>
      <t>The different methods described in this document can be used alone or in
combination. Each technique uses few bits and exposes a specific measurement.
It is assumed that the endpoints are collaborative in the sense of the
measurements, indeed both the client and server need to cooperate.</t>
      <t>Following the recommendation in <xref target="RFC8558"/> of making path signals explicit,
this document proposes adding some dedicated measurement bits to the clear
portion of the transport protocol headers. These bits can be added to an
unencrypted portion of a transport-layer header, e.g., UDP surplus space (see
<xref target="I-D.ietf-tsvwg-udp-options"/> and <xref target="I-D.herbert-udp-space-hdr"/>) or reserved bits in a QUIC v1 header, as
already done with the latency Spin bit (see 
<xref target="RFC9000" sectionFormat="of" section="17.4"/>). Note that this document does not recommend the use of any
specific bits, as these would need to be chosen by the specific protocol
implementations (see <xref target="applications"/>).</t>
      <t>The Spin bit, Delay bit, and loss bits explained in this document are inspired by
<xref target="RFC9341"/>, <xref target="RFC9312"/>, <xref target="I-D.trammell-quic-spin"/>, <xref target="I-D.trammell-tsvwg-spin"/>,
and <xref target="I-D.trammell-ippm-spin"/>.</t>
      <t>Additional details about the performance measurements for QUIC are described in
the paper <xref target="ANRW19-PM-QUIC"/>.</t>
    </section>
    <section anchor="latency-bits">
      <name>Latency Bits</name>
      <t>This section introduces bits that can be used for round-trip latency
measurements.  Whenever this section of the specification refers to packets, it
is referring only to packets with protocol headers that include the latency
bits.</t>
      <t>In <xref target="RFC9000" sectionFormat="comma" section="17.4"/> introduces an explicit, per-flow
transport-layer signal for hybrid measurement of RTT.  This signal consists of a
Spin bit that toggles once per RTT. <xref target="I-D.trammell-quic-spin" sectionFormat="of" section="4"/> discusses an
additional two-bit Valid Edge Counter (VEC) to compensate for loss and
reordering of the Spin bit and to increase fidelity of the signal in less than
ideal network conditions.</t>
      <t>This document introduces a standalone single-bit delay signal that can be used
by passive observers to measure the RTT of a network flow, avoiding the Spin bit
ambiguities that arise as soon as network conditions deteriorate.</t>
      <section anchor="spinbit">
        <name>Spin Bit</name>
        <t>This section is a small recap of the Spin bit working mechanism. For a
comprehensive explanation of the algorithm, see 
<xref target="RFC9312" sectionFormat="of" section="3.8.2"/>.</t>
        <t>The Spin bit is a signal generated by Alternate-Marking <xref target="RFC9341"/>, where the
size of the alternation changes with the flight size each RTT.</t>
        <t>The latency Spin bit is a single-bit signal that toggles once per RTT,
enabling latency monitoring of a connection-oriented communication
from intermediate observation points.</t>
        <t>A "Spin bit period" is a set of packets with the same Spin bit value sent during one
RTT time interval. A "Spin bit period value" is the value of the Spin bit shared by
all packets in a Spin bit period.</t>
        <t>The client and server maintain an internal per-connection spin value (i.e., 0 or
1) used to set the Spin bit on outgoing packets. Both endpoints initialize the
spin value to 0 when a new connection starts. Then:</t>
        <ul spacing="normal">
          <li>when the client receives a packet with the packet number larger than any
 number seen so far, it sets the connection spin value to the opposite value
 contained in the received packet; and</li>
          <li>when the server receives a packet with the packet number larger than any
 number seen so far, it sets the connection spin value to the same value
 contained in the received packet.</li>
        </ul>
        <t>The computed spin value is used by the endpoints for setting the Spin
bit on outgoing packets.  This mechanism allows the endpoints
to generate a square wave such that, by measuring the distance in time
between pairs of consecutive edges observed in the same direction, a
passive on-path observer can compute the round-trip network delay of that
network flow.</t>
        <t>Spin bit enables round-trip latency measurement by observing a single direction
of the traffic flow.</t>
        <t>Note that packet reordering can cause spurious edges that require heuristics to
correct. The Spin bit performance deteriorates as soon as network impairments
arise as explained in <xref target="delaybit"/>.</t>
      </section>
      <section anchor="delaybit">
        <name>Delay Bit</name>
        <t>The Delay bit has been designed to overcome accuracy limitations experienced by
the Spin bit under difficult network conditions:</t>
        <ul spacing="normal">
          <li>packet reordering leads to generation of spurious edges and errors in delay
estimation;</li>
          <li>loss of edges causes wrong estimation of Spin bit periods and therefore wrong RTT
measurements; and</li>
          <li>application-limited senders cause the Spin bit to measure the application
delays instead of network delays.</li>
        </ul>
        <t>Unlike the Spin bit, which is set in every packet transmitted on the network,
the Delay bit is set only once per round trip.</t>
        <t>When the Delay bit is used, a single packet with a marked bit (the Delay bit)
bounces between a client and a server during the entire connection lifetime.
This single packet is called the "delay sample".</t>
        <t>An observer placed at an intermediate point, observing a single direction of
traffic and tracking the delay sample and the relative timestamp, can measure the
round-trip delay of the connection.</t>
        <t>The delay sample lifetime comprises two phases: initialization and reflection.
The initialization is the generation of the delay sample, while the
reflection realizes the bounce behavior of this single packet between the two
endpoints.</t>
        <t>The next figure describes the elementary Delay bit mechanism.</t>
        <figure>
          <name>Delay Bit Mechanism</name>
          <artwork><![CDATA[
              +--------+   -   -   -   -   -   +--------+
              |        |      ----------->     |        |
              | Client |                       | Server |
              |        |     <-----------      |        |
              +--------+   -   -   -   -   -   +--------+

              (a) No traffic at beginning.

              +--------+   0   0   1   -   -   +--------+
              |        |      ----------->     |        |
              | Client |                       | Server |
              |        |     <-----------      |        |
              +--------+   -   -   -   -   -   +--------+

              (b) The Client starts sending data and sets
                  the first packet as the delay sample.

              +--------+   0   0   0   0   0   +--------+
              |        |      ----------->     |        |
              | Client |                       | Server |
              |        |     <-----------      |        |
              +--------+   -   -   -   1   0   +--------+

              (c) The Server starts sending data
                  and reflects the delay sample.

              +--------+   0   1   0   0   0   +--------+
              |        |      ----------->     |        |
              | Client |                       | Server |
              |        |     <-----------      |        |
              +--------+   0   0   0   0   0   +--------+

              (d) The Client reflects the delay sample.

              +--------+   0   0   0   0   0   +--------+
              |        |      ----------->     |        |
              | Client |                       | Server |
              |        |     <-----------      |        |
              +--------+   0   0   0   1   0   +--------+

              (e) The Server reflects the delay sample
                  and so on.
]]></artwork>
        </figure>
        <section anchor="generation-phase">
          <name>Generation Phase</name>
          <t>Only the client is actively involved in the Generation Phase. It maintains an
internal per-flow timestamp variable (<tt>ds_time</tt>) updated every time a delay
sample is transmitted.</t>
          <t>When connection starts, the client generates a new delay sample initializing the
Delay bit of the first outgoing packet to 1.  Then it updates the <tt>ds_time</tt>
variable with the timestamp of its transmission.</t>
          <t>The server initializes the Delay bit to 0 at the beginning of the connection,
and its only task during the connection is described in <xref target="reflection-phase"/>.</t>
          <t>In absence of network impairments, the delay sample should bounce between the client
and server continuously for the entire duration of the connection.  However, that is
highly unlikely for two reasons:</t>
          <ol spacing="normal" type="1"><li>The packet carrying the Delay bit might be lost.</li>
            <li>An endpoint could stop or delay sending packets because the application is
limiting the amount of traffic transmitted.</li>
          </ol>
          <t>To deal with these problems, the client generates a new delay sample if more
than a predetermined time (<tt>T_Max</tt>) has elapsed since the last delay sample
transmission (including reflections). Note that <tt>T_Max</tt> should be greater than
the max measurable RTT on the network. See <xref target="tmax-selection"/> for details.</t>
        </section>
        <section anchor="reflection-phase">
          <name>Reflection Phase</name>
          <t>Reflection is the process that enables the bouncing of the delay sample between
a client and a server.  The behavior of the two endpoints is almost the same.</t>
          <ul spacing="normal">
            <li>Server-side reflection: When a delay sample arrives, the server marks the
first packet in the opposite direction as the delay sample.</li>
            <li>Client-side reflection: When a delay sample arrives, the client marks the
first packet in the opposite direction as the delay sample. It also updates
the <tt>ds_time</tt> variable when the outgoing delay sample is actually forwarded.</li>
          </ul>
          <t>In both cases, if the outgoing delay sample is being transmitted with a delay
greater than a predetermined threshold after the reception of the incoming delay
sample (1 ms by default), the delay sample is not reflected, and the outgoing
Delay bit is kept at 0.</t>
          <t>By doing so, the algorithm can reject measurements that would overestimate the
delay due to lack of traffic at the endpoints.  Hence, the maximum estimation
error would amount to twice the threshold (e.g., 2 ms) per measurement.</t>
        </section>
        <section anchor="tmax-selection">
          <name><tt>T_Max</tt> Selection</name>
          <t>The internal <tt>ds_time</tt> variable allows a client to identify delay sample losses.
Considering that a lost delay sample is regenerated at the end of an explicit
time (<tt>T_Max</tt>) since the last generation, this same value can be used by an
observer to reject a measure and start a new one.</t>
          <t>In other words, if the difference in time between two delay samples is greater
or equal than <tt>T_Max</tt>, then these cannot be used to produce a delay measure.
Therefore, the value of <tt>T_Max</tt> must also be known to the on-path network probes.</t>
          <t>There are two alternatives to selecting the <tt>T_Max</tt> value so that both the client and
observers know it. The first one requires that <tt>T_Max</tt> is known a priori
(<tt>T_Max_p</tt>) and therefore set within the protocol specifications that implements
the marking mechanism (e.g., 1 second, which usually is greater than the max
expected RTT). The second alternative requires a dynamic mechanism able to
adapt the duration of the <tt>T_Max</tt> to the delay of the connection (<tt>T_Max_c</tt>).</t>
          <t>For instance, the client and observers could use the connection RTT as a basis for
calculating an effective <tt>T_Max</tt>. They should use a predetermined initial value
so that <tt>T_Max = T_Max_p</tt> (e.g., 1 second) and then, when a valid RTT is
measured, change <tt>T_Max</tt> accordingly so that <tt>T_Max = T_Max_c</tt>. In any case, the
selected <tt>T_Max</tt> should be large enough to absorb any possible variations in the
connection delay. This also helps to prevent the mechanism from failing when the
observer cannot recognize sudden changes in RTT exceeding <tt>T_Max</tt>.</t>
          <t><tt>T_Max_c</tt> could be computed as two times the measured <tt>RTT</tt> plus a fixed amount
of time (100 ms) to prevent low <tt>T_Max</tt> values in the case of very small RTTs.
The resulting formula is: <tt>T_Max_c = 2RTT + 100 ms</tt>. If <tt>T_Max_c</tt> is greater than
<tt>T_Max_p</tt>, then <tt>T_Max_c</tt> is forced to the <tt>T_Max_p</tt> value.
Note that the value of 100 ms is provided as an example, and it may be chosen
differently depending on the specific scenarios. For instance, an implementer may
consider using existing protocol-specific values if appropriate.</t>
          <t>Note that the observer's <tt>T_Max</tt> should always be less than or equal to the
client's <tt>T_Max</tt> to avoid considering as a valid measurement what is actually
the client's <tt>T_Max</tt>. To obtain this result, the client waits for two
consecutive incoming samples and computes the two related RTTs. Then it takes
the largest of them as the basis of the <tt>T_Max_c</tt> formula. At this point,
observers have already measured a valid RTT and then computed their <tt>T_Max_c</tt>.</t>
        </section>
        <section anchor="delay-measurement-using-delay-bit">
          <name>Delay Measurement Using the Delay Bit</name>
          <t>When the Delay bit is used, a passive observer can use delay samples directly
and avoid inherent ambiguities in the calculation of the RTT as can be seen in
Spin bit analysis.</t>
          <section anchor="rtt-measurement">
            <name>RTT Measurement</name>
            <t>The delay sample generation process ensures that only one packet marked with the
Delay bit set to 1 runs back and forth between two endpoints per round-trip
time.  To determine the RTT measurement of a flow, an on-path passive observer
computes the time difference between two delay samples observed in a single
direction.</t>
            <t>To ensure a valid measurement, the observer must verify that the distance in
time between the two samples taken into account is less than <tt>T_Max</tt>.</t>
            <figure>
              <name>Round-Trip Time (Both Directions)</name>
              <artwork><![CDATA[
           =======================|======================>
           = **********     -----Obs---->     ********** =
           = * Client *                       * Server * =
           = **********     <------------     ********** =
           <==============================================

                     (a) client-server RTT

           ==============================================>
           = **********     ------------>     ********** =
           = * Client *                       * Server * =
           = **********     <----Obs-----     ********** =
           <======================|=======================

                     (b) server-client RTT
]]></artwork>
            </figure>
          </section>
          <section anchor="half-rtt-measurement">
            <name>Half-RTT Measurement</name>
            <t>An observer that is able to observe both forward and return traffic directions
can use the delay samples to measure "upstream" and "downstream" RTT components,
also known as the half-RTT measurements. It does this by measuring the time
between a delay sample observed in one direction and the delay sample previously
observed in the opposite direction.</t>
            <t>As with RTT measurement, the observer must verify that the distance in time
between the two samples taken into account is less than <tt>T_Max</tt>.</t>
            <t>Note that upstream and downstream sections of paths between the endpoints and
the observer (i.e., observer-to-client vs. client-to-observer and
observer-to-server vs. server-to-observer) may have different delay
characteristics due to the difference in network congestion and other factors.</t>
            <figure>
              <name>Half Round-Trip Time (Both Directions)</name>
              <artwork><![CDATA[
           =======================>
           = **********     ------|----->     **********
           = * Client *          Obs          * Server *
           = **********     <-----|------     **********
           <=======================

                  (a) client-observer half-RTT

                                  =======================>
             **********     ------|----->     ********** =
             * Client *          Obs          * Server * =
             **********     <-----|------     ********** =
                                  <=======================

                  (b) observer-server half-RTT
]]></artwork>
            </figure>
          </section>
          <section anchor="intra-domain-rtt-measurement">
            <name>Intra-domain RTT Measurement</name>
            <t>Intra-domain RTT is the portion of the entire RTT used by a flow to traverse the
network of a provider.  To measure intra-domain RTT, two observers capable of
observing traffic in both directions must be employed simultaneously at the ingress
and egress of the network to be measured.  Intra-domain RTT is the difference
between the two computed upstream (or downstream) RTT components.</t>
            <figure>
              <name>Intra-domain Round-Trip Time (Client-Observer: Upstream)</name>
              <artwork><![CDATA[
        =========================================>
        = =====================>
        = = **********      ---|-->           ---|-->      **********
        = = * Client *         Obs               Obs       * Server *
        = = **********      <--|---           <--|---      **********
        = <=====================
        <=========================================

                 (a) client-observer RTT components (half-RTTs)

                               ==================>
            **********      ---|-->           ---|-->      **********
            * Client *         Obs               Obs       * Server *
            **********      <--|---           <--|---      **********
                               <==================

                 (b) the intra-domain RTT resulting from the
                     subtraction of the above RTT components
]]></artwork>
            </figure>
          </section>
        </section>
        <section anchor="observers-algorithm">
          <name>Observer's Algorithm</name>
          <t>An on-path observer maintains an internal per-flow variable to keep track of
the time at which the last delay sample has been observed. The flow characterization
should be part of the protocol.</t>
          <t>If the observer is unidirectional or in case of asymmetric routing, then upon detecting a
delay sample:</t>
          <ul spacing="normal">
            <li>if a delay sample was also detected previously in the same direction and the
distance in time between them is less than <tt>T_Max - K</tt>, then the two delay
samples can be used to calculate RTT measurement. <tt>K</tt> is a protection
threshold to absorb differences in <tt>T_Max</tt> computation and delay variations
between two consecutive delay samples (e.g., <tt>K = 10% T_Max</tt>).</li>
          </ul>
          <t>If the observer can observe both forward and return traffic flows, and it is
able to determine which direction contains the client and the server (e.g., by
observing the connection handshake), then upon detecting a delay sample:</t>
          <ul spacing="normal">
            <li>if a delay sample was also detected in the opposite direction and the distance
in time between them is less than <tt>T_Max - K</tt>, then the two delay samples can
be used to measure the observer-client half-RTT or the observer-server
half-RTT, according to the direction of the last delay sample observed.</li>
          </ul>
          <t>Note that the accuracy can be influenced by what the observer is capable of
observing. Additionally, the type of measurement differs, as described in the
previous sections.</t>
        </section>
        <section anchor="two-bits-delay-measurement-spin-bit-delay-bit">
          <name>Two Bits Delay Measurement: Spin Bit + Delay Bit</name>
          <t>The Spin and Delay bit algorithms work independently. If both marking methods are
used in the same connection, observers can choose the best measurement between
the two available:</t>
          <ul spacing="normal">
            <li>when a precise measurement can be produced using the Delay bit, observers
choose it; and</li>
            <li>when a Delay bit measurement is not available, observers choose the
approximate Spin bit one.</li>
          </ul>
        </section>
      </section>
    </section>
    <section anchor="loss-bits">
      <name>Loss Bits</name>
      <t>This section introduces bits that can be used for loss measurements.
Whenever this section of the specification refers to packets, it is
referring only to packets with protocol headers that include the loss
bits -- the only packets whose loss can be measured.</t>
      <dl indent="5">
        <dt>T:</dt> 
        <dd>The "round-Trip loss" bit is used in combination with the Spin bit to
measure round-trip loss. See <xref target="rtlossbit"/>.</dd>
        <dt>Q:</dt>
        <dd>The "sQuare" bit is used to measure upstream loss. See
<xref target="squarebit"/>.</dd>
        <dt>L:</dt>
        <dd>The "Loss Event" bit is used to measure end-to-end loss. See <xref target="lossbit"/>.</dd>
        <dt>R:</dt>
        <dd>The "Reflection square" bit is used in combination with the Q bit to
measure end-to-end loss. See <xref target="refsquarebit"/>.</dd>
      </dl>
      <t>Loss measurements enabled by T, Q, and L bits can be implemented by those loss
bits alone (T bit requires a working Spin bit). Two-bit combinations Q+L and Q+R
enable additional measurement opportunities discussed below.</t>
      <t>Each endpoint maintains appropriate counters independently and separately for
each identifiable flow (or each sub-flow for multipath connections).</t>
      <t>Since loss is reported independently for each flow, all bits (except for the L bit)
require a certain minimum number of packets to be exchanged per flow before any
signal can be measured. Therefore, loss measurements work best for flows that
transfer more than a minimal amount of data.</t>
      <section anchor="rtlossbit">
        <name>T Bit -- Round-Trip Loss Bit</name>
        <t>The round-Trip loss bit is used to mark a variable number of packets exchanged
twice between the endpoints realizing a two round-trip reflection. A passive
on-path observer, observing either direction, can count and compare the number
of marked packets seen during the two reflections, estimating the loss rate
experienced by the connection. The overall exchange comprises:</t>
        <ul spacing="normal">
          <li>the client selects and consequently sets the T bit to 1 in order to identify
a first train of packets;</li>
          <li>upon receiving each packet included in the first train, the server sets the T bit to 1 and reflects
to the client a respective second train of packets of the same size as the
first train received;</li>
          <li>upon receiving each packet included in the second train, the client sets the T bit to 1 and reflects
to the server a respective third train of packets of the same size as the
second train received; and</li>
          <li>upon receiving each packet included in the third train, the server sets the T bit to 1 and finally
reflects to the client a respective fourth train of packets of the same size
as the third train received.</li>
        </ul>
        <t>Packets belonging to the first round trip (first and second train)
represent the Generation Phase, while those belonging to the second
round trip (third and fourth train) represent the Reflection Phase.</t>
        <t>A passive on-path observer can count and compare the number of marked
packets seen during the two round trips (i.e., the first and third
or the second and the fourth trains of packets, depending on which
direction is observed) and estimate the loss rate experienced by the
connection. This process is repeated continuously to obtain more
measurements as long as the endpoints exchange traffic.  These
measurements can be called round-trip losses.</t>
        <t>Since the packet rates in two directions may be different, the number of marked
packets in the train is determined by the direction with the lowest packet rate.
See <xref target="tbit-details"/> for details on packet generation.</t>
        <section anchor="round-trip-loss">
          <name>Round-Trip Loss</name>
          <t>Since the measurements are performed on a portion of the traffic exchanged
between the client and the server, the observer calculates the end-to-end Round-Trip 
Packet Loss (RTPL) that, statistically, will correspond to the loss rate
experienced by the connection along the entire network path.</t>
          <figure>
            <name>Round-Trip Packet Loss (Both Directions)</name>
            <artwork><![CDATA[
           =======================|======================>
           = **********     -----Obs---->     ********** =
           = * Client *                       * Server * =
           = **********     <------------     ********** =
           <==============================================

                     (a) client-server RTPL

           ==============================================>
           = **********     ------------>     ********** =
           = * Client *                       * Server * =
           = **********     <----Obs-----     ********** =
           <======================|=======================

                     (b) server-client RTPL
]]></artwork>
          </figure>
          <t>This methodology also allows the half-RTPL measurement and
the Intra-domain RTPL measurement in a way similar to RTT measurement.</t>
          <figure>
            <name>Half Round-Trip Packet Loss (Both Directions)</name>
            <artwork><![CDATA[
           =======================>
           = **********     ------|----->     **********
           = * Client *          Obs          * Server *
           = **********     <-----|------     **********
           <=======================

                  (a) client-observer half-RTPL

                                  =======================>
             **********     ------|----->     ********** =
             * Client *          Obs          * Server * =
             **********     <-----|------     ********** =
                                  <=======================

                  (b) observer-server half-RTPL
]]></artwork>
          </figure>
          <figure>
            <name>Intra-domain Round-Trip Packet Loss (Observer-Server)</name>
            <artwork><![CDATA[
                           =========================================>
                                             =====================> =
        **********      ---|-->           ---|-->      ********** = =
        * Client *         Obs               Obs       * Server * = =
        **********      <--|---           <--|---      ********** = =
                                             <===================== =
                           <=========================================

             (a) observer-server RTPL components (half-RTPLs)

                           ==================>
        **********      ---|-->           ---|-->      **********
        * Client *         Obs               Obs       * Server *
        **********      <--|---           <--|---      **********
                           <==================

             (b) the intra-domain RTPL resulting from the
                 subtraction of the above RTPL components
]]></artwork>
          </figure>
        </section>
        <section anchor="tbit-details">
          <name>Setting the Round-Trip Loss Bit on Outgoing Packets</name>
          <t>The round-Trip loss signal requires a working Spin bit signal to separate trains
of marked packets (packets with T bit set to 1).  A "pause" of at least one
empty Spin bit period between each phase of the algorithm serves as such a
separator for the on-path observer. The connection between T bit and Spin bit
helps the observer correlate packet trains.</t>
          <t>The client maintains a "generation token" count that is set to zero at the
beginning of the session and is incremented every time a packet is received
(marked or unmarked). The client also maintains a "reflection counter" that
starts at zero at the beginning of the session.</t>
          <t>The client is in charge of launching trains of marked packets and does so
according to the algorithm:</t>
          <ol spacing="normal" type="1"><li>Generation Phase. The client starts generating marked packets for two
consecutive Spin bit periods. When the client transmits a packet and a
"generation token" is available, the client marks the packet and retires a
"generation token". If no token is available, the outgoing packet is
transmitted unmarked.  At the end of the first Spin bit period spent in
generation, the reflection counter is unlocked to start counting incoming
marked packets that will be reflected later.</li>
            <li>Pause Phase. When the generation is completed, the client pauses till it has
observed one entire Spin bit period with no marked packets.  That Spin bit
period is used by the observer as a separator between generated and
reflected packets.  During this marking pause, all the outgoing packets are
transmitted with T bit set to 0.  The reflection counter is still
incremented every time a marked packet arrives.</li>
            <li>Reflection Phase. The client starts transmitting marked packets,
decrementing the reflection counter for each transmitted marked packet until
the reflection counter has reached zero. The "generation token" method from the
Generation Phase is used during this phase as well.  At the end of the first
Spin bit period spent in reflection, the reflection counter is locked to avoid
incoming reflected packets incrementing it.</li>
            <li>Pause Phase 2. The Pause Phase is repeated after the Reflection Phase and
serves as a separator between the reflected packet train and a new packet
train.</li>
          </ol>
          <t>The generation token counter should be capped to limit the effects of a
subsequent sudden reduction in the other endpoint's packet rate that could
prevent that endpoint from reflecting collected packets. A
cap value of 1 is recommended.</t>
          <t>A server maintains a "marking counter" that starts at zero and is incremented
every time a marked packet arrives. When the server transmits a packet and the
"marking counter" is positive, the server marks the packet and decrements the
"marking counter". If the "marking counter" is zero, the outgoing packet is
transmitted unmarked.</t>
          <t>Note that a choice of 2 RTT (two Spin bit periods) for the Generation Phase is a
trade-off between the percentage of marked packets (i.e., the percentage of
traffic monitored) and the measurement delay. Using this value, the algorithm
produces a measurement approximately every 6 RTT (2 generations, ~2
reflections, 2 pauses), marking ~1/3 of packets exchanged in the slower
direction (see <xref target="tbit-losscov"/>). Choosing a Generation Phase of 1 RTT, we would
produce measurements every 4 RTT, monitoring ~1/4 of packets in the
slower direction.</t>
          <t>It is worth mentioning that problems can happen in some cases, especially if the
rate suddenly changes, but the mechanism described here
worked well with normal traffic conditions in the implementation.</t>
        </section>
        <section anchor="observers-logic-for-round-trip-loss-signal">
          <name>Observer's Logic for Round-Trip Loss Signal</name>
          <t>The on-path observer counts marked packets and separates different trains by
detecting Spin bit periods (at least one) with no marked packets.  The Round-Trip Packet Loss (RTPL) is the difference between the size of the Generation
train and the Reflection train.</t>
          <t>In the following example, packets are represented by two bits (first one
is the Spin bit, second one is the round-Trip loss bit):</t>
          <figure>
            <name>Round-Trip Loss Signal Example</name>
            <artwork><![CDATA[
        Generation          Pause           Reflection       Pause
   ____________________ ______________ ____________________ ________
  |                    |              |                    |        |
   01 01 00 01 11 10 11 00 00 10 10 10 01 00 01 01 10 11 10 00 00 10
]]></artwork>
          </figure>
          <t>Note that 5 marked packets have been generated, of which 4 have been reflected.</t>
        </section>
        <section anchor="tbit-losscov">
          <name>Loss Coverage and Signal Timing</name>
          <t>A cycle of the round-Trip loss signaling algorithm contains 2 RTTs of Generation
phase, 2 RTTs of Reflection Phase, and 2 Pause Phases at least 1 RTT in
duration each.  Hence, the loss signal is delayed by about 6 RTTs since the loss
events.</t>
          <t>The observer can only detect the loss of marked packets that occurs after its
initial observation of the Generation Phase and before its subsequent
observation of the Reflection Phase. Hence, if the loss occurs on the path that
sends packets at a lower rate (typically ACKs in such asymmetric scenarios),
2/6 (1/3) of the packets will be sampled for loss detection.</t>
          <t>If the loss occurs on the path that sends packets at a higher rate,
<tt>lowPacketRate/(3*highPacketRate)</tt> of the packets will be sampled for loss
detection. For protocols that use ACKs, the portion of packets sampled for loss
in the higher rate direction during unidirectional data transfer is
<tt>1/(3*packetsPerAck)</tt>, where the value of <tt>packetsPerAck</tt> can vary by protocol,
by implementation, and by network conditions.</t>
        </section>
      </section>
      <section anchor="squarebit">
        <name>Q Bit -- sQuare Bit</name>
        <t>The sQuare bit (Q bit) takes its name from the square wave generated by its
signal. This method is based on the Alternate-Marking method <xref target="RFC9341"/>, and
the Q bit represents the "packet color" that can be switched between 0 and 1 in order to mark consecutive blocks
of packets with different colors. This method does not require cooperation from
both endpoints.</t>
        <t><xref target="RFC9341"/> introduces two variations of the Alternate-Marking method depending
on whether the color is switched according to a fixed timer or after a fixed
number of packets. Cooperating and synchronized observers on either end of a network 
segment can use the fixed-timer method to measure packet loss on the
segment by comparing packet counters for the same packet blocks.  The time length of
the blocks can be chosen depending on the desired measurement frequency, but it
must be long enough to guarantee the proper operation with respect to clock errors
and network delay issues.</t>
        <t>The Q bit method described in this document chooses the color-switching method
based on a fixed number of packets for each block. This approach has the
advantage that it does not require cooperating or synchronized observers or
network elements. Each probe can measure packet loss autonomously without
relying on an external NMS. For the purpose of the
packet loss measurement, all blocks have the same number of packets, and it is
necessary to detect only the loss event and not to identify the exact block with
losses.</t>
        <t>Following the method based on fixed number of packets, the square wave signal is
generated by the switching of the Q bit: every outgoing packet contains the Q
bit value, which is initialized to 0 and inverted after sending N packets (a
sQuare Block or simply Q Block). Hence, Q Period is 2*N.</t>
        <t>Observation points can estimate upstream losses by watching a single direction
of the traffic flow and counting the number of packets in each observed Q Block,
as described in <xref target="upstreamloss"/>.</t>
        <section anchor="q-block-length-selection">
          <name>Q Block Length Selection</name>
          <t>The length of the block must be known to the on-path network probes.  There are
two alternatives to selecting the Q Block length. The first one requires that
the length is known a priori and therefore set within the protocol
specifications that implement the marking mechanism. The second requires the
sender to select it.</t>
          <t>In this latter scenario, the sender is expected to choose N (Q Block
length) based on the expected amount of loss and reordering on the
path.  The choice of N strikes a compromise -- the observation could
become too unreliable in case of packet reordering and/or severe loss
if N is too small, while short flows may not yield a useful upstream
loss measurement if N is too large (see <xref target="upstreamloss"/>).</t>
          <t>The value of N should be at least 64 and be a power of 2. This requirement allows
an observer to infer the Q Block length by observing one period of the square
signal. It also allows the observer to identify flows that set the loss bits to
arbitrary values (see <xref target="ossification"/>).</t>
          <t>If the sender does not have sufficient information to make an informed decision
about Q Block length, the sender should use N=64, since this value has been
extensively tried in large-scale field tests and yielded good results.
Alternatively, the sender may also choose a random power-of-2 N for each flow,
increasing the chances of using a Q Block length that gives the best signal for
some flows.</t>
          <t>The sender must keep the value of N constant for a given flow.</t>
        </section>
        <section anchor="upstreamloss">
          <name>Upstream Loss</name>
          <t>Blocks of N (Q Block length) consecutive packets are sent with the same
value of the Q bit, followed by another block of N packets with an
inverted value of the Q bit.  Hence, knowing the value of N, an
on-path observer can estimate the amount of upstream loss after
observing at least N packets.  The upstream loss rate (<tt>uloss</tt>) is one
minus the average number of packets in a block of packets with the
same Q value (<tt>p</tt>) divided by N (<tt>uloss=1-avg(p)/N</tt>).</t>
          <t>The observer needs to be able to tolerate packet reordering that can
blur the edges of the square signal, as explained in <xref target="endmarkingblock"/>.</t>
          <figure>
            <name>Upstream Loss</name>
            <artwork><![CDATA[
          =====================>
          **********     -----Obs---->     **********
          * Client *                       * Server *
          **********     <------------     **********

            (a) in client-server channel (uloss_up)

          **********     ------------>     **********
          * Client *                       * Server *
          **********     <----Obs-----     **********
                               <=====================

            (b) in server-client channel (uloss_down)
]]></artwork>
          </figure>
        </section>
        <section anchor="endmarkingblock">
          <name>Identifying Q Block Boundaries</name>
          <t>Packet reordering can produce spurious edges in the square signal. To address
this, the observer should look for packets with the current Q bit value up to X
packets past the first packet with a reverse Q bit value. The value of X, a
"Marking Block Threshold", should be less than <tt>N/2</tt>.</t>
          <t>The choice of X represents a trade-off between resiliency to reordering and
resiliency to loss. A very large Marking Block Threshold will be able to
reconstruct Q Blocks despite a significant amount of reordering, but it may
erroneously coalesce packets from multiple Q Blocks into fewer Q Blocks if loss
exceeds 50% for some Q Blocks.</t>
          <section anchor="Qburst">
            <name>Improved Resilience to Burst Losses</name>
            <t>Burst losses can affect the accuracy of Q measurements. Generally, burst losses can be
absorbed and correctly measured if smaller than the established Q Block
length. If the entire Q Block length of packets is lost in a burst, however, the
observer may be left completely unaware of the loss.</t>
            <t>To improve burst loss resilience, an observer may consider a received Q Block
larger than the selected Q Block length as an indication of a burst loss
event. The observer would then compute the loss as three times the Q Block length
minus the measured block length. By doing so, the observer can detect burst
losses of less than two blocks (e.g., less than 128 packets for a Q Block length
of 64 packets). A burst loss of two or more consecutive periods would still
remain unnoticed by the observer (or underestimated if a period longer than Q
Block length were formed).</t>
          </section>
        </section>
      </section>
      <section anchor="lossbit">
        <name>L Bit -- Loss Event Bit</name>
        <t>The Loss Event bit uses an Unreported Loss counter maintained by the protocol
that implements the marking mechanism. To use the Loss Event bit, the protocol
must allow the sender to identify lost packets. This is true of protocols such
as QUIC, partially true for TCP and Stream Control Transmission Protocol (SCTP) (losses of pure ACKs are not detected),
and is not true of protocols such as UDP and IPv4/IPv6.</t>
        <t>The Unreported Loss counter is initialized to 0, and the L bit of every outgoing
packet indicates whether the Unreported Loss counter is positive (L=1 if the
counter is positive, and L=0 otherwise).</t>
        <t>The value of the Unreported Loss counter is decremented every time a packet
with L=1 is sent.</t>
        <t>The value of the Unreported Loss counter is incremented for every packet that
the protocol declares lost, using whatever loss detection machinery the protocol
employs. If the protocol is able to rescind the loss determination later, a
positive Unreported Loss counter may be decremented due to the rescission.
In general, it should not become negative due to the rescission, but it can happen
in few cases.</t>
        <t>This loss signaling is similar to loss signaling in <xref target="RFC7713"/>, except that the Loss
Event bit is reporting the exact number of lost packets, whereas the signal mechanism
in <xref target="RFC7713"/> is reporting an approximate number of lost bytes.</t>
        <t>For protocols, such as TCP <xref target="RFC9293"/>, that allow network devices to change data
segmentation, it is possible that only a part of the packet is lost. In these
cases, the sender must increment the Unreported Loss counter by the fraction of the
packet data lost (so the Unreported Loss counter may become negative when a packet
with L=1 is sent after a partial packet has been lost).</t>
        <t>Observation points can estimate the end-to-end loss, as determined by the
upstream endpoint, by counting packets in this direction with the L bit equal to
1, as described in <xref target="endtoendloss"/>.</t>
        <section anchor="endtoendloss">
          <name>End-To-End Loss</name>
          <t>The Loss Event bit allows an observer to estimate the end-to-end loss rate by
counting packets with L bit values of 0 and 1 for a given flow. The end-to-end
loss ratio is the fraction of packets with L=1.</t>
          <t>The assumption here is that upstream loss affects packets with L=0 and L=1
equally. If some loss is caused by tail-drop in a network device, this may be a
simplification.  If the sender's congestion controller reduces the packet send
rate after loss, there may be a sufficient delay before sending packets with L=1
that they have a greater chance of arriving at the observer.</t>
          <section anchor="loss-profile">
            <name>Loss Profile Characterization</name>
            <t>The Loss Event bit allows an observer to characterize the loss profile, since the
distribution of observed packets with the L bit set to 1 roughly corresponds to the
distribution of packets lost between 1 RTT and 1 retransmission timeout (RTO) before (see
<xref target="loss-correlation"/>).  Hence, observing random single instances of the L bit set
to 1 indicates random single packet loss, while observing blocks of packets
with the L bit set to 1 indicates loss affecting entire blocks of packets.</t>
          </section>
        </section>
        <section anchor="lq-bits-loss-measurement-using-l-and-q-bits">
          <name>L+Q Bits -- Loss Measurement Using L and Q Bits</name>
          <t>Combining L and Q bits allows a passive observer watching a single direction of
traffic to accurately measure:</t>
          <dl>
            <dt>upstream loss:</dt>
            <dd>sender-to-observer loss (see <xref target="upstreamloss"/>)</dd>
            <dt>downstream loss:</dt>
            <dd>observer-to-receiver loss (see <xref target="downstreamloss"/>)</dd>
            <dt>end-to-end loss:</dt>
            <dd>sender-to-receiver loss on the observed path (see
<xref target="endtoendloss"/>) with loss profile characterization (see <xref target="loss-profile"/>)</dd>
          </dl>
          <section anchor="loss-correlation">
            <name>Correlating End-to-End and Upstream Loss</name>
            <t>Upstream loss is calculated by observing packets that did not suffer the
upstream loss (<xref target="upstreamloss"/>). End-to-end loss, however, is calculated by
observing subsequent packets after the sender's protocol detected the loss.
Hence, end-to-end loss is generally observed with a delay of between 1 RTT (loss
declared due to multiple duplicate acknowledgments) and 1 RTO (loss declared
due to a timeout) relative to the upstream loss.</t>
            <t>The flow RTT can sometimes be estimated by timing the protocol handshake
messages. This RTT estimate can be greatly improved by observing a dedicated
protocol mechanism for conveying RTT information, such as the Spin bit (see
<xref target="spinbit"/>) or Delay bit (see <xref target="delaybit"/>).</t>
            <t>Whenever the observer needs to perform a computation that uses both upstream and
end-to-end loss rate measurements, it should consider the upstream loss rate leading the
end-to-end loss rate by approximately 1 RTT. If the observer is unable to
estimate RTT of the flow, it should accumulate loss measurements over time
periods of at least 4 times the typical RTT for the observed flows.</t>
            <t>If the calculated upstream loss rate exceeds the end-to-end loss rate calculated
in <xref target="endtoendloss"/>, then either the Q Period is too short for the amount of
packet reordering or there is observer loss, described in <xref target="observerloss"/>. If
this happens, the observer should adjust the calculated upstream loss rate to
match end-to-end loss rate, unless the following applies.</t>
            <t>In case of a protocol, such as TCP or SCTP, that does not track losses of pure
ACK packets, observing a direction of traffic dominated by pure ACK packets
could result in measured upstream loss that is higher than measured end-to-end
loss if said pure ACK packets are lost upstream. Hence, if the measurement is
applied to such protocols, and the observer can confirm that pure ACK packets
dominate the observed traffic direction, the observer should adjust the
calculated end-to-end loss rate to match upstream loss rate.</t>
          </section>
          <section anchor="downstreamloss">
            <name>Downstream Loss</name>
            <t>Because downstream loss affects only those packets that did not suffer upstream
loss, the end-to-end loss rate (<tt>eloss</tt>) relates to the upstream loss rate
(<tt>uloss</tt>) and downstream loss rate (<tt>dloss</tt>) as <tt>(1-uloss)(1-dloss)=1-eloss</tt>.
Hence, <tt>dloss=(eloss-uloss)/(1-uloss)</tt>.</t>
          </section>
          <section anchor="observerloss">
            <name>Observer Loss</name>
            <t>A typical deployment of a passive observation system includes a network tap
device that mirrors network packets of interest to a device that performs
analysis and measurement on the mirrored packets. The observer loss is the loss
that occurs on the mirror path.</t>
            <t>Observer loss affects the upstream loss rate measurement since it causes the
observer to account for fewer packets in a block of identical Q bit values (see
<xref target="upstreamloss"/>). The end-to-end loss rate measurement, however, is unaffected
by the observer loss since it is a measurement of the fraction of packets with
the L bit value of 1, and the observer loss would affect all packets equally
(see <xref target="endtoendloss"/>).</t>
            <t>The need to adjust the upstream loss rate down to match the end-to-end loss rate as
described in <xref target="loss-correlation"/> is an indication of the observer loss, whose
magnitude is between the amount of such adjustment and the entirety of the
upstream loss measured in <xref target="upstreamloss"/>. Alternatively, a high apparent
upstream loss rate could be an indication of significant packet reordering,
possibly due to packets belonging to a single flow being multiplexed over
several upstream paths with different latency characteristics.</t>
          </section>
        </section>
      </section>
      <section anchor="refsquarebit">
        <name>R Bit -- Reflection Square Bit</name>
        <t>R bit requires a deployment alongside Q bit. Unlike the square signal for which
packets are transmitted in blocks of fixed size, the number of packets in
Reflection square blocks (also an Alternate-Marking signal) varies
according to these rules:</t>
        <ul spacing="normal">
          <li>when the transmission of a new block starts, its size is set equal
to the size of the last Q Block whose reception has been completed; and</li>
          <li>if the reception of at least one further Q Block is completed before transmission of the block is terminated, the size of the block
is updated to be the average size of the further received Q Blocks.</li>
        </ul>
        <t>The Reflection square value is initialized to 0 and is applied to the R bit of
every outgoing packet.  The Reflection square value is toggled for the first
time when the completion of a Q Block is detected in the incoming square signal
(produced by the other endpoint using the Q bit). The number of packets
detected within this first Q Block (<tt>p</tt>), is used to generate a reflection
square signal that toggles every <tt>M=p</tt> packets (at first). This new signal
produces blocks of M packets (marked using the R bit) and each of them is
called "Reflection Block" (Reflection Block).</t>
        <t>The M value is then updated every time a completed Q Block in the
incoming square signal is received, following this formula:
<tt>M=round(avg(p))</tt>.</t>
        <t>The parameter <tt>avg(p)</tt>, the average number of packets in a marking
period, is computed based on all the Q Blocks received since the
beginning of the current Reflection Block.</t>
        <t>The transmission of a Reflection Block is considered complete (and the signal toggled)
when the number of packets transmitted in that block is at least the latest
computed M value.</t>
        <t>To ensure a proper computation of the M value, endpoints implementing the R bit
must identify the boundaries of incoming Q Blocks. The same approach described
in <xref target="endmarkingblock"/> should be used.</t>
        <t>By looking at the R bit, unidirectional observation points have an indication of
loss experienced by the entire unobserved channel plus the loss on the path
from the sender to them.</t>
        <t>Since the Q Block is sent in one direction, and the corresponding reflected R
Block is sent in the opposite direction, the reflected R signal is transmitted
with the packet rate of the slowest direction. Namely, if the observed direction
is the slowest, there can be multiple Q Blocks transmitted in the unobserved
direction before a complete Reflection Block is transmitted in the observed direction. If
the unobserved direction is the slowest, the observed direction can be sending R
Blocks of the same size repeatedly before it can update the signal to account
for a newly completed Q Block.</t>
        <section anchor="enhancement-of-r-block-length-computation">
          <name>Enhancement of Reflection Block Length Computation</name>
          <t>The use of the rounding function used in the M computation introduces errors
that can be minimized by storing the rounding applied each time M is computed
and using it during the computation of the M value in the following Reflection Block.</t>
          <t>This can be achieved by introducing the new <tt>r_avg</tt> parameter in the computation of
M.  The new formula is <tt>Mr=avg(p)+r_avg; M=round(Mr); r_avg=Mr-M</tt> where the
initial value of <tt>r_avg</tt> is equal to 0.</t>
        </section>
        <section anchor="improved-resilience-to-packet-reordering">
          <name>Improved Resilience to Packet Reordering</name>
          <t>When a protocol implementing the marking mechanism is able to detect when
packets are received out of order, it can improve resilience to packet
reordering beyond what is possible by using methods described in
<xref target="endmarkingblock"/>.</t>
          <t>This can be achieved by updating the size of the current Reflection Block while it is
being transmitted.  The Reflection Block size is then updated every time an
incoming reordered packet of the previous Q Block is detected.  This can be
done if and only if the transmission of the current Reflection Block is in
progress and no packets of the following Q Block have been received.</t>
          <section anchor="Rburst">
            <name>Improved Resilience to Burst Losses</name>
            <t>Burst losses can affect the accuracy of R measurements similar to how they affect
accuracy of Q measurements. Therefore, recommendations in <xref target="Qburst"/> apply
equally to improving burst loss resilience for R measurements.</t>
          </section>
        </section>
        <section anchor="rq-bits-loss-measurement-using-r-and-q-bits">
          <name>R+Q Bits -- Loss Measurement Using R and Q Bits</name>
          <t>Since both sQuare and Reflection square bits are toggled at most every N packets
(except for the first transition of the R bit as explained before), an on-path
observer can count the number of packets of each marking block and, knowing the
value of N, can estimate the amount of loss experienced by the connection.  An
observer can calculate different measurements depending on whether it is able to
observe a single direction of the traffic or both directions.</t>
        <dl newline="true" spacing="normal">
          <dt>Single directional observer:</dt>
          <dd><dl newline="false" spacing="normal">
            <dt>upstream loss in the observed direction:</dt>
            <dd>the loss between the sender and the
observation point (see <xref target="upstreamloss"/>)</dd>
            <dt>"three-quarters" connection loss:</dt>
            <dd>the loss between the receiver and
the sender in the unobserved direction plus the loss between the
sender and the observation point in the observed direction</dd>
            <dt>end-to-end loss in the unobserved direction:</dt>
            <dd>the loss between the
receiver and the sender in the opposite direction</dd>
          </dl></dd>
          <dt>Two directions observer (same metrics seen previously applied to both
direction, plus):</dt>
          <dd><dl>
            <dt>client-observer half round-trip loss:</dt> 
            <dd>the loss between the client
and the observation point in both directions</dd>
            <dt>observer-server half round-trip loss:</dt> 
            <dd>the loss between the
observation point and the server in both directions</dd>
            <dt>downstream loss:</dt>
            <dd>the loss between the observation point and the
receiver (applicable to both directions)</dd>
          </dl></dd></dl>
          <section anchor="tqloss">
            <name>Three-Quarters Connection Loss</name>
            <t>Except for the very first block in which there is nothing to reflect
(a complete Q Block has not been yet received), packets are
continuously R-bit marked into alternate blocks of size lower or equal
than N.  By knowing the value of N, an on-path observer can estimate the
amount of loss that has occurred in the whole opposite channel plus the loss
from the sender up to it in the observation channel. As for the
previous metric, the <tt>three-quarters</tt> connection loss rate (<tt>tqloss</tt>) is
one minus the average number of packets in a block of packets with the
same R value (<tt>t</tt>) divided by <tt>N</tt> (<tt>tqloss=1-avg(t)/N</tt>).</t>
            <figure>
              <name>Three-Quarters Connection Loss</name>
              <artwork><![CDATA[
        =======================>
        = **********     -----Obs---->     **********
        = * Client *                       * Server *
        = **********     <------------     **********
        <============================================

            (a) in client-server channel (tqloss_up)

          ============================================>
          **********     ------------>     ********** =
          * Client *                       * Server * =
          **********     <----Obs-----     ********** =
                               <=======================

            (b) in server-client channel (tqloss_down)
]]></artwork>
            </figure>
            <t>The following metrics derive from this last metric and the upstream
loss produced by the Q bit.</t>
          </section>
          <section anchor="end-to-end-loss-in-the-opposite-direction">
            <name>End-To-End Loss in the Opposite Direction</name>
            <t>End-to-end loss in the unobserved direction (<tt>eloss_unobserved</tt>) relates to the
"three-quarters" connection loss (<tt>tqloss</tt>) and upstream loss in the observed
direction (<tt>uloss</tt>) as <tt>(1-eloss_unobserved)(1-uloss)=1-tqloss</tt>.  Hence,
<tt>eloss_unobserved=(tqloss-uloss)/(1-uloss)</tt>.</t>
            <figure>
              <name>End-To-End Loss in the Opposite Direction</name>
              <artwork><![CDATA[
          **********     -----Obs---->     **********
          * Client *                       * Server *
          **********     <------------     **********
          <==========================================

            (a) in client-server channel (eloss_down)

          ==========================================>
          **********     ------------>     **********
          * Client *                       * Server *
          **********     <----Obs-----     **********

            (b) in server-client channel (eloss_up)
]]></artwork>
            </figure>
          </section>
          <section anchor="half-round-trip-loss">
            <name>Half Round-Trip Loss</name>
            <t>If the observer is able to observe both directions of traffic, it is able to
calculate two "half round-trip" loss measurements -- loss from the observer to
the receiver (in a given direction) and then back to the observer in the
opposite direction.  For both directions, "half round-trip" loss (<tt>hrtloss</tt>)
relates to "three-quarters" connection loss (<tt>tqloss_opposite</tt>) measured in the
opposite direction and the upstream loss (<tt>uloss</tt>) measured in the given
direction as <tt>(1-uloss)(1-hrtloss)=1-tqloss_opposite</tt>.  Hence,
<tt>hrtloss=(tqloss_opposite-uloss)/(1-uloss)</tt>.</t>
            <figure>
              <name>Half Round-Trip Loss (Both Directions)</name>
              <artwork><![CDATA[
        =======================>
        = **********     ------|----->     **********
        = * Client *          Obs          * Server *
        = **********     <-----|------     **********
        <=======================

      (a) client-observer half round-trip loss (hrtloss_co)

                               =======================>
          **********     ------|----->     ********** =
          * Client *          Obs          * Server * =
          **********     <-----|------     ********** =
                               <=======================

      (b) observer-server half round-trip loss (hrtloss_os)
]]></artwork>
            </figure>
          </section>
          <section anchor="downstream-loss">
            <name>Downstream Loss</name>
            <t>If the observer is able to observe both directions of traffic, it is able to
calculate two downstream loss measurements using either end-to-end loss and
upstream loss, similar to the calculation in <xref target="downstreamloss"/>, or "half
round-trip" loss and upstream loss in the opposite direction.</t>
            <t>For the latter, <tt>dloss=(hrtloss-uloss_opposite)/(1-uloss_opposite)</tt>.</t>
            <figure>
              <name>Downstream Loss</name>
              <artwork><![CDATA[
                               =====================>
          **********     ------|----->     **********
          * Client *          Obs          * Server *
          **********     <-----|------     **********

             (a) in client-server channel (dloss_up)

          **********     ------|----->     **********
          * Client *          Obs          * Server *
          **********     <-----|------     **********
          <=====================

             (b) in server-client channel (dloss_down)
]]></artwork>
            </figure>
          </section>
        </section>
      </section>
      <section anchor="e-bit-ecn-echo-event-bit">
        <name>E Bit -- ECN-Echo Event Bit</name>
        <t>While the primary focus of this document is on exposing packet loss and
delay, modern networks can report congestion before they are forced to
drop packets, as described in <xref target="RFC3168"/>.  When transport protocols keep
ECN-Echo feedback under encryption, this signal cannot be observed by
the network operators.  When tasked with diagnosing network
performance problems, knowledge of a congestion downstream of an
observation point can be instrumental.</t>
        <t>If downstream congestion information is desired, this information can be
signaled with an additional bit.</t>
        <dl>
          <dt>E:</dt>
          <dd>The "ECN-Echo Event" bit is set to 0 or 1 according to the Unreported ECN-Echo 
counter, as explained below in <xref target="ecnbit"/>.</dd>
        </dl>
        <section anchor="ecnbit">
          <name>Setting the ECN-Echo Event Bit on Outgoing Packets</name>
          <t>The Unreported ECN-Echo counter operates identically to Unreported Loss counter
(<xref target="lossbit"/>), except it counts packets delivered by the network with Congestion Experienced (CE)
markings, according to the ECN-Echo feedback from the receiver.</t>
          <t>This ECN-Echo signaling is similar to ECN signaling in <xref target="RFC7713"/>. The ECN-Echo
mechanism in QUIC provides the number of packets received with CE marks. For
protocols like TCP, the method described in <xref target="RFC7786"/> can be employed. As
stated in <xref target="RFC7786"/>, such feedback can be further improved using a method
described in <xref target="I-D.ietf-tcpm-accurate-ecn"/>.</t>
        </section>
        <section anchor="ech-usage">
          <name>Using E Bit for Passive ECN-Reported Congestion Measurement</name>
          <t>A network observer can count packets with the CE codepoint and determine the
upstream CE-marking rate directly.</t>
          <t>Observation points can also estimate ECN-reported end-to-end congestion by
counting packets in this direction with an E bit equal to 1.</t>
          <t>The upstream CE-marking rate and end-to-end ECN-reported congestion can provide
information about the downstream CE-marking rate. The presence of E bits along with L
bits, however, can somewhat confound precise estimates of upstream and
downstream CE markings if the flow contains packets that are not
ECN capable.</t>
        </section>
        <section anchor="multiple-e-bits">
          <name>Multiple E Bits</name>
          <t>Some protocols, such as QUIC, support separate ECN-Echo counters. For example,
<xref target="RFC9000" sectionFormat="of" section="13.4.1"/> describes separate counters for ECT(0),
ECT(1), and ECN-CE. To better support such protocols, multiple E bits can be
used, one per a corresponding ECN-Echo counter.</t>
        </section>
      </section>
    </section>
    <section anchor="summary-of-delay-and-loss-marking-methods">
      <name>Summary of Delay and Loss Marking Methods</name>
      <t>This section summarizes the marking methods described in this document, which
proposes a toolkit of techniques that can be used separately, partly, or all
together depending on the need.</t>
      <t>For the delay measurement, it is possible to use the Spin bit and/or the Delay
bit. A unidirectional or bidirectional observer can be used.</t>
        <table anchor="fig_summary_D">
          <name>Delay Comparison</name>
	  <thead>
	    <tr>
		<th rowspan="2" colspan="1">Method</th>
		<th rowspan="2" colspan="1" align="center"># of bits</th>
		<th rowspan="1" colspan="2" align="center">Available Delay Metrics</th>
		<th rowspan="2" colspan="1" align="center">Impairments Resiliency</th>
		<th rowspan="2" colspan="1" align="center"># of meas.</th>
	    </tr>
            <tr>
                <th align="center">UniDir Observer</th>
                <th align="center">BiDir Observer</th>
	    </tr>
	  </thead>
	  <tbody>
	    <tr>
		<td>S: Spin Bit</td>
		<td align="center">1</td>
		<td align="center">RTT</td>
		<td align="center">x2, Half RTT</td>
		<td align="center">low</td>
		<td align="center">very high</td>
	    </tr>
	    <tr>
		<td>D: Delay Bit</td>
		<td align="center">1</td>
		<td align="center">RTT</td>
		<td align="center">x2, Half RTT</td>
		<td align="center">high</td>
		<td align="center">medium</td>
	    </tr>
	    <tr>
		<td>SD: Spin Bit &amp; Delay Bit *</td>
		<td align="center">2</td>
		<td align="center">RTT</td>
		<td align="center">x2, Half RTT</td>
		<td align="center">high</td>
		<td align="center">very high</td>
	    </tr>
	  </tbody>
        </table>
      <dl indent="6">
         <dt>x2</dt>
         <dd>Same metric for both directions</dd>
         <dt>*</dt>
         <dd>Both bits work independently; an observer could use less accurate Spin bit measurements when Delay bit ones are unavailable.</dd>
      </dl>
      <t>For the Loss measurement, each row in <xref target="fig_summary_L"/>
represents a loss-marking method. For each method, the table specifies
the number of bits required in the header, the available metrics using
a unidirectional or bidirectional observer, applicable protocols,
measurement fidelity, and delay.</t>
      <table anchor="fig_summary_L">
        <name>Loss Comparison</name>
	<thead>
	  <tr>
                <th rowspan="2" colspan="1">Method</th>
		<th rowspan="2" colspan="1" align="center">Bits</th>
		<th rowspan="1" colspan="2" align="center">Available Loss Metrics</th>
		<th rowspan="2" colspan="1" align="center">Prto</th>
		<th rowspan="1" colspan="2" align="center">Measurement Aspects</th>
	  </tr>
          <tr>
                <th align="center">UniDir Observer</th>
                <th align="center">BiDir Observer</th>
                <th align="center">Fidelity</th>
                <th align="center">Delay</th>
          </tr>
	</thead>
	<tbody>
	  <tr>
		<td>T: Round-Trip Loss Bit</td>
		<td align="center">$1</td>
		<td align="center">RT</td>
		<td align="center">x2, Half RT</td>
		<td align="center">*</td>
		<td>Rate by sampling 1/3 to 1/(3*ppa) of pkts over 2 RTT</td>
		<td>~6 RTT</td>
	  </tr>
 	  <tr>
		<td>Q: sQuare Bit</td>
		<td align="center">1</td>
		<td align="center">Upstream</td>
		<td align="center">x2</td>
		<td align="center">*</td>
		<td>Rate over N pkts (e.g., 64)</td>
		<td>N pkts (e.g., 64)</td>
	  </tr>
	  <tr>
		<td>L: Loss Event Bit</td>
		<td align="center">1</td>
		<td align="center">E2E</td>
		<td align="center">x2</td>
		<td align="center">#</td>
		<td>Loss shape (and rate)</td>
		<td>Min: RTT, Max: RTO</td>
	  </tr>
	  <tr>
		<td rowspan="3" colspan="1">QL: sQuare + Loss Ev. Bits</td>
		<td rowspan="3" colspan="1" align="center">2</td>
		<td rowspan="1" colspan="1" align="center">Upstream</td>
		<td rowspan="1" colspan="1" align="center">x2</td>
		<td rowspan="1" colspan="1" align="center">#</td>
		<td rowspan="1" colspan="1">see Q</td>
		<td rowspan="1" colspan="1">see Q</td>
	  </tr>
	  <tr>
		<td rowspan="1" colspan="1" align="center">Downstream</td>
		<td rowspan="1" colspan="1" align="center">x2</td>
		<td rowspan="1" colspan="1" align="center">#</td>
		<td rowspan="1" colspan="1">see Q|L</td>
		<td rowspan="1" colspan="1">see L</td>
          </tr>
	  <tr>
		<td rowspan="1" colspan="1" align="center">E2E</td>
		<td rowspan="1" colspan="1" align="center">x2</td>
		<td rowspan="1" colspan="1" align="center">#</td>
		<td rowspan="1" colspan="1">see L</td>
		<td rowspan="1" colspan="1">see L</td>
          </tr>
          <tr>
                <td rowspan="3" colspan="1">QR: sQuare + Ref. Sq. Bits</td>
                <td rowspan="3" colspan="1" align="center">2</td>
                <td rowspan="1" colspan="1" align="center">Upstream</td>
                <td rowspan="1" colspan="1" align="center">x2</td>
                <td rowspan="1" colspan="1" align="center">*</td>
                <td rowspan="3" colspan="1">Rate over N*ppa pkts (see Q bit for N)</td>
                <td rowspan="1" colspan="1">see Q</td>
          </tr>
          <tr>
                <td rowspan="1" colspan="1" align="center">3/4 RT</td>
                <td rowspan="1" colspan="1" align="center">x2</td>
                <td rowspan="1" colspan="1" align="center">*</td>
                <td rowspan="2" colspan="1">N*ppa pkts (see Q bit for N)</td>
          </tr>
          <tr>
                <td rowspan="1" colspan="1" align="center">!E2E</td>
                <td rowspan="1" colspan="1" align="center">E2E, Downstream, Half RT</td>
                <td rowspan="1" colspan="1" align="center">*</td>
          </tr>
	</tbody>
       </table>
       <dl indent="6">
         <dt>*</dt>
         <dd>All protocols</dd>
         <dt>#</dt>
         <dd>Protocols employing loss detection (with or without pure ACK loss detection)</dd>
         <dt>$</dt>
         <dd>Require a working Spin bit</dd>
         <dt>!</dt>
         <dd>Metric relative to the opposite channel</dd>
         <dt>x2</dt>
         <dd>Same metric for both directions</dd>
         <dt>ppa</dt>
         <dd>Packets-Per-Ack</dd>
         <dt>Q|L</dt>
         <dd>See Q if Upstream loss is significant; L otherwise</dd>
         <dt>E2E</dt>
         <dd>End to end</dd>
       </dl>
      <section anchor="implementation-considerations">
        <name>Implementation Considerations</name>
        <t>By combining the information of the two tables above, it can be deduced that the
solutions with 3 bits (i.e., QL or QR + S or D) or 4 bits (i.e., QL or QR + SD)
allow having more complete and resilient measurements.</t>
        <t>The methodologies described in the previous sections are transport agnostic and
can be applied in various situations. The choice of the methods also depends
on the specific protocol. For example, QL is a good combination; however, if
a protocol does not support, or cannot set, the L bit, QR is the only
viable solution.</t>
      </section>
    </section>
    <section anchor="applications">
      <name>Examples of Application</name>
      <t>This document describes several measurement methods, but it is not expected that
all methods will be implemented together. For example, only some of the methods
described in this document (i.e., sQuare bit and Spin bit) are utilized in
<xref target="I-D.ietf-core-coap-pm"/>. Also, the binding of a delay signal to QUIC is
partially described in <xref target="RFC9000" sectionFormat="of" section="17.4"/>, which adds only the
Spin bit to the first byte of the short packet header, leaving two reserved bits
for future use (see <xref target="RFC9000" sectionFormat="of" section="17.2.2"/>).</t>
      <t>All signals discussed in this document have been implemented in successful
experiments for both QUIC and TCP. The application scenarios considered allow
the monitoring of the interconnections inside a data center (Intra-DC), between
data centers (Inter-DC), as well as end-to-end large-scale data transfers.  For
the application of the methods described in this document, it is assumed that
the monitored flows follow stable paths and traverse the same measurement
points.</t>
      <t>The specific implementation details and the choice of the bits used for the
experiments with QUIC and TCP are out of scope for this document.  A
specification defining the specific protocol application is expected to discuss
the implementation details depending on which bits will be implemented in the
protocol, e.g., <xref target="I-D.ietf-core-coap-pm"/>. If bits used for specific
measurements can also be used for other purposes by a protocol, the
specification is expected to address ways for on-path observers to disambiguate
the signals or to discuss limitations on the conditions under which the
observers can expect a valid signal.</t>
    </section>
    <section anchor="ossification">
      <name>Protocol Ossification Considerations</name>
      <t>Accurate loss and delay information is not required for the operation of any
protocol, though its presence for a sufficient number of flows is important for
the operation of networks.</t>
      <t>The delay and loss bits are amenable to "greasing" described in <xref target="RFC8701"/> if
the protocol designers are not ready to dedicate (and ossify) bits used for loss
reporting to this function. The greasing could be accomplished similarly to the
latency Spin bit greasing in <xref target="RFC9000" sectionFormat="of" section="17.4"/>. For example,
the protocol designers could decide that a fraction of flows should not encode
loss and delay information, and instead, the bits would be set to arbitrary
values. Setting any of the bits described in this document to arbitrary values
would make the corresponding delay and loss information resemble noise rather
than the expected signal for the flow, and the observers would need to be ready
to ignore such flows.</t>
    </section>
    <section anchor="security-considerations">
      <name>Security Considerations</name>
      <t>The methods described in this document are transport agnostic and potentially
applicable to any transport-layer protocol, and especially valuable for encrypted
protocols. These methods can be applied to both limited domains and the Internet,
depending on the specific protocol application.</t>
      <t>Passive loss and delay observations have been a part of the network operations
for a long time, so exposing loss and delay information to the network does not
add new security concerns for protocols that are currently observable.</t>
      <t>In the absence of packet loss, Q and R bits signals do not provide any
information that cannot be observed by simply counting packets transiting a
network path. In the presence of packet loss, Q and R bits will disclose
the loss, but this is information about the environment and not the endpoint
state. The L bit signal discloses internal state of the protocol's loss-detection 
machinery, but this state can often be gleaned by timing packets and
observing the congestion controller response.</t>
      <t>The measurements described in this document do not imply that new packets injected
into the network can cause potential harm to the network itself and to data
traffic. The measurements could be harmed by an attacker altering the marking
of the packets or injecting artificial traffic. Authentication techniques may be
used where appropriate to guard against these traffic attacks.</t>
      <t>Hence, loss bits do not provide a viable new mechanism to attack data integrity
and secrecy.</t>
      <t>The measurement fields introduced in this document are intended to be included
in the packets. However, it is worth mentioning that it may be possible to use this
information as a covert channel.</t>
      <t>This document does not define a specific application, and the described
techniques can generally apply to different communication protocols operating in
different security environments. A specification defining a specific protocol
application is expected to address the respective security considerations and
must consider specifics of the protocol and its expected operating environment.
For example, security considerations for QUIC, discussed in 
<xref target="RFC9000" sectionFormat="of" section="21"/> and <xref target="RFC9001" sectionFormat="of" section="9"/>, consider a possibility of
active and passive attackers in the network as well as attacks on specific QUIC
mechanisms.</t>
      <section anchor="optimistic-ack-attack">
        <name>Optimistic ACK Attack</name>
        <t>A defense against an optimistic ACK attack, described in 
<xref target="RFC9000" sectionFormat="of" section="21.4"/>, involves a sender randomly skipping packet numbers to detect
a receiver acknowledging packet numbers that have never been received. The Q bit
signal may inform the attacker which packet numbers were skipped on purpose and
which had been actually lost (and are, therefore, safe for the attacker to
acknowledge). To use the Q bit for this purpose, the attacker must first receive
at least an entire Q Block of packets, which renders the attack ineffective
against a delay-sensitive congestion controller.</t>
        <t>A protocol that is more susceptible to an optimistic ACK attack with the loss
signal provided by the Q bit and that uses a loss-based congestion controller should
shorten the current Q Block by the number of skipped packets numbers. For example,
skipping a single packet number will invert the square signal one outgoing
packet sooner.</t>
        <t>Similar considerations apply to the R bit, although a shortened Reflection Block along
with a matching skip in packet numbers does not necessarily imply a lost
packet, since it could be due to a lost packet on the reverse path along with a
deliberately skipped packet by the sender.</t>
      </section>
      <section anchor="delay-bit-with-rtt-obfuscation">
        <name>Delay Bit with RTT Obfuscation</name>
        <t>Theoretically, delay measurements can be used to roughly evaluate the distance
of the client from the server (using the RTT) or from any intermediate observer
(using the client-observer half-RTT). As described in <xref target="RTT-PRIVACY"/>, connection
RTT measurements for geolocating endpoints are usually inferior to even the
most basic IP geolocation databases. It is the variability within RTT
measurements (the jitter) that is most informative, as it can provide insight
into the operating environment of the endpoints as well as the state of the
networks (queuing delays) used by the connection.</t>
        <t>Nevertheless, to further mask the actual RTT of the connection, the Delay bit
algorithm can be slightly modified by, for example, delaying the client-side
reflection of the delay sample by a fixed, randomly chosen time value. This
would lead an intermediate observer to measure a delay greater than the real
one.</t>
        <t>This Additional Delay should be randomly selected by the client and kept
constant for a certain amount of time across multiple connections. This ensures
that the client-server jitter remains the same as if no Additional Delay had
been inserted. For example, a new Additional Delay value could be generated
whenever the client's IP address changes.</t>
        <t>Despite the Additional Delay, this Hidden Delay technique still allows an
accurate measurement of the RTT components (observer-server) and all the
intra-domain measurements used to distribute the delay in the network.
Furthermore, unlike the Delay bit, the Hidden Delay bit does not require the
use of the client reflection threshold (1 ms by default). Removing this
threshold may lead to increasing the number of valid measurements produced by
the algorithm.</t>
        <t>Note that the Hidden Delay bit does not affect an observer's ability to measure
accurate RTT using other means, such as timing packets exchanged during the
connection establishment.</t>
      </section>
    </section>
    <section anchor="privacy-considerations">
      <name>Privacy Considerations</name>
      <t>To minimize unintentional exposure of information, loss bits provide an explicit
loss signal -- a preferred way to share information per <xref target="RFC8558"/>.</t>
      <t>New protocols commonly have specific privacy goals, and loss reporting must
ensure that loss information does not compromise those privacy goals. For
example, <xref target="RFC9000"/> allows changing Connection IDs in the middle of a
connection to reduce the likelihood of a passive observer linking old and new
sub-flows to the same device (see <xref target="RFC9000" sectionFormat="of" section="5.1"/>). A QUIC
implementation would need to reset all counters when it changes the destination
(IP address or UDP port) or the Connection ID used for outgoing packets. It
would also need to avoid incrementing the Unreported Loss counter for loss of
packets sent to a different destination or with a different Connection ID.</t>
      <t>It is also worth highlighting that, if these techniques are not widely deployed,
an endpoint that uses them may be fingerprinted based on their usage.
However, since there is no release of user data, the techniques seem unlikely to
substantially increase the existing privacy risks.</t>
      <t>Furthermore, if there is experimental traffic with these bits set on the network,
a network operator could potentially prioritize this marked traffic by placing it
in a priority queue. This may result in the delivery of better service, which
could potentially mislead an experiment intended to benchmark the network.</t>
    </section>
    <section anchor="iana-considerations">
      <name>IANA Considerations</name>
      <t>This document has no IANA actions.</t>
    </section>

  </middle>
  <back>

<displayreference target="RFC9293" to="TCP"/>
<displayreference target="RFC3168" to="ECN"/>
<displayreference target="RFC7799" to="IPPM-METHODS"/>
<displayreference target="RFC9000" to="QUIC-TRANSPORT"/>
<displayreference target="RFC9001" to="QUIC-TLS"/>
<displayreference target="RFC9065" to="TRANSPORT-ENCRYPT"/>
<displayreference target="RFC9312" to="QUIC-MANAGEABILITY"/>
<displayreference target="I-D.trammell-quic-spin" to="QUIC-SPIN"/>
<displayreference target="I-D.ietf-tsvwg-udp-options" to="UDP-OPTIONS"/>
<displayreference target="I-D.herbert-udp-space-hdr" to="UDP-SURPLUS"/>
<displayreference target="I-D.ietf-tcpm-accurate-ecn" to="ACCURATE-ECN"/>
<displayreference target="RFC9341" to="AltMark"/>
<displayreference target="RFC9343" to="IPv6AltMark"/>
<displayreference target="RFC7713" to="ConEx"/>
<displayreference target="RFC7786" to="ConEx-TCP"/>
<displayreference target="I-D.trammell-tsvwg-spin" to="TSVWG-SPIN"/>
<displayreference target="I-D.trammell-ippm-spin" to="IPPM-SPIN"/>
<displayreference target="I-D.ietf-core-coap-pm" to="CORE-COAP-PM"/>

    <references>
      <name>References</name>
      <references>
        <name>Normative References</name>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9293.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.3168.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7799.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9000.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8558.xml"/>

      </references>
      <references>
        <name>Informative References</name>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9001.xml"/> 
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9065.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9312.xml"/>
<reference anchor="I-D.trammell-quic-spin" target="https://datatracker.ietf.org/doc/html/draft-trammell-quic-spin-03">
<front>
<title>
Adding Explicit Passive Measurability of Two-Way Latency to the QUIC Transport Protocol
</title>
<author fullname="Brian Trammell" initials="B." surname="Trammell" role="editor">
<organization>ETH Zurich</organization>
</author>
<author fullname="Piet De Vaere" initials="P." surname="De Vaere">
<organization>ETH Zurich</organization>
</author>
<author fullname="Roni Even" initials="R." surname="Even">
<organization>Huawei</organization>
</author>
<author fullname="Giuseppe Fioccola" initials="G." surname="Fioccola">
<organization>Telecom Italia</organization>
</author>
<author fullname="Thomas Fossati" initials="T." surname="Fossati">
<organization>Nokia</organization>
</author>
<author fullname="Marcus Ihlar" initials="M." surname="Ihlar">
<organization>Ericsson</organization>
</author>
<author fullname="Al Morton" initials="A." surname="Morton">
<organization>AT&amp;T Labs</organization>
</author>
<author fullname="Stephan Emile" initials="S." surname="Emile">
<organization>Orange</organization>
</author>
<date day="14" month="May" year="2018"/>
</front>
<seriesInfo name="Internet-Draft" value="draft-trammell-quic-spin-03"/>
</reference>
        <reference anchor="RTT-PRIVACY">
          <front>
            <title>Revisiting the Privacy Implications of Two-Way Internet Latency Data</title>
            <author fullname="Brian Trammell" initials="B." surname="Trammell">
              <organization/>
            </author>
            <author fullname="Mirja Khlewind" initials="M." surname="Khlewind">
              <organization/>
            </author>
            <date year="2018" month="March"/>
          </front>
          <seriesInfo name="DOI" value="10.1007/978-3-319-76481-8_6"/>
          <seriesInfo name="ISBN" value="9783319764801"/>
          <refcontent>Passive and Active Measurement, pp. 73-84, Springer International Publishing</refcontent>
        </reference>
<reference anchor="I-D.ietf-tsvwg-udp-options" target="https://datatracker.ietf.org/doc/html/draft-ietf-tsvwg-udp-options-23">
<front>
<title>Transport Options for UDP</title>
<author fullname="Dr. Joseph D. Touch" initials="J." surname="Touch">
<organization>Independent Consultant</organization>
</author>
<date day="15" month="September" year="2023"/>
</front>
<seriesInfo name="Internet-Draft" value="draft-ietf-tsvwg-udp-options-23"/>
</reference>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml3/reference.I-D.herbert-udp-space-hdr.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml3/reference.I-D.ietf-tcpm-accurate-ecn.xml"/>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9341.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9343.xml"/>

        <reference anchor="ANRW19-PM-QUIC">
          <front>
            <title>Performance measurements of QUIC communications</title>
            <author fullname="Fabio Bulgarella" initials="F." surname="Bulgarella">
              <organization>Politecnico di Torino</organization>
            </author>
            <author fullname="Mauro Cociglio" initials="M." surname="Cociglio">
              <organization>Telecom Italia</organization>
            </author>
            <author fullname="Giuseppe Fioccola" initials="G." surname="Fioccola">
              <organization>Huawei Technologies</organization>
            </author>
            <author fullname="Guido Marchetto" initials="G." surname="Marchetto">
              <organization>Politecnico di Torino</organization>
            </author>
            <author fullname="Riccardo Sisto" initials="R." surname="Sisto">
              <organization>Politecnico di Torino</organization>
            </author>
            <date month="July" year="2019"/>
          </front>
          <seriesInfo name="DOI" value="10.1145/3340301.3341127"/>
          <refcontent>Proceedings of the Applied Networking Research Workshop (ANRW '19), Association for Computing Machinery</refcontent>
        </reference>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7713.xml"/>
<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7786.xml"/>

<reference anchor="I-D.trammell-tsvwg-spin" target="https://datatracker.ietf.org/doc/html/draft-trammell-tsvwg-spin-00">
<front>
<title>
A Transport-Independent Explicit Signal for Hybrid RTT Measurement
</title>
<author fullname="Brian Trammell" initials="B." surname="Trammell" role="editor">
<organization>ETH Zurich</organization>
</author>
<date day="2" month="July" year="2018"/>
</front>
<seriesInfo name="Internet-Draft" value="draft-trammell-tsvwg-spin-00"/>
</reference>

<reference anchor="I-D.trammell-ippm-spin" target="https://datatracker.ietf.org/doc/html/draft-trammell-ippm-spin-00">
<front>
<title>
An Explicit Transport-Layer Signal for Hybrid RTT Measurement
</title>
<author fullname="Brian Trammell" initials="B." surname="Trammell" role="editor">
<organization>ETH Zurich</organization>
</author>
<date day="9" month="January" year="2019"/>
</front>
<seriesInfo name="Internet-Draft" value="draft-trammell-ippm-spin-00"/>
</reference>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml3/reference.I-D.ietf-core-coap-pm.xml"/>

<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8701.xml"/>

      </references>
    </references>
     <section anchor="acknowledgments" numbered="false">
      <name>Acknowledgments</name>
      <t>The authors would like to thank the QUIC WG for their contributions, 
<contact fullname="Christian Huitema"/> for implementing Q and L bits in his picoquic stack, and <contact fullname="Ike Kunze"/> for
providing constructive reviews and helpful suggestions.</t>
    </section>
    <section anchor="contributors" numbered="false">
      <name>Contributors</name>
      <t>The following people provided valuable contributions to this document:</t>
        <contact fullname="Marcus Ihlar">
          <organization>Ericsson</organization>
          <address>
            <email>marcus.ihlar@ericsson.com</email>
          </address>
        </contact>
        <contact fullname="Jari Arkko">
          <organization>Ericsson</organization>
          <address>
            <email>jari.arkko@ericsson.com</email>
          </address>
        </contact>
        <contact fullname="Emile Stephan">
          <organization>Orange</organization>
          <address>
            <email>emile.stephan@orange.com</email>
          </address>
        </contact>
        <contact fullname="Dmitri Tikhonov">
          <organization>LiteSpeed Technologies</organization>
          <address>
            <email>dtikhonov@litespeedtech.com</email>
          </address>
        </contact>
    </section>
  </back>
</rfc>
