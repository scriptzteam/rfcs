<?xml version='1.0' encoding='UTF-8'?>

<!DOCTYPE rfc [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">
]>

<rfc xmlns:xi="http://www.w3.org/2001/XInclude" ipr="trust200902" category="info" docName="draft-ietf-mops-ar-use-case-18" number="9699" consensus="true" obsoletes="" updates="" submissionType="IETF" xml:lang="en" tocInclude="true" symRefs="true" sortRefs="true" version="3">

  <front>
    <title abbrev="XR Use Case">Use Case for an Extended
    Reality Application on Edge Computing Infrastructure</title>
    <seriesInfo name="RFC" value="9699"/>
    <author fullname="Renan Krishna" initials="R." surname="Krishna">
      <address>
        <postal>
          <country>United Kingdom</country>
        </postal>
        <email>renan.krishna@gmail.com</email>
      </address>
    </author>
    <author initials="A." surname="Rahman" fullname="Akbar Rahman">
      <organization>Ericsson</organization>
      <address>
        <postal>
          <street>349 Terry Fox Drive</street>
          <city>Ottawa</city>
	  <region>Ontario</region>
          <code>K2K 2V6</code>
          <country>Canada</country>
        </postal>
        <email>Akbar.Rahman@ericsson.com</email>
      </address>
    </author>
    <date month="December" year="2024"/>
    <area>OPS</area>
    <workgroup>mops</workgroup>

    <abstract>
      <t>This document explores the issues involved in the use of edge
      computing resources to operationalize a media use case that involves an
      Extended Reality (XR) application. In particular, this document
      discusses an XR application that can run on devices having different
      form factors (such as different physical sizes and shapes) and needs edge
      computing resources to mitigate the effect of problems such as the need
      to support interactive communication requiring low latency, limited
      battery power, and heat dissipation from those devices.  This document
      also discusses the expected behavior of XR applications, which can be
      used to manage traffic, and the service requirements for XR applications
      to be able to run on the network. Network operators who are interested
      in providing edge computing resources to operationalize the requirements
      of such applications are the intended audience for this document.
      </t>
    </abstract>
  </front>
  <middle>
    <section anchor="introduction" numbered="true" toc="default">
      <name>Introduction</name>
      <t>
		Extended Reality (XR) is a term that includes Augmented
		Reality (AR), Virtual Reality (VR), and Mixed Reality (MR)
		<xref target="XR" format="default"/>.  AR combines the real
		and virtual, is interactive, and is aligned to the physical
		world of the user <xref target="AUGMENTED_2"
		format="default"/>. On the other hand, VR places the user
		inside a virtual environment generated by a computer <xref
		target="AUGMENTED" format="default"/>. MR merges the real and
		virtual along a continuum that connects a completely real
		environment at one end to a completely virtual environment at
		the other end. In this continuum, all combinations of the real
		and virtual are captured <xref target="AUGMENTED"
		format="default"/>.
      </t>

      
<t>
	    XR applications have several requirements for the network and the
	    mobile devices running these applications.  Some XR applications
	    (such as AR applications) require real-time processing of video
	    streams to recognize specific objects. This processing is then
	    used to overlay information on the video being displayed to the
	    user.  In addition, other XR applications (such as AR and VR applications) also
	    require generation of new video frames to be played to the
	    user. Both the real-time processing of video streams and the
	    generation of overlay information are computationally intensive
	    tasks that generate heat <xref target="DEV_HEAT_1"
	    format="default"/> <xref target="DEV_HEAT_2" format="default"/>
	    and drain battery power <xref target="BATT_DRAIN"
	    format="default"/> on the mobile device running the XR
	    application.  Consequently, in order to run applications with XR
	    characteristics on mobile devices, computationally intensive tasks
	    need to be offloaded to resources provided by edge computing.
      </t>
      <t>
		Edge computing is an emerging paradigm where, for the purpose of this document, computing resources and storage are made available in close
		network proximity at the edge of the Internet to mobile devices and sensors <xref target="EDGE_1" format="default"/> <xref target="EDGE_2" format="default"/>. A computing resource or storage is in
		close network proximity to a mobile device or sensor if there is a short and high-capacity network path to it
		such that the latency and bandwidth requirements of applications running on those mobile devices or sensors can be met.
		These edge computing devices use cloud technologies that enable them to support offloaded XR applications. In particular, cloud implementation techniques <xref target="EDGE_3" format="default"/> such as the following can be deployed:
		</t>
		
		<dl spacing="normal">
        <dt>Disaggregation:</dt><dd>Using Software-Defined Networking (SDN) to break vertically integrated systems into independent components. These components can have open interfaces that are standard, well documented, and non-proprietary.</dd>

        <dt>Virtualization:</dt><dd>Being able to run multiple independent copies of those components, such as SDN Controller applications and Virtual Network Functions, on a
		common hardware platform.</dd>
        <dt>Commoditization:</dt><dd>Being able to elastically scale those virtual components across commodity hardware as the workload dictates.</dd>
      </dl>
		
		
		
		<t>
		 Such techniques enable XR applications that require low latency and high bandwidth to be delivered by proximate edge devices. This is because the disaggregated components can run on proximate edge devices rather than on a remote cloud several hops away and deliver low-latency, high-bandwidth service to offloaded applications <xref target="EDGE_2" format="default"/>.
      </t>

      <t>
	  This document discusses the issues involved when edge computing
	  resources are offered by network operators to operationalize the
	  requirements of XR applications running on devices with various form
	  factors. For the purpose of this document, a network operator is any
	  organization or individual that manages or operates the computing
	  resources or storage in close network proximity to a mobile device
	  or sensor.  Examples of form factors include the following: 1)
	  head-mounted displays (HMDs), such as optical see-through HMDs and
	  video see-through HMDs, 2) hand-held displays, and 3) smartphones
	  with video cameras and location-sensing capabilities using systems
	  such as a global navigation satellite system (GNSS).  These devices
	  have limited battery capacity and dissipate heat when running. Also,
	  as the user of these devices moves around as they run the XR
	  application, the wireless latency and bandwidth available to the
	  devices fluctuates, and the communication link itself might fail. As
	  a result, algorithms such as those based on Adaptive Bitrate (ABR)
	  techniques that base their policy on heuristics or models of
	  deployment perform sub-optimally in such dynamic environments <xref
	  target="ABR_1" format="default"/>.  In addition, network operators
	  can expect that the parameters that characterize the expected
	  behavior of XR applications are heavy-tailed. Heaviness of tails is
	  defined as the difference from the normal distribution in the
	  proportion of the values that fall a long way from the mean <xref
	  target="HEAVY_TAIL_3" format="default"/>. Such workloads require
	  appropriate resource management policies to be used on the edge.
	  The service requirements of XR applications are also challenging
	  when compared to current video applications.  In particular, several
	  Quality-of-Experience (QoE) factors such as motion sickness are
	  unique to XR applications and must be considered when
	  operationalizing a network.


		This document examines these issues with the use case presented in the following section.
      </t>
    </section>

    <section anchor="use_case" numbered="true" toc="default">
      <name>Use Case</name>

      <t>
This use case involves an XR application running on a mobile device. Consider
a group of tourists who are taking a tour around the historical site of the
Tower of London.  As they move around the site and within the historical
buildings, they can watch and listen to historical scenes in 3D that are
generated by the XR application and then overlaid by their XR headsets onto
their real-world view. The headset continuously updates their view as they
move around.
      </t>
      <t>
		The XR  application first processes the scene that the walking tourist is watching in real time and identifies objects
		that will be targeted for overlay of high-resolution videos. It then generates high-resolution 3D images
		of historical scenes related to the perspective of the tourist in real time. These generated video images are then
		overlaid on the view of the real world as seen by the tourist.
      </t>
      <t>
		This  processing of scenes
		and generation of high-resolution images are discussed in greater detail below.
		
      </t>
      <section anchor="processsing_of_scenes" numbered="true" toc="default">
        <name>Processing of Scenes</name>
        <t>
		The task of processing a scene can be broken down into a pipeline of three consecutive subtasks: tracking, acquisition of a
		model of the real world, and registration <xref target="AUGMENTED" format="default"/>.
        </t>


	<dl newline="false" spacing="normal">

		<dt>Tracking:</dt><dd>The XR application that runs on the mobile device
		needs to track the six-dimensional pose (translational in the
		three perpendicular axes and rotational about those three
		axes) of the user's head, eyes, and objects that are in
		view <xref target="AUGMENTED" format="default"/>. This
		requires tracking natural features (for example, points or
		edges of objects) that are then used in the next stage of the
		pipeline.</dd>


		<dt>Acquisition of a model of the real world:</dt><dd>The
		tracked natural features are used to develop a model of the
		real world. One of the ways this is done is to develop a model based on an
		annotated point cloud (a set of points in space that are
		annotated with descriptors) that is then stored in
		a database. To ensure that this database can be scaled up,
		techniques such as combining client-side simultaneous
		tracking and mapping with server-side localization are used
		to construct a model of the real world <xref target="SLAM_1"
		format="default"/> <xref target="SLAM_2" format="default"/>
		<xref target="SLAM_3" format="default"/> <xref target="SLAM_4"
		format="default"/>. Another model that can be built is based
		on a polygon mesh and texture mapping technique. The polygon
		mesh encodes a 3D object's shape, which is expressed as a
		collection of small flat surfaces that are polygons. In
		texture mapping, color patterns are mapped onto an object's
		surface. A third modeling technique uses a 2D lightfield that
		describes the intensity or color of the light rays arriving at
		a single point from arbitrary directions. Such a 2D lightfield
		is stored as a two-dimensional table. Assuming distant light
		sources, the single point is approximately valid for small
		scenes. For larger scenes, many 3D positions are additionally
		stored, making the table 5D. A set of all such points (either a
		2D or 5D lightfield) can then be used to construct a model of
		the real world <xref target="AUGMENTED"
		format="default"/>.</dd>

		<dt>Registration:</dt><dd>The coordinate systems,
		brightness, and color of virtual and real objects need to be
		aligned with each other; this process is called
		"registration" <xref target="REG" format="default"/>.  Once the
		natural features are tracked as discussed above, virtual
		objects are geometrically aligned with those features by
		geometric registration. This is followed by resolving
		occlusion that can occur between virtual and real objects
		<xref target="OCCL_1" format="default"/> <xref target="OCCL_2"
		format="default"/>.
		
		The XR application also applies photometric registration <xref
		target="PHOTO_REG" format="default"/> by aligning
		brightness and color between the virtual and real
		objects. Additionally, algorithms that calculate global
		illumination of both the virtual and real objects <xref
		target="GLB_ILLUM_1" format="default"/> <xref
		target="GLB_ILLUM_2" format="default"/> are executed. Various
		algorithms are also required to deal with artifacts generated by lens distortion
		<xref target="LENS_DIST" format="default"/>, blur <xref
		target="BLUR" format="default"/>, noise <xref target="NOISE"
		format="default"/>, etc.</dd>
        </dl>
      </section>
      <section anchor="generation" numbered="true" toc="default">
        <name>Generation of Images</name>

        <t>
   The XR application must generate a high-quality video that has the
   properties described above and overlay the video on the XR device's
   display.  This step is called "situated visualization". A situated
   visualization is a visualization in which the virtual objects that need to
   be seen by the XR user are overlaid correctly on the real world. This
   entails dealing with registration errors that may arise, ensuring that
   there is no visual interference <xref target="VIS_INTERFERE"
   format="default"/>, and finally maintaining temporal coherence by adapting
   to the movement of user's eyes and head.
        </t>
      </section>
    </section>
    <section anchor="Req" numbered="true" toc="default">
      <name>Technical Challenges and Solutions</name>

      <t>
	As discussed in <xref target="use_case"/>, the components of XR
	applications perform tasks that are computationally intensive, such as
	real-time generation and processing of high-quality video content.
	This section discusses the challenges such applications can face as a
	consequence and offers some solutions.
      </t>
      <t>As a result of performing computationally intensive tasks on XR devices such as XR glasses,
		excessive heat is generated by the chipsets that are involved
		in the computation <xref target="DEV_HEAT_1" format="default"/> <xref target="DEV_HEAT_2" format="default"/>.  Additionally,
		the battery on such devices discharges quickly when running
		such applications <xref target="BATT_DRAIN" format="default"/>.
	
      </t>
      <t>
	A solution to problem of heat dissipation and battery drainage is to offload the processing and video generation tasks
	to the remote cloud. However, running such tasks on the cloud is not feasible as the end-to-end delays
		must be within the order of a few milliseconds. Additionally, such applications require high bandwidth
		and low jitter to provide a high QoE to the user. In order to achieve such hard timing constraints, computationally intensive
		tasks can be offloaded to edge devices.
	
      </t>
      <t>
	Another requirement for our use case and similar applications, such as 360-degree streaming (streaming of video that represents a view in every direction in 3D space), is that the display on
	the XR device should synchronize the visual input with the way the user is moving their head. This synchronization
	is necessary to avoid motion sickness that results from a time lag between when the user moves their head and
	when the appropriate video scene is rendered. This time lag is often called "motion-to-photon delay".
Studies have shown that this delay
can be at most 20 ms and preferably between 7-15 ms in
order to avoid motion sickness <xref target="PER_SENSE" format="default"/> <xref target="XR" format="default"/> <xref target="OCCL_3" format="default"/>. Out of these 20 ms, display techniques including the refresh
rate of write displays and pixel switching take 12-13 ms <xref target="OCCL_3" format="default"/> <xref target="CLOUD" format="default"/>. This leaves 7-8 ms for the processing of
motion sensor inputs, graphic rendering, and round-trip time (RTT) between the XR device and the edge.
The use of predictive techniques to mask latencies has been considered as a mitigating strategy to reduce motion sickness <xref target="PREDICT" format="default"/>.
In addition, edge devices that are proximate to the user might be used to offload these computationally intensive tasks.
   Towards this end, a 3GPP study suggests an Ultra-Reliable Low Latency of
   0.1 to 1 ms for communication between an edge server and User Equipment
   (UE) <xref target="URLLC" format="default"/>.
      </t>
      <t>
		Note that the edge device providing the computation and storage is itself limited in such resources compared to the cloud.  
		For example, a sudden surge in demand from a large group of tourists can overwhelm the device. This will result in a degraded user
		 experience as their XR device experiences delays in receiving the video frames. In order to deal
		 with this problem, the client XR applications will need to use ABR algorithms that choose bitrate policies
		 tailored in a fine-grained manner
		 to the resource demands and play back the videos with appropriate QoE metrics as the user moves around with the group of tourists.
      </t>


      <t>
   However, the heavy-tailed nature of several operational parameters (e.g.,
   buffer occupancy, throughput, client-server latency, and variable
   transmission times) makes prediction-based adaptation by ABR algorithms
   sub-optimal <xref target="ABR_2" format="default"/>.  This is because with
   such distributions, the law of large numbers (how long it takes for the
   sample mean to stabilize) works too slowly <xref target="HEAVY_TAIL_2"
   format="default"/> and the mean of sample does not equal the mean of
   distribution <xref target="HEAVY_TAIL_2" format="default"/>; as a result,
   standard deviation and variance are unsuitable as metrics for such
   operational parameters <xref target="HEAVY_TAIL_1"
   format="default"/>.
   Other subtle issues with these distributions include
   the "expectation paradox" <xref target="HEAVY_TAIL_1" format="default"/>
   (the longer the wait for an event, the longer a further need to wait) and
   the mismatch between the size and count of events <xref
   target="HEAVY_TAIL_1" format="default"/>. These issues make designing an algorithm
   for adaptation error-prone and challenging.
   In addition, edge devices and
   communication links may fail, and logical communication relationships
   between various software components change frequently as the user moves
   around with their XR device <xref target="UBICOMP" format="default"/>.
		
      </t>

    </section>
    <section anchor="ArTraffic" numbered="true" toc="default">
      <name>XR Network Traffic</name>
	
	  <section anchor="traffic_workload" numbered="true" toc="default">
        <name>Traffic Workload</name>

        <t>
		As discussed in Sections <xref target="introduction" format="counter"/> and <xref target="Req" format="counter" />, the parameters that capture the characteristics of XR application behavior are heavy-tailed.
		Examples of such parameters include the distribution of arrival times between XR application invocations, the amount
		of data transferred, and the inter-arrival times of packets within a session. As a result, any traffic model based on
		such parameters is also heavy-tailed. Using
		these models to predict performance under alternative resource allocations by the network operator is challenging. For example, both uplink and downlink traffic to a user device has parameters such as volume of XR data, burst time, and idle time that are heavy-tailed.
      </t>
      <t>


         <xref target="TABLE_1" format="default"/> below shows various
         streaming video applications and their associated throughput
         requirements <xref target="METRICS_1" format="default"/>. Since our
         use case envisages a 6 degrees of freedom (6DoF) video or point
         cloud, the table indicates that it will require 200 to 1000 Mbps of
         bandwidth.  Also, the table shows that XR applications, such as the
         one in our use case, transmit a larger amount of data per unit time
         as compared to regular video applications. As a result, issues
         arising from heavy-tailed parameters, such as long-range dependent
         traffic <xref target="METRICS_2" format="default"/> and self-similar
         traffic <xref target="METRICS_3" format="default"/>, would be
         experienced at timescales of milliseconds and microseconds rather
         than hours or seconds. Additionally, burstiness at the timescale of
         tens of milliseconds due to the multi-fractal spectrum of traffic
         will be experienced <xref target="METRICS_4" format="default"/>.
         Long-range dependent traffic can have long bursts, and various
         traffic parameters from widely separated times can show correlation
         <xref target="HEAVY_TAIL_1" format="default"/>. Self-similar traffic
         contains bursts at a wide range of timescales <xref
         target="HEAVY_TAIL_1" format="default"/>. Multi-fractal spectrum
         bursts for traffic summarize the statistical distribution of local
         scaling exponents found in a traffic trace <xref
         target="HEAVY_TAIL_1" format="default"/>.  The operational
         consequence of XR traffic having characteristics such as long-range
         dependency and self-similarity is that the edge servers to which
         multiple XR devices are connected wirelessly could face long bursts
         of traffic <xref target="METRICS_2" format="default"/> <xref
         target="METRICS_3" format="default"/>. In addition, multi-fractal
         spectrum burstiness at the scale of milliseconds could induce jitter
         contributing to motion sickness <xref target="METRICS_4"
         format="default"/>. This is because bursty traffic combined with
         variable queueing delays leads to large delay jitter <xref
         target="METRICS_4" format="default"/>.  The operators of edge servers
         will need to run a "managed edge cloud service" <xref
         target="METRICS_5" format="default"/> to deal with the above
         problems. Functionalities that such a managed edge cloud service
         could operationally provide include dynamic placement of XR servers,
         mobility support, and energy management <xref target="METRICS_6"
         format="default"/>.  Providing support for edge servers in techniques
         such as those described in <xref target="RFC8939" format="default"/>,
         <xref target="RFC9023" format="default"/>, and <xref target="RFC9450"
         format="default"/> could guarantee performance of XR
         applications. For example, these techniques could be used for the
         link between the XR device and the edge as well as within the managed
         edge cloud service. Another option for network operators could be to
         deploy equipment that supports differentiated services <xref
         target="RFC2475" format="default"/> or per-connection
         Quality-of-Service (QoS) guarantees using RSVP <xref target="RFC2210"
         format="default"/>.

      </t>
<t>
     Thus, the provisioning of edge servers (in terms of the number of
     servers, the topology, the placement of servers, the assignment of link
     capacity, CPUs, and Graphics Processing Units (GPUs)) should be performed
     with the above factors in mind.
        </t>

	  <table anchor="TABLE_1">
	    <name>Throughput Requirements for Streaming Video Applications</name>
		<thead>
		 <tr>
		  <th>Application</th> 
		  <th>Throughput Required</th>
		 </tr>
		</thead>
		<tbody>
		 <tr>
		  <td><t>Real-world objects annotated with text and images for workflow assistance (e.g., repair)</t></td> 
		  <td> <t>1 Mbps</t></td>
		 </tr>		
		 <tr>
		  <td><t>Video conferencing</t></td> 
		  <td> <t>2 Mbps</t></td>
		 </tr>
		 <tr>
		  <td> <t>3D model and data visualization</t></td> 
		  <td> <t>2 to 20 Mbps</t></td>
		 </tr>
		 <tr>
		  <td> <t>Two-way 3D telepresence</t></td> 
		  <td> <t>5 to 25 Mbps</t></td>
		 </tr>
		 <tr>
		  <td> <t>Current-Gen 360-degree video (4K)</t></td> 
		  <td> <t>10 to 50 Mbps</t></td>
		 </tr>
		 <tr>
		  <td> <t>Next-Gen 360-degree video (8K, 90+ frames per second, high dynamic range, stereoscopic)</t></td> 
		  <td> <t>50 to 200 Mbps</t></td>
		 </tr>
		 <tr>
		  <td> <t>6DoF video or point cloud</t></td> 
		  <td> <t>200 to 1000 Mbps</t></td>
		 </tr>
		</tbody>
	  </table>



      </section>
	
	
	  <section anchor="traffic_performance" numbered="true" toc="default">
        <name>Traffic Performance Metrics</name>
	
      <t>
	  The performance requirements for XR traffic have characteristics that need to be considered when operationalizing a network.
	  These characteristics are discussed in this section.</t>
<t>The bandwidth requirements of XR applications are substantially higher than those of video-based applications.</t>

	<t>The latency requirements of XR applications have been studied recently  <xref target="XR_TRAFFIC" format="default"/>. The following characteristics were identified:
      </t>
      <ul spacing="normal">
        <li>The uploading of data from an XR device to a remote server for processing dominates the end-to-end latency.
			   </li>
        <li> A lack of visual features in the grid environment can cause increased latencies as the XR device
			   uploads additional visual data for processing to the remote server.</li>
        <li>XR applications tend to have large bursts that are separated by significant time gaps.</li>
      </ul>
	
	
	 <t> Additionally, XR applications interact with each other on a timescale of an RTT propagation, and this must be considered when operationalizing a network.</t>

         <t>
            <xref target="TABLE_2" format="default"/> shows a taxonomy of
            applications with their associated required response times and
            bandwidths (this data is from Table V in <xref target="METRICS_6"
            format="default"/>). Response times can be defined as the time
            interval between the end of a request submission and the end of
            the corresponding response from a system. If the XR device
            offloads a task to an edge server, the response time of the server
            is the RTT from when a data packet is sent from the XR device
            until a response is received. Note that the required response time
            provides an upper bound for the sum of the time taken by
            computational tasks (such as processing of scenes and generation
            of images) and the RTT. This response time depends only on the QoS
            required by an application. The response time is therefore
            independent of the underlying technology of the network and the
            time taken by the computational tasks.

         </t>

        <t>
	  Our use case requires a response time of 20 ms at most and
	  preferably between 7-15 ms, as discussed earlier. This requirement
	  for response time is similar to the first two entries in <xref
	  target="TABLE_2" format="default"/>. Additionally, the required
	  bandwidth for our use case is 200 to 1000 Mbps (see <xref
	  target="traffic_workload"/>).  Since our use case envisages multiple
	  users running the XR application on their devices and connecting to
	  the edge server that is closest to them, these latency and bandwidth
	  connections will grow linearly with the number of users. 
	  The operators should match the network provisioning to the maximum
	  number of tourists that can be supported by a link to an edge
	  server.
         </t>

	 <table anchor="TABLE_2">
	    <name>Traffic Performance Metrics of Selected XR Applications</name>
		<thead>
		 <tr>
		  <th> Application</th> 
		  <th> Required Response Time</th>  
		  <th> Expected Data Capacity</th> 
		  <th> Possible Implementations/ Examples</th>
		 </tr>
		</thead>
		<tbody>
		 <tr>
		  <td><t>Mobile XR-based remote assistance with uncompressed
		  4K (1920x1080 pixels) 120 fps HDR 10-bit real-time video
		  stream</t></td>
		  <td><t>Less than 10 milliseconds</t></td>
		  <td><t>Greater than 7.5 Gbps</t></td>
		  <td><t>Assisting maintenance technicians, Industry 4.0
		  remote maintenance, remote assistance in robotics
		  industry</t></td>
		 </tr>
		 <tr>
		  <td><t>Indoor and localized outdoor navigation </t></td>
		  <td><t>Less than 20 milliseconds</t></td>
		  <td><t>50 to 200 Mbps</t></td>
		  <td><t>Guidance in theme parks, shopping malls, archaeological sites, and
		  museums</t></td>
		 </tr>
		 <tr>
		  <td><t>Cloud-based mobile XR applications</t></td>
		  <td><t>Less than 50 milliseconds</t></td>
		  <td><t>50 to 100 Mbps</t></td>
		  <td><t>Google Live View, XR-enhanced Google Translate </t></td>
		 </tr>
		</tbody>
	 </table>
	
	  </section>

	</section>

<section anchor="conclusion" numbered="true" toc="default">
        <name>Conclusion</name>
        <t>
	    In order to operationalize a use case such as the one presented in this document, a network operator could dimension their network to provide a short and high-capacity network path from the edge computing
	    resources or storage to the mobile devices running the XR application. This is required to ensure a response time of 20 ms at most and preferably between 7-15 ms. Additionally, a bandwidth of 200
	    to 1000 Mbps is required by such applications. To deal with the characteristics of XR traffic as discussed in this document, network operators could deploy a managed edge cloud service that operationally
	    provides dynamic placement of XR servers, mobility support, and energy management. Although the use case is technically feasible, economic viability is an important factor that must be considered.
		
        </t>
</section>

<section anchor="iana" numbered="true" toc="default">
        <name>IANA Considerations</name>
        <t>
	    This document has no IANA actions.
		
        </t>
</section>


        <section anchor="Sec" numbered="true" toc="default">
        <name>Security Considerations</name>


        <t>
	    The security issues for the presented use case are similar to
	    those described in <xref target="DIST" format="default"/>, <xref
	    target="NIST1" format="default"/>, <xref target="CWE"
	    format="default"/>, and <xref target="NIST2"
	    format="default"/>. This document does not introduce any new
	    security issues.
        </t>
	
       </section>
	
	
	
  </middle>
  <back>
    <references>
      <name>Informative References</name>


      <reference anchor="DEV_HEAT_1" target="https://dl.acm.org/doi/10.1145/2637166.2637230">
        <front>
          <title> Draining our glass: an energy and heat characterization of Google Glass</title>
          <author initials="R" surname="LiKamWa" fullname="Robert LiKamWa">
            <organization/>
          </author>
          <author initials="Z" surname="Wang" fullname="Zhen Wang">
            <organization/>
          </author>
          <author initials="A" surname="Carroll" fullname="Aaron Carroll">
            <organization/>
          </author>
          <author initials="F" surname="Lin" fullname="Felix Xiaozhu Lin">
            <organization/>
          </author>
          <author initials="L" surname="Zhong" fullname="Lin Zhong">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>APSys '14: 5th Asia-Pacific Workshop on Systems, pp. 1-7</refcontent>
        <seriesInfo name="DOI" value="10.1145/2637166.2637230"/>
      </reference>

      <reference anchor="EDGE_1" target="https://ieeexplore.ieee.org/document/7807196">
        <front>
          <title> The Emergence of Edge Computing</title>
          <author initials="M" surname="Satyanarayanan" fullname="Mahadev Satyanarayanan">
            <organization/>
          </author>
          <date year="2017"/>
        </front>
        <refcontent>Computer, vol. 50, no. 1, pp. 30-39</refcontent>
        <seriesInfo name="DOI" value="10.1109/MC.2017.9"/>
      </reference>

      <reference anchor="EDGE_2" target="https://ieeexplore.ieee.org/document/8812200">
        <front>
          <title> The Seminal Role of Edge-Native Applications</title>
          <author initials="M" surname="Satyanarayanan" fullname="Mahadev Satyanarayanan">
            <organization/>
          </author>
          <author initials="G" surname="Klas" fullname="Guenter Klas">
            <organization/>
          </author>
          <author initials="M" surname="Silva" fullname="Marco Silva">
            <organization/>
          </author>
          <author initials="S" surname="Mangiante" fullname="Simone Mangiante">
            <organization/>
          </author>
          <date year="2019"/>
        </front>
        <refcontent>2019 IEEE International Conference on Edge Computing (EDGE), pp. 33-40</refcontent>
        <seriesInfo name="DOI" value="10.1109/EDGE.2019.00022"/>
      </reference>


      <reference anchor="ABR_1" target="https://dl.acm.org/doi/10.1145/3098822.3098843">
        <front>
          <title> Neural Adaptive Video Streaming with Pensieve</title>
          <author initials="H" surname="Mao" fullname="Hongzi Mao">
            <organization/>
          </author>
          <author initials="R" surname="Netravali" fullname="Ravi Netravali">
            <organization/>
          </author>
          <author initials="M" surname="Alizadeh" fullname="Mohammad Alizadeh">
            <organization/>
          </author>
          <date year="2017"/>
        </front>
        <refcontent>SIGCOMM '17: Proceedings of the Conference of the ACM Special Interest Group on Data Communication, pp. 197-210</refcontent>
        <seriesInfo name="DOI" value="10.1145/3098822.3098843"/>
      </reference>

      <reference anchor="ABR_2" target="https://www.usenix.org/conference/nsdi20/presentation/yan">
        <front>
          <title> Learning in situ: a randomized experiment in video streaming </title>
          <author initials="F" surname="Yan" fullname="Francis Y. Yan">
            <organization/>
          </author>
          <author initials="H" surname="Ayers" fullname="Hudson Ayers">
            <organization/>
          </author>
          <author initials="C" surname="Zhu" fullname="Chenzhi Zhu">
            <organization/>
          </author>
          <author initials="S" surname="Fouladi" fullname="Sadjad Fouladi">
            <organization/>
          </author>
          <author initials="J" surname="Hong" fullname="James Hong">
            <organization/>
          </author>
          <author initials="K" surname="Zhang" fullname="Keyi Zhang">
            <organization/>
          </author>
          <author initials="P" surname="Levis" fullname="Philip Levis">
            <organization/>
          </author>
          <author initials="K" surname="Winstein" fullname="Keith Winstein">
            <organization/>
          </author>
          <date month="February" year="2020"/>
        </front>
        <refcontent>17th USENIX Symposium on Networked Systems Design and Implementation (NSDI '20), pp. 495-511</refcontent>
      </reference>

      <reference anchor="HEAVY_TAIL_1" target="https://www.wiley.com/en-us/Internet+Measurement%3A+Infrastructure%2C+Traffic+and+Applications-p-9780470014615">
        <front>
          <title>Internet Measurement: Infrastructure, Traffic and Applications</title>
          <author initials="M" surname="Crovella" fullname="Mark Crovella">
            <organization/>
          </author>
          <author initials="B" surname="Krishnamurthy" fullname="Balachander Krishnamurthy">
            <organization/>
          </author>
          <date year="2006"/>
        </front>
        <refcontent>John Wiley and Sons</refcontent>
      </reference>



      <reference anchor="HEAVY_TAIL_2" target="https://arxiv.org/pdf/2001.10488">
        <front>
          <title>Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications</title>
          <author initials="N" surname="Taleb" fullname="Nassim Nicholas Taleb">
            <organization/>
          </author>
          <date year="2022"/>
        </front>
        <refcontent>Revised Edition, STEM Academic Press</refcontent>
      </reference>

      <reference anchor="UBICOMP" target="https://www.taylorfrancis.com/chapters/edit/10.1201/9781420093612-6/ubiquitous-computing-systems-jakob-bardram-adrian-friday">
        <front>
          <title>Ubiquitous Computing Systems</title>
          <author initials="J" surname="Bardram" fullname="Jakob Eyvind Bardram">
            <organization/>
          </author>
          <author initials="A" surname="Friday" fullname="Adrian Friday">
            <organization/>
          </author>
          <date year="2009"/>
        </front>
        <refcontent>Ubiquitous Computing Fundamentals, 1st Edition, Chapman and Hall/CRC Press, pp. 37-94</refcontent>
      </reference>

      <reference anchor="SLAM_1" target="https://ieeexplore.ieee.org/document/6909455">
        <front>
          <title>A Minimal Solution to the Generalized Pose-and-Scale Problem</title>
          <author initials="J" surname="Ventura" fullname="Jonathan Ventura">
            <organization/>
          </author>
          <author initials="C" surname="Arth" fullname="Clemens Arth">
            <organization/>
          </author>
          <author initials="G" surname="Reitmayr" fullname="Gerhard Reitmayr">
            <organization/>
          </author>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 422-429</refcontent>
        <seriesInfo name="DOI" value="10.1109/CVPR.2014.61"/>
      </reference>

      
      <reference anchor="SLAM_2" target="https://link.springer.com/chapter/10.1007/978-3-319-10593-2_2">
        <front>
          <title>gDLS: A Scalable Solution to the Generalized Pose and Scale Problem</title>
          <author initials="C" surname="Sweeny" fullname="Chris Sweeny">
            <organization/>
          </author>
          <author initials="V" surname="Fragoso" fullname="Victor Fragoso">
            <organization/>
          </author>
          <author initials="T" surname="Höllerer" fullname="Tobias Höllerer">
            <organization/>
          </author>
          <author initials="M" surname="Turk" fullname="Matthew Turk">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>Computer Vision - ECCV 2014, pp. 16-31</refcontent>
	<seriesInfo name="DOI" value="10.1007/978-3-319-10593-2_2"/>
      </reference>


      <reference anchor="SLAM_3" target="https://ieeexplore.ieee.org/document/6636302">
        <front>
          <title>Model Estimation and Selection towards Unconstrained Real-Time Tracking and Mapping</title>
          <author initials="S" surname="Gauglitz" fullname="Steffen Gauglitz">
            <organization/>
          </author>
          <author initials="C" surname="Sweeney" fullname="Chris Sweeney">
            <organization/>
          </author>
          <author initials="J" surname="Ventura" fullname="Jonathan Ventura">
            <organization/>
          </author>
          <author initials="M" surname="Turk" fullname="Matthew Turk">
            <organization/>
          </author>
          <author initials="T" surname="Höllerer" fullname="Tobias Höllerer">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>IEEE Transactions on Visualization and Computer Graphics, vol. 20, no. 6, pp. 825-838</refcontent>
        <seriesInfo name="DOI" value="10.1109/TVCG.2013.243"/>
      </reference>

      <reference anchor="SLAM_4" target="https://ieeexplore.ieee.org/document/6671783">
        <front>
          <title>Handling pure camera rotation in keyframe-based SLAM</title>
          <author initials="C" surname="Pirchheim" fullname="Christian Pirchheim">
            <organization/>
          </author>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <author initials="G" surname="Reitmayr" fullname="Gerhard Reitmayr">
            <organization/>
          </author>
          <date year="2013"/>
        </front>
        <refcontent>2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 229-238</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2013.6671783"/>
      </reference>

      <reference anchor="OCCL_1" target="https://onlinelibrary.wiley.com/doi/10.1111/1467-8659.1530011">
        <front>
          <title>Interactive Occlusion and Automatic Object Placement for Augmented Reality</title>
          <author initials="D.E" surname="Breen" fullname="David E. Breen">
            <organization/>
          </author>
          <author initials="R.T" surname="Whitaker" fullname="Ross T. Whitaker">
            <organization/>
          </author>
          <author initials="E" surname="Rose" fullname="Eric Rose">
            <organization/>
          </author>
          <author initials="M" surname="Tuceryan" fullname="Mihran Tuceryan">
            <organization/>
          </author>
          <date month="August" year="1996"/>
        </front>
        <refcontent>Computer Graphics Forum, vol. 15, no. 3, pp. 11-22</refcontent>
        <seriesInfo name="DOI" value="10.1111/1467-8659.1530011"/>
      </reference>

      <reference anchor="OCCL_2" target="https://ieeexplore.ieee.org/document/6948419">
        <front>
          <title>Pixel-wise closed-loop registration in video-based augmented reality</title>
          <author initials="F" surname="Zheng" fullname="Feng Zheng">
            <organization/>
          </author>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <author initials="G" surname="Welch" fullname="Greg Welch">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 135-143</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2014.6948419"/>
      </reference>

      <reference anchor="PHOTO_REG" target="https://ieeexplore.ieee.org/document/6165138">
        <front>
          <title>Online Tracking of Outdoor Lighting Variations for Augmented Reality with Moving Cameras</title>
          <author initials="Y" surname="Liu" fullname="Yanli Liu">
            <organization/>
          </author>
          <author initials="X" surname="Granier" fullname="Xavier Granier">
            <organization/>
          </author>
          <date year="2012"/>
        </front>
        <refcontent>IEEE Transactions on Visualization and Computer Graphics, vol. 18, no. 4, pp. 573-580</refcontent>
        <seriesInfo name="DOI" value="10.1109/TVCG.2012.53"/>
      </reference>

      <reference anchor="GLB_ILLUM_1" target="https://ieeexplore.ieee.org/document/6671773">
        <front>
          <title>Differential Irradiance Caching for fast high-quality light transport between virtual and real worlds</title>
          <author initials="P" surname="Kan" fullname="Peter Kan">
            <organization/>
          </author>
          <author initials="H" surname="Kaufmann" fullname="Hannes Kaufmann">
            <organization/>
          </author>
          <date year="2013"/>
        </front>
        <refcontent>2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 133-141</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2013.6671773"/>
      </reference>

      <reference anchor="GLB_ILLUM_2" target="https://ieeexplore.ieee.org/document/6948407">
        <front>
          <title>Delta Voxel Cone Tracing</title>
          <author initials="T" surname="Franke" fullname="Tobias Franke">
            <organization/>
          </author>
          <date year="2014"/>
        </front>
        <refcontent>2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pp. 39-44</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2014.6948407"/>
      </reference>

      <reference anchor="LENS_DIST" target="https://link.springer.com/chapter/10.1007/978-3-7091-6785-4_2">
        <front>
          <title>Practical Calibration Procedures for Augmented Reality</title>
          <author initials="A" surname="Fuhrmann" fullname="Anton Fuhrmann">
            <organization/>
          </author>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <author initials="W" surname="Purgathofer" fullname="Werner Purgathofer">
            <organization/>
          </author>
          <date year="2000"/>
        </front>
        <refcontent>Virtual Environments 2000, pp. 3-12</refcontent>
        <seriesInfo name="DOI" value="10.1007/978-3-7091-6785-4_2"/>
      </reference>

      <reference anchor="BLUR" target="https://diglib.eg.org/items/6954bf7e-5852-44cf-8155-4ba269dc4cee">
        <front>
          <title>Physically-Based Depth of Field in Augmented Reality</title>
          <author initials="P" surname="Kan" fullname="Peter Kan">
            <organization/>
          </author>
          <author initials="H" surname="Kaufmann" fullname="Hannes Kaufmann">
            <organization/>
          </author>
          <date year="2012"/>
        </front>
        <refcontent>Eurographics 2012 - Short Papers, pp. 89-92</refcontent>
        <seriesInfo name="DOI" value="10.2312/conf/EG2012/short/089-092"/>
      </reference>

      <reference anchor="NOISE" target="https://ieeexplore.ieee.org/document/4079277">
        <front>
          <title>Enhanced visual realism by incorporating camera image effects</title>
          <author initials="J" surname="Fischer" fullname="Jan Fischer">
            <organization/>
          </author>
          <author initials="D" surname="Bartz" fullname="Dirk Bartz">
            <organization/>
          </author>
          <author initials="W" surname="Strasser" fullname="Wolfgang Strasser">
            <organization/>
          </author>
          <date year="2006"/>
        </front>
        <refcontent>2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, pp. 205-208</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2006.297815"/>
      </reference>

      <reference anchor="VIS_INTERFERE" target="https://ieeexplore.ieee.org/document/4538846">
        <front>
          <title>Interactive Focus and Context Visualization for Augmented Reality</title>
          <author initials="D" surname="Kalkofen" fullname="Denis Kalkofen">
            <organization/>
          </author>
          <author initials="E" surname="Mendez" fullname="Erick Mendez">
            <organization/>
          </author>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <date year="2007"/>
        </front>
        <refcontent>2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 191-201</refcontent>
        <seriesInfo name="DOI" value="10.1109/ISMAR.2007.4538846"/>
      </reference>

      <reference anchor="DEV_HEAT_2" target="https://www.mdpi.com/1424-8220/20/5/1446">
        <front>
          <title>Thermal Model and Countermeasures for Future Smart Glasses</title>
          <author initials="K" surname="Matsuhashi" fullname="Kodai Matsuhashi">
            <organization/>
          </author>
          <author initials="T" surname="Kanamoto" fullname="Toshiki Kanamoto">
            <organization/>
          </author>
          <author initials="A" surname="Kurokawa" fullname="Atsushi Kurokawa">
            <organization/>
          </author>
          <date year="2020"/>
        </front>
        <refcontent>Sensors, vol. 20, no. 5, p. 1446</refcontent>
        <seriesInfo name="DOI" value="10.3390/s20051446"/>
      </reference>

      <reference anchor="BATT_DRAIN" target="https://ieeexplore.ieee.org/document/7993011">
        <front>
          <title>A Survey of Wearable Devices and Challenges</title>
          <author initials="S" surname="Seneviratne" fullname="Suranga Seneviratne">
            <organization/>
          </author>
          <author initials="Y" surname="Hu" fullname="Yining Hu">
            <organization/>
          </author>
          <author initials="T" surname="Nguyen" fullname="Tham Nguyen">
            <organization/>
          </author>
          <author initials="G" surname="Lan" fullname="Guohao Lan">
            <organization/>
          </author>
          <author initials="S" surname="Khalifa" fullname="Sara Khalifa">
            <organization/>
          </author>
          <author initials="K" surname="Thilakarathna" fullname="Kanchana Thilakarathna">
            <organization/>
          </author>
          <author initials="M" surname="Hassan" fullname="Mahbub Hassan">
            <organization/>
          </author>
          <author initials="A" surname="Seneviratne" fullname="Aruna Seneviratne">
            <organization/>
          </author>
          <date year="2017"/>
        </front>
        <refcontent>IEEE Communication Surveys and Tutorials, vol. 19 no. 4, pp. 2573-2620</refcontent>
        <seriesInfo name="DOI" value="10.1109/COMST.2017.2731979"/>
      </reference>

      <reference anchor="PER_SENSE" target="https://dl.acm.org/doi/10.1145/1012551.1012559">
        <front>
          <title> Perceptual sensitivity to head tracking latency in virtual environments with varying degrees of scene complexity.</title>
          <author initials="K" surname="Mania" fullname="Katerina Mania">
            <organization/>
          </author>
          <author initials="B.D." surname="Adelstein" fullname="Bernard D. Adelstein">
            <organization/>
          </author>
          <author initials="S.R." surname="Ellis" fullname="Stephen R. Ellis">
            <organization/>
          </author>
          <author initials="M.I." surname="Hill" fullname="Michael I. Hill">
            <organization/>
          </author>
          <date year="2004"/>
        </front>
        <refcontent>APGV '04: Proceedings of the 1st Symposium on Applied perception in graphics and visualization, pp. 39-47</refcontent>
        <seriesInfo name="DOI" value="10.1145/1012551.1012559"/>
      </reference>

      <reference anchor="XR" target="https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3534">
        <front>
          <title>Extended Reality (XR) in 5G</title>
          <author>
            <organization>3GPP</organization>
          </author>
          <date year="2020"/>
        </front>
        <seriesInfo name="3GPP TR" value="26.928"/>
      </reference>

      <reference anchor="CLOUD" target="https://dl.acm.org/doi/10.1145/3442381.3449854">
        <front>
          <title>Surrounded by the Clouds: A Comprehensive Cloud Reachability Study</title>
          <author initials="L." surname="Corneo" fullname="Lorenzo Corneo">
            <organization/>
          </author>
          <author initials="M." surname="Eder" fullname="Maximilian Eder">
            <organization/>
          </author>
          <author initials="N." surname="Mohan" fullname="Nitinder Mohan">
            <organization/>
          </author>
          <author initials="A." surname="Zavodovski" fullname="Aleksandr Zavodovski">
            <organization/>
          </author>
          <author initials="S." surname="Bayhan" fullname="Suzan Bayhan">
            <organization/>
          </author>
          <author initials="W." surname="Wong" fullname="Walter Wong">
            <organization/>
          </author>
          <author initials="P." surname="Gunningberg" fullname="Per Gunningberg">
            <organization/>
          </author>
          <author initials="J." surname="Kangasharju" fullname="Jussi Kangasharju">
            <organization/>
          </author>
          <author initials="J." surname="Ott" fullname="Jörg Ott">
            <organization/>
          </author>
          <date year="2021"/>
        </front>
        <refcontent>WWW '21: Proceedings of the Web Conference 2021, pp. 295-304</refcontent>
        <seriesInfo name="DOI" value="10.1145/3442381.3449854"/>
      </reference>

      <reference anchor="OCCL_3" target="https://www.roadtovr.com/oculus-shares-5-key-ingredients-for-presence-in-virtual-reality/">
        <front>
          <title>Oculus Shares 5 Key Ingredients for Presence in Virtual Reality</title>
          <author initials="B." surname="Lang" fullname="Ben Lang">
            <organization/>
          </author>
          <date day="24" month="September" year="2014"/>
        </front>
        <refcontent>Road to VR</refcontent>
      </reference>

      <reference anchor="PREDICT" target="https://pubmed.ncbi.nlm.nih.gov/22624290/">
        <front>
          <title>The effect of apparent latency on simulator sickness while using a see-through helmet-mounted display: reducing apparent latency with predictive compensation</title>
          <author initials="T.J." surname="Buker" fullname="Timothy J. Buker">
            <organization/>
          </author>
          <author initials="D.A." surname="Vincenzi" fullname="Dennis A. Vincenzi ">
            <organization/>
          </author>
          <author initials="J.E." surname="Deaton" fullname=" John E. Deaton">
            <organization/>
          </author>
          <date month="April" year="2012"/>
        </front>
        <refcontent>Human Factors, vol. 54, no. 2, pp. 235-249</refcontent>
        <seriesInfo name="DOI" value="10.1177/0018720811428734"/>
      </reference>

      <reference anchor="URLLC" target="https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3453">
        <front>
          <title>Study on enhancement of Ultra-Reliable
              Low-Latency Communication (URLLC) support in the 5G Core
              network (5GC)</title>
          <author>
            <organization>3GPP</organization>
          </author>
          <date year="2019"/>
        </front>
        <seriesInfo name="3GPP TR" value="23.725"/>
      </reference>

      
      <reference anchor="AUGMENTED" target="https://www.oreilly.com/library/view/augmented-reality-principles/9780133153217/">
        <front>
          <title>Augmented Reality: Principles and Practice</title>
          <author initials="D" surname="Schmalstieg" fullname="Dieter Schmalstieg">
            <organization/>
          </author>
          <author initials="T" surname="Höllerer" fullname="Tobias Höllerer">
            <organization/>
          </author>
          <date year="2016"/>
        </front>
        <refcontent>Addison-Wesley Professional</refcontent>
      </reference>

      <reference anchor="REG" target="https://direct.mit.edu/pvar/article-abstract/6/4/413/18334/Registration-Error-Analysis-for-Augmented-Reality?redirectedFrom=fulltext">
        <front>
          <title>Registration Error Analysis for Augmented Reality</title>
          <author initials="R.L." surname="Holloway" fullname="Richard L. Holloway">
            <organization/>
          </author>
          <date month="August" year="1997"/>
        </front>
        <refcontent>Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 413-432</refcontent>
        <seriesInfo name="DOI" value="10.1162/pres.1997.6.4.413"/>
      </reference>

      <reference anchor="XR_TRAFFIC" target="https://ieeexplore.ieee.org/document/9158434">
        <front>
          <title> Characterization of Multi-User Augmented Reality over Cellular Networks </title>
          <author initials="K." surname="Apicharttrisorn" fullname="Kittipat Apicharttrisorn">
            <organization/>
          </author>
          <author initials="B." surname="Balasubramanian" fullname="Bharath Balasubramanian ">
            <organization/>
          </author>
          <author initials="J." surname="Chen" fullname="Jiasi Chen">
            <organization/>
          </author>
          <author initials="R." surname="Sivaraj" fullname="Rajarajan Sivaraj">
            <organization/>
          </author>
          <author initials="Y." surname="Tsai" fullname="Yi-Zhen Tsai">
            <organization/>
          </author>
          <author initials="R." surname="Jana" fullname="Rittwik Jana">
            <organization/>
          </author>
          <author initials="S." surname="Krishnamurthy" fullname="Srikanth Krishnamurthy">
            <organization/>
          </author>
          <author initials="T." surname="Tran" fullname="Tuyen Tran">
            <organization/>
          </author>
          <author initials="Y." surname="Zhou" fullname="Yu Zhou">
            <organization/>
          </author>
          <date year="2020"/>
        </front>
        <refcontent>2020 17th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON), pp. 1-9</refcontent>
        <seriesInfo name="DOI" value="10.1109/SECON48991.2020.9158434"/>
      </reference>
	
      <reference anchor="EDGE_3" target="https://link.springer.com/book/10.1007/978-3-031-79733-0">
        <front>
          <title>5G Mobile Networks: A Systems Approach</title>
          <author initials="L." surname="Peterson" fullname="Larry Peterson">
            <organization/>
          </author>
	  <author initials="O." surname="Sunay" fullname="Oguz Sunay">
            <organization/>
          </author>
          <date year="2020"/>
        </front>
        <refcontent>Synthesis Lectures on Network Systems</refcontent>
        <seriesInfo name="DOI" value="10.1007/978-3-031-79733-0"/>
      </reference>
	
      <reference anchor="AUGMENTED_2" target="https://direct.mit.edu/pvar/article-abstract/6/4/355/18336/A-Survey-of-Augmented-Reality?redirectedFrom=fulltext">
        <front>
          <title>A Survey of Augmented Reality</title>
          <author initials="R.T." surname="Azuma" fullname="Ronald T. Azuma">
            <organization/>
          </author>
          <date month="August" year="1997"/>
        </front>
        <refcontent>Presence: Teleoperators and Virtual Environments, vol. 6, no. 4, pp. 355-385</refcontent>
        <seriesInfo name="DOI" value="10.1162/pres.1997.6.4.355"/>
      </reference>

      <reference anchor="METRICS_1" target="https://gsacom.com/paper/augmented-virtual-reality-first-wave-5g-killer-apps-qualcomm-abi-research/">
        <front>
          <title>Augmented and Virtual Reality: The first Wave of Killer Apps: Qualcomm - ABI Research</title>
          <author>
            <organization>ABI Research</organization>
          </author>
          <date month="April" year="2017"/>
        </front>
      </reference>

      <reference anchor="METRICS_2" target="https://ieeexplore.ieee.org/document/392383">
        <front>
          <title>Wide area traffic: the failure of Poisson modeling</title>
          <author initials="V." surname="Paxon" fullname="Vern Paxon">
            <organization/>
          </author>
	  <author initials="S." surname="Floyd" fullname="Sally Floyd">
            <organization/>
          </author>
          <date month="June" year="1995"/>
        </front>
        <refcontent>IEEE/ACM Transactions on Networking, vol. 3, no. 3, pp. 226-244</refcontent>
        <seriesInfo name="DOI" value="10.1109/90.392383"/>
      </reference>

      <reference anchor="METRICS_3" target="https://ieeexplore.ieee.org/abstract/document/554723">
        <front>
          <title>Self-similarity through high variability: statistical analysis and Ethernet LAN traffic at source level</title>
          <author initials="W." surname="Willinger" fullname="Walter Willinger">
            <organization/>
          </author>
         <author initials="M.S." surname="Taqqu" fullname="Murad S. Taqqu">
            <organization/>
          </author>
         <author initials="R." surname="Sherman" fullname="Robert Sherman">
            <organization/>
          </author>
         <author initials="D.V." surname="Wilson" fullname="Daniel V. Wilson">
            <organization/>
          </author>
          <date month="February" year="1997"/>
        </front>
        <refcontent>IEEE/ACM Transactions on Networking, vol. 5, no. 1, pp. 71-86</refcontent>
        <seriesInfo name="DOI" value="10.1109/90.554723"/>
      </reference>


      <reference anchor="METRICS_4" target="https://www.sciencedirect.com/science/article/pii/S1063520300903427">
        <front>
          <title>Multiscale Analysis and Data Networks</title>
          <author initials="A.C." surname="Gilbert" fullname="A.C. Gilbert">
            <organization/>
          </author>
          <date month="May" year="2001"/>
        </front>
        <refcontent>Applied and Computational Harmonic Analysis, vol. 10, no. 3, pp. 185-202</refcontent>
        <seriesInfo name="DOI" value="10.1006/acha.2000.0342"/>
      </reference>

      <reference anchor="METRICS_5" target="https://research.google/pubs/site-reliability-engineering-how-google-runs-production-systems/">
        <front>
          <title>Site Reliability Engineering: How Google Runs Production Systems</title>
          <author initials="B." surname="Beyer" fullname="Betsy Beyer" role="editor">
            <organization/>
          </author>
         <author initials="C." surname="Jones" fullname="Chris Jones" role="editor">
            <organization/>
          </author>
         <author initials="J." surname="Petoff" fullname="Jennifer Petoff" role="editor">
            <organization/>
          </author>
         <author initials="N.R." surname="Murphy" fullname="Niall Richard Murphy" role="editor">
            <organization/>
          </author>
          <date year="2016"/>
        </front>
        <refcontent>O'Reilly Media, Inc.</refcontent>
      </reference>

      <reference anchor="METRICS_6" target="https://ieeexplore.ieee.org/document/9363323">
        <front>
          <title>A Survey on Mobile Augmented Reality With 5G Mobile Edge Computing: Architectures, Applications, and Technical Aspects</title>
          <author initials="Y." surname="Siriwardhana" fullname="Yushan Siriwardhana">
            <organization/>
          </author>
         <author initials="P." surname="Porambage" fullname="Pawani Porambage">
            <organization/>
          </author>
         <author initials="M." surname="Liyanage" fullname="Madhusanka Liyanage">
            <organization/>
          </author>
         <author initials="M." surname="Ylianttila" fullname="Mika Ylianttila">
            <organization/>
          </author>
          <date year="2021"/>
        </front>
        <refcontent>IEEE Communications Surveys and Tutorials, vol. 23, no. 2, pp. 1160-1192</refcontent>
        <seriesInfo name="DOI" value="10.1109/COMST.2021.3061981"/>
      </reference>


      
      <reference anchor="HEAVY_TAIL_3" target="https://www.wiley.com/en-us/A+Primer+in+Data+Reduction%3A+An+Introductory+Statistics+Textbook-p-9780471101352">
        <front>
          <title>A Primer in Data Reduction: An Introductory Statistics Textbook</title>
          <author initials="A." surname="Ehrenberg" fullname="A.S.C Ehrenberg ">
            <organization/>
          </author>		
          <date year="2007"/>
        </front>
        <refcontent>John Wiley and Sons</refcontent>
      </reference>

      <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9023.xml"/>
      <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8939.xml"/>
      <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.9450.xml"/>

      <reference anchor="DIST" target="https://dl.acm.org/doi/10.5555/2029110">
	<front>
	  <title> Distributed Systems: Concepts and Design</title>
	  <author initials="G" surname="Coulouris" fullname="George Coulouris">
	    <organization/>
	  </author>
	  <author initials="J" surname="Dollimore" fullname="Jean Dollimore">
	    <organization/>
	  </author>
	  <author initials="T" surname="Kindberg" fullname="Tim Kindberg">
	    <organization/>
	  </author>
	  <author initials="G" surname="Blair" fullname="Gordon Blair">
	    <organization/>
	  </author>
	  <date year="2011"/>
	</front>
	<refcontent>Addison-Wesley</refcontent>
      </reference>

      <reference anchor="NIST1" target="https://csrc.nist.gov/pubs/sp/800/146/final">
	<front>
	  <title>Cloud Computing Synopsis and Recommendations</title>
	  <author>
	    <organization>NIST</organization>
	  </author>
	  <date month="May" year="2012"/>
	</front>
        <seriesInfo name="NIST SP" value="800-146"/>
	<seriesInfo name="DOI" value="10.6028/NIST.SP.800-146"/>
      </reference>

      <reference anchor="CWE" target="https://www.sans.org/top25-software-errors/">
	<front>
	  <title>CWE/SANS TOP 25 Most Dangerous Software Errors</title>
	  <author>
	    <organization>SANS Institute</organization>
	  </author>
	</front>
      </reference>
      
      <reference anchor="NIST2" target="https://csrc.nist.gov/pubs/sp/800/123/final">
	<front>
	  <title>Guide to General Server Security</title>
	  <author>
	    <organization>NIST</organization>
	  </author>
	  <date month="July" year="2008"/>
	</front>
	<seriesInfo name="NIST SP" value="800-123"/>
        <seriesInfo name="DOI" value="10.6028/NIST.SP.800-123"/>
      </reference>	
	
	<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2210.xml"/>
	<xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2475.xml"/>
	
      </references>

       <section anchor="ack" numbered="false" toc="default">
        <name>Acknowledgements</name>
        <t>Many thanks to <contact fullname="Spencer Dawkins"/>, <contact
        fullname="Rohit Abhishek"/>, <contact fullname="Jake Holland"/>,
        <contact fullname="Kiran Makhijani"/>, <contact fullname="Ali
        Begen"/>, <contact fullname="Cullen Jennings"/>, <contact
        fullname="Stephan Wenger"/>, <contact fullname="Eric Vyncke"/>,
        <contact fullname="Wesley Eddy"/>, <contact fullname="Paul Kyzivat"/>,
        <contact fullname="Jim Guichard"/>, <contact fullname="Roman
        Danyliw"/>, <contact fullname="Warren Kumari"/>, and <contact
        fullname="Zaheduzzaman Sarker"/> for providing helpful feedback,
        suggestions, and comments.</t>
      </section>

  </back>
</rfc>
