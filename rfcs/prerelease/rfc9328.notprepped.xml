<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE rfc [
  <!ENTITY nbsp    "&#160;">
  <!ENTITY zwsp   "&#8203;">
  <!ENTITY nbhy   "&#8209;">
  <!ENTITY wj     "&#8288;">
]>

<!-- generated by https://github.com/cabo/kramdown-rfc version 1.6.9 (Ruby 2.6.8) -->

<rfc xmlns:xi="http://www.w3.org/2001/XInclude" ipr="trust200902" submissionType="IETF" category="std" consensus="true" docName="draft-ietf-avtcore-rtp-vvc-18" number="9328" tocInclude="true" sortRefs="true" symRefs="true" updates="" obsoletes="" xml:lang="en" version="3">

  <!-- xml2rfc v2v3 conversion 3.15.0 -->
  <front>
    <title abbrev="RTP Payload Format for VVC">RTP Payload Format for Versatile Video Coding (VVC)</title>
    <seriesInfo name="RFC" value="9328"/>
    <author initials="S." surname="Zhao" fullname="Shuai Zhao">
      <organization>Intel</organization>
      <address>
        <postal>
          <street>2200 Mission College Blvd</street>
          <city>Santa Clara</city>
          <code>95054</code>
          <country>United States of America</country>
        </postal>
        <email>shuai.zhao@ieee.org</email>
      </address>
    </author>
    <author initials="S." surname="Wenger" fullname="Stephan Wenger">
      <organization>Tencent</organization>
      <address>
        <postal>
          <street>2747 Park Blvd</street>
          <city>Palo Alto</city>
          <code>94588</code>
          <country>United States of America</country>
        </postal>
        <email>stewe@stewe.org</email>
      </address>
    </author>
    <author initials="Y." surname="Sanchez" fullname="Yago Sanchez">
      <organization>Fraunhofer HHI</organization>
      <address>
        <postal>
          <street>Einsteinufer 37</street>
          <city>Berlin</city>
          <code>10587</code>
          <country>Germany</country>
        </postal>
        <email>yago.sanchez@hhi.fraunhofer.de</email>
      </address>
    </author>
    <author initials="Y.-K." surname="Wang" fullname="Ye-Kui Wang">
      <organization>Bytedance Inc.</organization>
      <address>
        <postal>
          <street>8910 University Center Lane</street>
          <city>San Diego</city>
          <code>92122</code>
          <country>United States of America</country>
        </postal>
        <email>yekui.wang@bytedance.com</email>
      </address>
    </author>
    <author initials="M." surname=" M Hannuksela" fullname="Miska M. Hannuksela">
      <organization>Nokia Technologies</organization>
      <address>
        <postal>
          <street>Hatanpään valtatie 30</street>
          <city>Tampere</city>
          <code>33100</code>
          <country>Finland</country>
        </postal>
        <email>miska.hannuksela@nokia.com</email>
      </address>
    </author>
    <date year="2022" month="December"/>

    <area>art</area>
    <workgroup>avtcore</workgroup>
<keyword>H.266</keyword>
<keyword>ISO/IEC 23090-3</keyword>
<keyword>MPEG-I Part 3</keyword>
<keyword>RTP Payload</keyword>
<keyword>Video</keyword>

    <abstract>
      <t>  This memo describes an RTP payload format for the Versatile Video Coding (VVC)
  specification, which was published as both ITU-T Recommendation H.266 and ISO/IEC
  International Standard 23090-3.  VVC was developed by the Joint Video Experts 
  Team (JVET). The RTP payload
format allows for packetization of one or more Network Abstraction
Layer (NAL) units in each RTP packet payload, as well as fragmentation
of a NAL unit into multiple RTP packets.  The payload format has wide
applicability in videoconferencing, Internet video streaming, and
high-bitrate entertainment-quality video, among other applications.</t>
    </abstract>
  </front>
  <middle>
    <section anchor="introduction">
      <name>Introduction</name>
      <t>The Versatile Video Coding specification was formally published as both ITU-T Recommendation H.266 <xref target="VVC"/> and ISO/IEC International Standard 23090-3 <xref target="ISO23090-3"/>.  VVC is reported to provide significant coding efficiency gains over High Efficiency Video Coding <xref target="HEVC"/>, also known as H.265, and other earlier video codecs.</t>
      <t>This memo specifies an RTP payload format for VVC.  It shares its
basic design with the NAL-unit-based RTP 
payload formats of Advanced Video Coding (AVC) <xref target="RFC6184"/>, Scalable Video Coding 
(SVC) <xref target="RFC6190"/>, and High Efficiency Video Coding (HEVC) <xref target="RFC7798"/>, as well as
their respective predecessors.  With respect to design
philosophy, security, congestion control, and overall implementation
complexity, it has similar properties to those earlier payload format
specifications.  This is a conscious choice, as at least <xref target="RFC6184"/> is
widely deployed and generally known in the relevant implementer
communities.  Certain scalability-related mechanisms known from <xref target="RFC6190"/> were incorporated into this document, as VVC version 1 supports temporal, spatial, and
signal-to-noise ratio (SNR) scalability.</t>
      <section anchor="overview-of-the-vvc-codec">
        <name>Overview of the VVC Codec</name>
        <t>VVC and HEVC share a similar hybrid video codec design.  In this
memo, we provide a very brief overview of those features of VVC
that are, in some form, addressed by the payload format specified
herein.  Implementers have to read, understand, and apply the ITU-T/ISO/IEC specifications pertaining to VVC to arrive at
interoperable, well-performing implementations.</t>
        <t>Conceptually, both VVC and HEVC include a Video Coding Layer (VCL),
which is often used to refer to the coding-tool features, and a NAL, which 
is often used to refer to the systems and transport interface aspects of the codecs.</t>
        <section anchor="coding-tool-features-informative">
          <name>Coding-Tool Features (Informative)</name>
          <t>Coding-tool features are described below with occasional reference to
the coding-tool set of HEVC, which is well known in the community.</t>
          <t>Similar to earlier hybrid-video-coding-based standards, including
HEVC, the following basic video coding design is employed by VVC.
A prediction signal is first formed by either intra- or motion-
compensated prediction, and the residual (the difference between the
original and the prediction) is then coded.  The gains in coding
efficiency are achieved by redesigning and improving almost all parts
of the codec over earlier designs.  In addition, VVC includes several
tools to make the implementation on parallel architectures easier.</t>
          <t>Finally, VVC includes temporal, spatial, and SNR scalability, as well 
as multiview coding support.</t>
          <dl newline="true" spacing="normal">
	    <dt>Coding blocks and transform structure</dt>
          <dd>Among major coding-tool differences between HEVC and VVC, one of
the important improvements is the more flexible coding tree structure
in VVC, i.e., multi-type tree.  In addition to quadtree, binary and
ternary trees are also supported, which contributes significant
improvement in coding efficiency.  Moreover, the maximum size of a 
coding tree unit (CTU) is increased from 64x64 to 128x128.  To
improve the coding efficiency of chroma signal, luma-chroma-separated
trees at CTU level may be employed for intra slices.  The square transforms 
in HEVC are extended to non-square transforms for rectangular blocks 
resulting from binary and ternary tree splits. Besides, VVC supports 
multiple transform sets (MTSs), including DCT-2, DST-7, and DCT-8, as well 
as the non-separable secondary transform.  The transforms used in VVC 
can have different sizes with support for larger transform sizes.  For DCT-2, 
the transform sizes range from 2x2 to 64x64, and for DST-7 and DCT-8, the
transform sizes range from 4x4 to 32x32.  In addition, VVC also
support sub-block transform for both intra- and inter-coded blocks.
For intra-coded blocks, intra sub-partitioning (ISP) may be used to
allow sub-block-based intra prediction and transform.  For inter blocks, sub-block transform may be used assuming that only a part of
an inter block has non-zero transform coefficients.</dd>
          <dt>Entropy coding</dt>
          <dd>Similar to HEVC, VVC uses a single entropy-coding engine, which is
based on context adaptive binary arithmetic coding <xref target="CABAC"/>
but with the support of multi-window sizes.  The window sizes can be
initialized differently for different context models.  Due to such a
design, it has more efficient adaptation speed and better coding
efficiency.  A joint chroma residual coding scheme is applied to
further exploit the correlation between the residuals of two color
components.  In VVC, different residual coding schemes are applied
for regular transform coefficients and residual samples generated
using transform-skip mode.</dd>
          <dt>In-loop filtering</dt>
          <dd>VVC has more feature support in loop filters than HEVC.  The
deblocking filter in VVC is similar to HEVC but operates at a
smaller grid.  After deblocking and sample adaptive offset (SAO), an
adaptive loop filter (ALF) may be used.  As a Wiener filter, ALF
reduces distortion of decoded pictures.  Besides, VVC introduces a
new module called luma mapping with chroma scaling 
to fully utilize the dynamic range of signal so that rate-distortion
performance of both Standard Dynamic Range (SDR) and High Dynamic Range (HDR) content is improved.</dd>
          <dt>Motion prediction and coding</dt>
          <dd>Compared to HEVC, VVC introduces several improvements in this area.
First, there is the adaptive motion vector resolution (AMVR), which
can save bit cost for motion vectors by adaptively signaling motion
vector resolution.  Then, the affine motion compensation is included
to capture complicated motion-like zooming and rotation.  Meanwhile,
prediction refinement with the optical flow (PROF) with affine mode
is further deployed to mimic affine motion at the pixel level.
Thirdly, the decoder-side motion vector refinement (DMVR) is a method
to derive the motion vector at the decoder side based on block matching so that fewer bits may be spent
on motion vectors.  Bidirectional optical flow (BDOF) is a similar
method to PROF.  BDOF adds a sample-wise offset at the 4x4 sub-block level that is derived with equations based on gradients of the prediction samples and a motion difference relative to coding-unit (CU) motion vectors.  Furthermore, merge with motion vector difference (MMVD)
is a special mode that further signals a limited set of motion
vector differences on top of merge mode.  In addition to MMVD, there
are another three types of special merge modes, i.e., sub-block
merge, triangle, and combined intra/inter prediction (CIIP).  The sub-block merge list includes one candidate of sub-block temporal motion
vector prediction (SbTMVP) and up to four candidates of affine motion
vectors.  Triangle is based on triangular block motion compensation.
CIIP combines intra and inter predictions with weighting.
Adaptive weighting may be employed with a block-level tool called 
bi-prediction with CU-based weighting (BCW), which provides more 
flexibility than in HEVC.</dd>
          <dt>Intra prediction and intra coding</dt>
          <dd>To capture the diversified local image texture directions with finer
granularity, VVC supports 65 angular directions instead of 33
directions in HEVC.  The intra mode coding is based on a 6-most-probable-modes scheme, and the 6 most probable modes are derived using
the neighboring intra prediction directions.  In addition, to deal
with the different distributions of intra prediction angles for
different block aspect ratios, a wide-angle-intra-prediction (WAIP)
scheme is applied in VVC by including intra prediction angles
beyond those present in HEVC.  Unlike HEVC, which only allows using
the most adjacent line of reference samples for intra prediction,
VVC also allows using two further reference lines, known as
multi-reference-line (MRL) intra prediction.  The additional
reference lines can be only used for the 6 most probable intra prediction
modes.  To capture the strong correlation between different color
components, in VVC, a cross-component linear mode (CCLM) is
utilized, which assumes a linear relationship between the luma sample values and their associated chroma samples.  For intra prediction,
VVC also applies a position-dependent prediction combination (PDPC)
for refining the prediction samples closer to the intra prediction
block boundary.  Matrix-based intra prediction (MIP) modes are also
used in VVC, which generates an up to 8x8 intra prediction block
using a weighted sum of downsampled neighboring reference samples,
and the weights are hard-coded constants.</dd>
          <dt>Other coding-tool features</dt>
          <dd>VVC introduces dependent quantization (DQ) to reduce quantization
error by state-based switching between two quantizers.</dd>
        </dl>
        </section>
        <section anchor="systems-and-transport-interfaces-informative">
          <name>Systems and Transport Interfaces (Informative)</name>
          <t>VVC inherits the basic systems and transport interface designs
from HEVC and AVC.  These include the NAL-unit-based syntax
structure, the hierarchical syntax and data unit structure, the
supplemental enhancement information (SEI) message mechanism, and the
video buffering model based on the hypothetical reference decoder
(HRD). The scalability features of VVC are conceptually similar to
the scalable extension of HEVC, known as SHVC.  The hierarchical syntax
and data unit structure consists of parameter sets at various levels
(i.e., decoder, sequence (pertaining to all), sequence (pertaining to a single), and
picture), picture-level header parameters, slice-level header parameters, and lower-level parameters.</t>
          <t>A number of key components that influenced the network abstraction 
layer design of VVC, as well as this memo, are described below</t>
          <dl newline="true" spacing="normal">
            <dt>Decoding capability information</dt>
          <dd>The decoding capability information (DCI) includes parameters that stay constant for the lifetime of a VVC bitstream in the duration of a video conference, continuous video stream, and similar, i.e., any video that is processed by a decoder between setup and teardown.  For streaming, the requirement of constant parameters pertains through splicing. Such information includes profile, level, and sub-profile information to determine a maximum capability interop point that is guaranteed to never be exceeded, even if splicing of video sequences occurs within a session. It further includes constraint fields (most of which are flags), which can optionally be set to indicate that the video bitstream will be constrained in the use of certain features, as indicated by the values of those fields. With this, a bitstream can be labeled as not using certain tools, which allows, among other things, for resource allocation in a decoder implementation.</dd>
          <dt>Video parameter set</dt>
          <dd>The video parameter set (VPS) pertains to one or more coded video sequences (CVSs) of multiple layers covering the same range of access units and includes, among other information, decoding dependency expressed as information for reference-picture-list construction of enhancement layers. The VPS provides a "big picture" of a scalable sequence, including what types of operation points are provided; the profile, tier, and level of the operation points; and some other high-level properties of the bitstream that can be used as the basis for session negotiation and content selection, etc. One VPS may be referenced by one or more sequence parameter sets.</dd>
          <dt>Sequence parameter set</dt>
          <dd>The sequence parameter set (SPS) contains syntax elements pertaining to a coded layer video sequence (CLVS), which is a group of pictures belonging to the same layer, starting with a random access point, and followed by pictures that may depend on each other until the next random access point picture. In MPEG-2, the equivalent of a CVS was a group of pictures (GOP), which normally started with an I frame and was followed by P and B frames. While more complex in its options of random access points, VVC retains this basic concept. One remarkable difference of VVC is that a CLVS may start with a Gradual Decoding Refresh (GDR) picture without requiring presence of traditional random access points in the bitstream, such as instantaneous decoding refresh (IDR) or clean random access (CRA) pictures. In many TV-like applications, a CVS contains a few hundred milliseconds to a few seconds of video. In video conferencing (without switching Multipoint Control Units (MCUs) involved), a CVS can be as long in duration as the whole session.</dd>
          <dt>Picture and adaptation parameter set</dt>
          <dd>The picture parameter set (PPS) and the adaptation parameter set (APS) carry information pertaining to  zero or more pictures and zero or more slices, respectively. The PPS contains information that is likely to stay constant from picture to picture, at least for pictures for a certain type, whereas the APS contains information, such as adaptive loop filter coefficients, that are likely to change from picture to picture or even within a picture. A single APS is referenced by all slices of the same picture if that APS contains information about luma mapping with chroma scaling (LMCS) or a scaling list. Different APSs containing ALF parameters can be referenced by slices of the same picture.</dd>
          <dt>Picture header</dt>
          <dd>A picture header (PH) contains information that is common to all slices that belong to the same picture. Being able to send that information as a separate NAL unit when pictures are split into several slices allows for saving bitrate, compared to repeating the same information in all slices. However, there might be scenarios where low-bitrate video is transmitted using a single slice per picture. Having a separate NAL unit to convey that information incurs in an overhead for such scenarios. For such scenarios, the picture header syntax structure is directly included in the slice header, instead of its own NAL unit. The mode of the picture header syntax structure being included in its own NAL unit or not can only be switched on/off for an entire CLVS and can only be switched off when, in the entire CLVS, each picture contains only one slice.</dd>
          <dt>Profile, tier, and level</dt>
          <dd>The profile, tier, and level syntax structures in DCI, VPS, and SPS 
contain profile, tier, and level information for all layers that refer
to the DCI, for layers associated with one or more output layer 
sets specified by the VPS, and for any layer
that refers to the SPS, respectively.</dd>
          <dt>Sub-profiles</dt>
          <dd>Within the VVC specification, a sub-profile is a 32-bit number, coded according to ITU-T Recommendation T.35, that does not carry semantics. It is carried in the profile_tier_level structure and hence is (potentially) present in the DCI, VPS, and SPS. External registration bodies can register a T.35 codepoint with ITU-T registration authorities and associate with their registration a description of bitstream restrictions beyond the profiles defined by ITU-T and ISO/IEC. This would allow encoder manufacturers to label the bitstreams generated by their encoder as complying with such sub-profile. It is expected that upstream standardization organizations (such as Digital Video Broadcasting (DVB) and Advanced Television Systems Committee (ATSC)), as well as walled-garden video services, will take advantage of this labeled system. In contrast to "normal" profiles, it is expected that sub-profiles may indicate encoder choices traditionally left open in the (decoder-centric) video coding specifications, such as GOP structures, minimum/maximum Quantizer Parameter (QP) values, and the mandatory use of certain tools or SEI messages.</dd>
          <dt>General constraint fields</dt>
          <dd>The profile_tier_level structure carries a considerable number of constraint fields (most of which are flags), which an encoder can use to indicate to a decoder that it will not use a certain tool or technology. They were included in reaction to a perceived market need to label a bitstream as not exercising a certain tool that has become commercially unviable.</dd>
          <dt>Temporal scalability support</dt>
          <dd>VVC includes support of temporal scalability, by the inclusion of the signaling of TemporalId in the NAL unit header, the restriction that pictures of a particular temporal sublayer cannot be used for inter prediction reference by pictures of a lower temporal sublayer, the sub-bitstream extraction process, and the requirement that each sub-bitstream extraction output be a conforming bitstream. Media-Aware Network Elements (MANEs) can utilize the TemporalId in the NAL unit header for stream adaptation purposes based on temporal scalability.</dd>
          <dt>Reference picture resampling (RPR)</dt>
          <dd>In AVC and HEVC, the spatial resolution of pictures cannot change unless a new sequence using a new SPS starts, with an intra random access point (IRAP) picture. VVC enables picture resolution change within a sequence at a position without encoding an IRAP picture, which is always intra coded. This feature is sometimes referred to as reference picture resampling (RPR), as the feature needs resampling of a reference picture used for inter prediction when that reference picture has a different resolution than the current picture being decoded. RPR allows resolution change without the need of coding an IRAP picture and hence avoids a momentary bit rate spike caused by an IRAP picture in streaming or video conferencing scenarios, e.g., to cope with network condition changes.  RPR can also be used in application scenarios wherein zooming of the entire video region or some region of interest is needed.</dd>
          <dt>Spatial, SNR, and multiview scalability</dt>
          <dd><t>VVC includes support for spatial, SNR, and multiview scalability. Scalable video coding is widely considered to have technical benefits and enrich services for various video applications. Until recently, however, the functionality has not been included in the first version of specifications of the video codecs. In VVC, however, all those forms of scalability are supported in the first version of VVC natively through the signaling of the nuh_layer_id in the NAL unit header, the VPS that associates layers with the given nuh_layer_id to each other, reference picture selection, reference picture resampling for spatial scalability, and a number of other mechanisms not relevant for this memo.</t>
          <dl newline="true" spacing="normal">
              <dt>Spatial scalability</dt>
              <dd>With the existence of reference picture resampling (RPR), the additional burden for scalability support is just a modification of the high-level syntax (HLS). The inter-layer prediction is employed in a scalable system to improve the coding efficiency of the enhancement layers. In addition to the spatial and temporal motion-compensated predictions that are available in a single-layer codec, the inter-layer prediction in VVC uses the possibly resampled video data of the reconstructed reference picture from a reference layer to predict the current enhancement layer. The resampling process for inter-layer prediction, when used, is performed at the block level, reusing the existing interpolation process for motion compensation in single-layer coding. It means that no additional resampling process is needed to support spatial scalability.</dd>
              <dt>SNR scalability</dt>
              <dd>SNR scalability is similar to spatial scalability except that the resampling factors are 1:1. In other words, there is no change in resolution, but there is inter-layer prediction.</dd>
              <dt>Multiview scalability</dt>
              <dd>The first version of VVC also supports multiview scalability, wherein a multi-layer bitstream carries layers representing multiple views, and one or more of the represented views can be output at the same time.</dd>
          </dl>
	  </dd>
          <dt>SEI messages</dt>
          <dd>Supplemental enhancement information (SEI) messages are information in the bitstream that do not influence the decoding process as specified in the VVC specification but address issues of representation/rendering of the decoded bitstream, label the bitstream for certain applications, and other, similar tasks. The overall concept of SEI messages and many of the messages themselves has been inherited from the AVC and HEVC specifications. Except for the SEI messages that affect the specification of the hypothetical reference decoder (HRD), other SEI messages for use in the VVC environment, which are generally useful also in other video coding technologies, are not included in the main VVC specification but in a companion specification <xref target="VSEI"/>.</dd>
	</dl>
        </section>
        <section anchor="high-level-picture-partitioning-informative">
          <name>High-Level Picture Partitioning (Informative)</name>
          <t>VVC inherited the concept of tiles and wavefront parallel processing (WPP) from HEVC, with some minor to moderate differences. The basic concept of slices was kept in VVC but designed in an essentially different form. VVC is the first video coding standard that includes subpictures as a feature, which provides the same functionality as HEVC motion-constrained tile sets (MCTSs) but designed differently to have better coding efficiency and to be friendlier for usage in application systems. More details of these differences are described below.</t>
	  <dl newline="true" spacing="normal">
            <dt>Tiles and WPP</dt>
            <dd>Same as in HEVC, a picture can be split into tile rows and tile columns in VVC, in-picture prediction across tile boundaries is disallowed, etc. However, the syntax for signaling of tile partitioning has been simplified by using a unified syntax design for both the uniform and the non-uniform mode. In addition, signaling of entry point offsets for tiles in the slice header is optional in VVC, while it is mandatory in HEVC. The WPP design in VVC has two differences compared to HEVC: i) the CTU row delay is reduced from two CTUs to one CTU, and ii) signaling of entry point offsets for WPP in the slice header is optional in VVC while it is mandatory in HEVC.</dd>
          <dt>Slices</dt>
          <dd><t>In VVC, the conventional slices based on CTUs (as in HEVC) or macroblocks (as in AVC) have been removed. The main reasoning behind this architectural change is as follows. The advances in video coding since 2003 (the publication year of AVC v1) have been such that slice-based error concealment has become practically impossible due to the ever-increasing number and efficiency of in-picture and inter-picture prediction mechanisms. An error-concealed picture is the decoding result of a transmitted coded picture for which there is some data loss (e.g., loss of some slices) of the coded picture or a reference picture, as at least some part of the coded picture is not error-free (e.g., that reference picture was an error-concealed picture). For example, when one of the multiple slices of a picture is lost, it may be error-concealed using an interpolation of the neighboring slices. While advanced video coding prediction mechanisms provide significantly higher coding efficiency, they also make it harder for machines to estimate the quality of an error-concealed picture, which was already a hard problem with the use of simpler prediction mechanisms. Advanced in-picture prediction mechanisms also cause the coding efficiency loss due to splitting a picture into multiple slices to be more significant. Furthermore, network conditions become significantly better while, at the same time, techniques for dealing with packet losses have become significantly improved. As a result, very few implementations have recently used slices for maximum-transmission-unit-size matching. Instead, substantially all applications where low-delay error resilience is required (e.g., video telephony and video conferencing) rely on system/transport-level error resilience (e.g., retransmission or forward error correction) and/or picture-based error resilience tools (e.g., feedback-based error resilience, insertion of IRAPs, scalability with a higher protection level of the base layer, and so on). Considering all the above, nowadays, it is very rare that a picture that cannot be correctly decoded is passed to the decoder, and when such a rare case occurs, the system can afford to wait for an error-free picture to be decoded and available for display without resulting in frequent and long periods of picture freezing seen by end users.</t>
          <t>Slices in VVC have two modes: rectangular slices and raster-scan slices. The rectangular slice, as indicated by its name, covers a rectangular region of the picture. Typically, a rectangular slice consists of several complete tiles. However, it is also possible that a rectangular slice is a subset of a tile and consists of one or more consecutive, complete CTU rows within a tile. A raster-scan slice consists of one or more complete tiles in a tile raster-scan order; hence, the region covered by raster-scan slices need not but could have a non-rectangular shape, but it may also happen to have the shape of a rectangle. The concept of slices in VVC is therefore strongly linked to or based on tiles instead of CTUs (as in HEVC) or macroblocks (as in AVC).</t></dd>
          <dt>Subpictures</dt>
          <dd><t>VVC is the first video coding standard that includes the support of subpictures as a feature. Each subpicture consists of one or more complete rectangular slices that collectively cover a rectangular region of the picture. A subpicture may be either specified to be extractable (i.e., coded independently of other subpictures of the same picture and of earlier pictures in decoding order) or not extractable. Regardless of whether a subpicture is extractable or not, the encoder can control whether in-loop filtering (including deblocking, SAO, and ALF) is applied across the subpicture boundaries individually for each subpicture.</t>
          <t>Functionally, subpictures are similar to the motion-constrained tile sets (MCTSs) in HEVC. They both allow independent coding and extraction of a rectangular subset of a sequence of coded pictures for use cases like viewport-dependent 360-degree video streaming optimization and region of interest (ROI) applications.</t>
          <t>There are several important design differences between subpictures and MCTSs. First, the subpictures featured in VVC allow motion vectors of a coding block to point outside of the subpicture, even when the subpicture is extractable by applying sample padding at the subpicture boundaries, in this case, similarly as at picture boundaries. Second, additional changes were introduced for the selection and derivation of motion vectors in the merge mode and in the decoder-side motion vector refinement process of VVC. This allows higher coding efficiency compared to the non-normative motion constraints applied at the encoder-side for MCTSs. Third, rewriting of slice headers (SHs) (and PH NAL units, when present) is not needed when extracting one or more extractable subpictures from a sequence of pictures to create a sub-bitstream that is a conforming bitstream. In sub-bitstream extractions based on HEVC MCTSs, rewriting of SHs is needed. Note that, in both HEVC MCTSs extraction and VVC subpictures extraction, rewriting of SPSs and PPSs is needed. However, typically, there are only a few parameter sets in a bitstream, whereas each picture has at least one slice; therefore, rewriting of SHs can be a significant burden for application systems. Fourth, slices of different subpictures within a picture are allowed to have different NAL unit types. Fifth, VVC specifies HRD and level definitions for subpicture sequences, thus the conformance of the sub-bitstream of each extractable subpicture sequence can be ensured by encoders.</t></dd>
	</dl>
        </section>
        <section anchor="NALUnitHeader">
          <name>NAL Unit Header</name>
          <t>VVC maintains the NAL unit concept of HEVC with modifications.  VVC
uses a two-byte NAL unit header, as shown in <xref target="vvc-nuh"/>.  The payload
of a NAL unit refers to the NAL unit excluding the NAL unit header.</t>
          <figure anchor="vvc-nuh">
	    <name>The Structure of the VVC NAL Unit Header</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
                  +---------------+---------------+
                  |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|
                  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                  |F|Z| LayerID   |  Type   | TID |
                  +---------------+---------------+
]]></artwork>
          </figure>
          <t>The semantics of the fields in the NAL unit header are as specified
in VVC and described briefly below for convenience.  In addition to
the name and size of each field, the corresponding syntax element
name in VVC is also provided.</t>
          <dl newline="true" spacing="normal">
          <dt>F: 1 bit</dt>
          <dd>forbidden_zero_bit.  This field is required to be zero in VVC.  Note that the
inclusion of this bit in the NAL unit header was to enable
transport of VVC video over MPEG-2 transport systems (avoidance
of start code emulations) <xref target="MPEG2S"/>.  In the context of this payload format, 
the value 1 may be used to indicate a syntax violation, e.g., for
a NAL unit resulted from aggregating a number of fragmented units
of a NAL unit but missing the last fragment, as described in the last sentence of <xref target="funits"/>.</dd>
          <dt>Z: 1 bit</dt>
          <dd>nuh_reserved_zero_bit.  This field is required to be zero in VVC, and reserved 
for future extensions by ITU-T and ISO/IEC.<br/>
This memo does not overload the "Z" bit for local extensions a) 
because overloading the "F" bit is sufficient and b) 
in order to preserve the usefulness of this memo to possible future versions 
of <xref target="VVC"/>.</dd>
          <dt>LayerId: 6 bits</dt>
          <dd>nuh_layer_id.  This field identifies the layer a NAL unit belongs to, wherein
a layer may be, e.g., a spatial scalable layer, a quality scalable
layer, a layer containing a different view, etc.</dd>
          <dt>Type: 5 bits</dt>
          <dd>nal_unit_type.  This field specifies the NAL unit type, as defined
in Table 5 of <xref target="VVC"/>.  For a reference of all currently defined
NAL unit types and their semantics, please refer to
Section 7.4.2.2 in <xref target="VVC"/>.</dd>
          <dt>TID: 3 bits</dt>
          <dd>nuh_temporal_id_plus1.  This field specifies the temporal
identifier of the NAL unit plus 1.  The value of TemporalId is
equal to TID minus 1.  A TID value of 0 is illegal to ensure that
there is at least one bit in the NAL unit header equal to 1 in order to enable the consideration of start code emulations in the NAL unit payload data independent of the NAL unit header.</dd>
          </dl>
        </section>
      </section>
      <section anchor="overview-of-the-payload-format">
        <name>Overview of the Payload Format</name>
        <t>This payload format defines the following processes required for 
transport of VVC coded data over RTP <xref target="RFC3550"/>:</t>
        <ul spacing="normal">
          <li>usage of the RTP header with this payload format</li>
          <li>packetization of VVC coded NAL units into RTP packets using
three types of payload structures: a single NAL unit packet,
aggregation packet, and fragment unit</li>
          <li>transmission of VVC NAL units of the same bitstream within a
single RTP stream</li>
          <li>media type parameters to be used with the Session Description 
Protocol (SDP) <xref target="RFC8866"/></li>
          <li>usage of RTCP feedback messages</li>
        </ul>
      </section>
    </section>
    <section anchor="conventions">
      <name>Conventions</name>
      <t>The key words "<bcp14>MUST</bcp14>", "<bcp14>MUST NOT</bcp14>", "<bcp14>REQUIRED</bcp14>", "<bcp14>SHALL</bcp14>", "<bcp14>SHALL NOT</bcp14>", "<bcp14>SHOULD</bcp14>", "<bcp14>SHOULD NOT</bcp14>", "<bcp14>RECOMMENDED</bcp14>", "<bcp14>NOT RECOMMENDED</bcp14>", "<bcp14>MAY</bcp14>", and "<bcp14>OPTIONAL</bcp14>" in this document are to be interpreted as described in BCP 14 <xref target="RFC2119"/> <xref target="RFC8174"/> when, and only when, they appear in all capitals, as shown here.</t>
    </section>
    <section anchor="definitionsandabbr">
      <name>Definitions and Abbreviations</name>
      <section anchor="definitions">
        <name>Definitions</name>
        <t>This document uses the terms and definitions of VVC.  <xref target="definitionforvvc"/>
lists relevant definitions from <xref target="VVC"/> for convenience.  <xref target="def"/>
provides definitions specific to this memo.  All the used terms and definitions 
	in this memo are verbatim copies from the <xref target="VVC"/> specification.</t>
        <section anchor="definitionforvvc">
          <name>Definitions from the VVC Specification</name>
	  <dl newline="true" spacing="normal">
            <dt>Access unit (AU):</dt>
	    <dd>A set of PUs that belong to different layers and 
contain coded pictures associated with the same time for output 
from the DPB.</dd>
            <dt>Adaptation parameter set (APS):</dt>
	    <dd>A syntax structure containing syntax 
elements that apply to zero or more slices as determined by zero or 
more syntax elements found in slice headers.</dd>
            <dt>Bitstream:</dt>
            <dd>A sequence of bits, in the form of a NAL unit stream or 
a byte stream, that forms the representation of a sequence of AUs 
forming one or more coded video sequences (CVSs).</dd>
            <dt>Coded picture:</dt>
	    <dd>A coded representation of a picture comprising VCL 
NAL units with a particular value of nuh_layer_id within an AU and 
containing all CTUs of the picture.</dd>
            <dt>Clean random access (CRA) PU:</dt>
	    <dd>A PU in which the coded picture is a 
CRA picture.</dd>
            <dt>Clean random access (CRA) picture:</dt>
	    <dd>An IRAP picture for which each 
VCL NAL unit has nal_unit_type equal to CRA_NUT.</dd>
           <dt>Coded video sequence (CVS):</dt>
           <dd>A sequence of AUs that consists, in 
decoding order, of a CVSS AU, followed by zero or more AUs that are 
not CVSS AUs, including all subsequent AUs up to but not including 
any subsequent AU that is a CVSS AU.</dd>
           <dt>Coded video sequence start (CVSS) AU:</dt>
	   <dd>An AU in which there is a PU 
for each layer in the CVS and the coded picture in each PU is a CLVSS 
picture.</dd>
           <dt>Coded layer video sequence (CLVS):</dt>
	   <dd>A sequence of PUs with the same 
value of nuh_layer_id that consists, in decoding order, of a CLVSS PU, 
followed by zero or more PUs that are not CLVSS PUs, including all 
subsequent PUs up to but not including any subsequent PU that is a 
CLVSS PU.</dd>
           <dt>Coded layer video sequence start (CLVSS) PU:</dt>
	   <dd>A PU in which the coded 
picture is a CLVSS picture.</dd>
           <dt>Coded layer video sequence start (CLVSS) picture:</dt>
	   <dd>A coded picture that is an IRAP picture with NoOutputBeforeRecoveryFlag equal to 1 or a GDR picture with NoOutputBeforeRecoveryFlag equal to 1.</dd>
	   <dt>Coding Tree Block (CTB):</dt>
	   <dd>An NxN block of samples for some value of N such that the division of a component
into CTBs is a partitioning.</dd>
           <dt>Coding tree unit (CTU):</dt>
	   <dd>A CTB of luma samples, two corresponding CTBs 
of chroma samples of a picture that has three sample arrays, or a CTB 
of samples of a monochrome picture or a picture that is coded using 
three separate colour planes and syntax structures used to code the 
	   samples.</dd>
	   <dt>Coding Unit (CU):</dt>
	   <dd>A coding block of luma samples, two corresponding coding 
blocks of chroma samples of a picture that has three sample arrays in the 
single tree mode, or a coding block of luma samples of a picture that has 
three sample arrays in the dual tree mode, or two coding blocks of chroma 
samples of a picture that has three sample arrays in the dual tree mode, or 
a coding block of samples of a monochrome picture, and syntax structures 
used to code the samples.</dd>
           <dt>Decoding Capability Information (DCI):</dt>
	   <dd>A syntax structure containing 
syntax elements that apply to the entire bitstream.</dd>
           <dt>Decoded picture buffer (DPB):</dt>
	   <dd>A buffer holding decoded pictures for 
reference, output reordering, or output delay specified for the 
hypothetical reference decoder.</dd>
           <dt>Gradual decoding refresh (GDR) picture:</dt>
	   <dd>A picture for which each VCL NAL unit has nal_unit_type equal to GDR_NUT.</dd>
           <dt>Instantaneous decoding refresh (IDR) PU:</dt>
	   <dd>A PU in which the coded picture 
is an IDR picture.</dd>
           <dt>Instantaneous decoding refresh (IDR) picture:</dt>
	   <dd>An IRAP picture for 
which each VCL NAL unit has nal_unit_type equal to IDR_W_RADL or IDR_N_LP.</dd>
           <dt>Intra random access point (IRAP) AU:</dt>
	   <dd>An AU in which there is a PU 
for each layer in the CVS and the coded picture in each PU is an 
IRAP picture.</dd>
           <dt>Intra random access point (IRAP) PU:</dt>
	   <dd>A PU in which the coded picture 
is an IRAP picture.</dd>
           <dt>Intra random access point (IRAP) picture:</dt>
	   <dd>A coded picture for which all VCL NAL units have the same value of nal_unit_type in the range of IDR_W_RADL to CRA_NUT, inclusive.</dd>
           <dt>Layer:</dt>
	   <dd>A set of VCL NAL units that all have a particular value of 
nuh_layer_id and the associated non-VCL NAL units.</dd>
           <dt>Network abstraction layer (NAL) unit:</dt>
	   <dd>A syntax structure containing 
an indication of the type of data to follow and bytes containing 
that data in the form of an RBSP interspersed as necessary with emulation 
prevention bytes.</dd>
           <dt>Network abstraction layer (NAL) unit stream:</dt>
	   <dd>A sequence of NAL units.</dd>
           <dt>Output Layer Set (OLS):</dt>
	   <dd>A set of layers for which one or more layers are specified as the output layers.</dd>
           <dt>Operation point (OP):</dt>
	   <dd>A temporal subset of an OLS, identified by an 
	   OLS index and a highest value of TemporalId.</dd>
	   <dt>Picture Header (PH):</dt>
	   <dd>A syntax structure containing syntax elements that 
apply to all slices of a coded picture.</dd>
           <dt>Picture parameter set (PPS):</dt>
	   <dd>A syntax structure containing syntax 
elements that apply to zero or more entire coded pictures as determined 
by a syntax element found in each slice header.</dd>
           <dt>Picture unit (PU):</dt>
	   <dd>A set of NAL units that are associated with each 
other according to a specified classification rule, are consecutive 
in decoding order, and contain exactly one coded picture.</dd>
           <dt>Random access:</dt>
	   <dd>The act of starting the decoding process for a 
	   bitstream at a point other than the beginning of the bitstream.</dd>
	   <dt>Raw Byte Sequence Payload (RBSP):</dt>
	   <dd>A syntax structure containing an integer 
number of bytes that is encapsulated in a NAL unit and is either empty or 
has the form of a string of data bits containing syntax elements followed 
by an RBSP stop bit and zero or more subsequent bits equal to 0.</dd>
           <dt>Sequence parameter set (SPS):</dt>
	   <dd>A syntax structure containing syntax 
elements that apply to zero or more entire CLVSs as determined by 
the content of a syntax element found in the PPS referred to by a 
syntax element found in each picture header.</dd>
           <dt>Slice:</dt>
	   <dd>An integer number of complete tiles or an integer number of 
consecutive complete CTU rows within a tile of a picture that are 
exclusively contained in a single NAL unit.</dd>
           <dt>Slice header (SH):</dt>
	   <dd>A part of a coded slice containing the data elements 
pertaining to all tiles or CTU rows within a tile represented in the slice.</dd>
           <dt>Sublayer:</dt> 
	   <dd>A temporal scalable layer of a temporal scalable bitstream
consisting of VCL NAL units with a particular value of the TemporalId
variable, and the associated non-VCL NAL units.</dd>
           <dt>Subpicture:</dt>
	   <dd>A rectangular region of one or more slices within a picture.</dd>
           <dt>Sublayer representation:</dt>
	   <dd>A subset of the bitstream consisting of NAL
units of a particular sublayer and the lower sublayers.</dd>
           <dt>Tile:</dt>
	   <dd>A rectangular region of CTUs within a particular tile column and 
a particular tile row in a picture.</dd>
           <dt>Tile column:</dt>
	   <dd>A rectangular region of CTUs having a height equal to 
the height of the picture and a width specified by syntax elements in 
the picture parameter set.</dd>
           <dt>Tile row:</dt>
	   <dd>A rectangular region of CTUs having a height specified by 
syntax elements in the picture parameter set and a width equal to the 
width of the picture.</dd>
           <dt>Video coding layer (VCL) NAL unit:</dt>
	   <dd>A collective term for coded slice NAL 
units and the subset of NAL units that have reserved values of 
nal_unit_type that are classified as VCL NAL units in this Specification.</dd>
         </dl>
        </section>
        <section anchor="def">
          <name>Definitions Specific to This Memo</name>
	  <dl newline="true" spacing="normal">
            <dt>Media-Aware Network Element (MANE):</dt>
	    <dd><t>A network element, such as a
middlebox, selective forwarding unit, or application-layer gateway
that is capable of parsing certain aspects of the RTP payload headers
or the RTP payload and reacting to their contents.</t>
              <aside>
              <t>Informative note: The concept of a MANE goes beyond normal routers
or gateways in that a MANE has to be aware of the signaling (e.g.,
to learn about the payload type mappings of the media streams),
and in that it has to be trusted when working with Secure RTP
(SRTP).  The advantage of using MANEs is that they allow packets
to be dropped according to the needs of the media coding.  For
example, if a MANE has to drop packets due to congestion on a
certain link, it can identify and remove those packets whose
elimination produces the least adverse effect on the user
experience.  After dropping packets, MANEs must rewrite RTCP
packets to match the changes to the RTP stream, as specified in
<xref target="RFC3550" section="7" sectionFormat="of" />.</t></aside></dd>
             <dt>NAL unit decoding order:</dt>
	     <dd>A NAL unit order that conforms to the
constraints on NAL unit order given in Section 7.4.2.4 in <xref target="VVC"/>, 
follow the order of NAL units in the bitstream.</dd>
             <dt>RTP stream (see <xref target="RFC7656"/>):</dt>
	     <dd>Within the scope of this memo, one RTP stream is utilized to transport a VVC bitstream, which may contain one or more layers, and each layer may contain one or more temporal sublayers.</dd>
             <dt>Transmission order:</dt>
	     <dd>The order of packets in ascending RTP sequence
number order (in modulo arithmetic).  Within an aggregation packet,
the NAL unit transmission order is the same as the order of
	     appearance of NAL units in the packet.</dd>
	  </dl>
        </section>
      </section>
      <section anchor="abbreviations">
        <name>Abbreviations</name>
	<dl newline="false" spacing="normal" indent="8">
          <dt>AU</dt>
          <dd>Access Unit</dd>
          <dt>AP</dt>
          <dd>Aggregation Packet</dd>
          <dt>APS</dt>
          <dd>Adaptation Parameter Set</dd>
          <dt>CTU</dt>
          <dd>Coding Tree Unit</dd>
          <dt>CVS</dt>
          <dd>Coded Video Sequence</dd>
          <dt>DPB</dt>
          <dd>Decoded Picture Buffer</dd>
          <dt>DCI</dt>
          <dd>Decoding Capability Information</dd>
          <dt>DON</dt>
	  <dd>Decoding Order Number</dd>
          <dt>FIR</dt>
          <dd>Full Intra Request</dd>
          <dt>FU</dt>
          <dd>Fragmentation Unit</dd>
          <dt>GDR</dt>
          <dd>Gradual Decoding Refresh</dd>
          <dt>HRD</dt>
          <dd>Hypothetical Reference Decoder</dd>
          <dt>IDR</dt>
          <dd>Instantaneous Decoding Refresh</dd>
          <dt>IRAP</dt>
	  <dd>Intra Random Access Point</dd>
          <dt>MANE</dt>
	  <dd>Media-Aware Network Element</dd>
          <dt>MTU</dt>
          <dd>Maximum Transfer Unit</dd>
          <dt>NAL</dt>
	  <dd>Network Abstraction Layer</dd>
          <dt>NALU</dt>
	  <dd>Network Abstraction Layer Unit</dd>
          <dt>OLS</dt>
	  <dd>Output Layer Set</dd>
          <dt>PLI</dt>
          <dd>Picture Loss Indication</dd>
          <dt>PPS</dt>
          <dd>Picture Parameter Set</dd>
          <dt>RPSI</dt>
	  <dd>Reference Picture Selection Indication</dd>
          <dt>SEI</dt>
	  <dd>Supplemental Enhancement Information</dd>
          <dt>SLI</dt>
          <dd>Slice Loss Indication</dd>
          <dt>SPS</dt>
	  <dd>Sequence Parameter Set</dd>
          <dt>VCL</dt>
          <dd>Video Coding Layer</dd>
          <dt>VPS</dt>
	  <dd>Video Parameter Set</dd>
      </dl>
      </section>
    </section>
    <section anchor="RTPPayloadFormat">
      <name>RTP Payload Format</name>
      <section anchor="RTPHeaderUsage">
        <name>RTP Header Usage</name>
        <t>The format of the RTP header is specified in <xref target="RFC3550"/> (reprinted as
<xref target="rtp-hdr"/> for convenience).  This payload format uses the fields of
the header in a manner consistent with that specification.</t>
        <t>The RTP payload (and the settings for some RTP header bits) for
aggregation packets and fragmentation units are specified in Sections 
<xref target="aps" format="counter"/> and <xref target="funits" format="counter"/>, respectively.</t>
        <figure anchor="rtp-hdr">
	  <name>RTP Header According to RFC 3550</name>
          <artwork name="" type="" align="left" alt=""><![CDATA[
    0                   1                   2                   3
    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |V=2|P|X|  CC   |M|     PT      |       sequence number         |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                           timestamp                           |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |           synchronization source (SSRC) identifier            |
   +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
   |            contributing source (CSRC) identifiers             |
   |                             ....                              |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
        </figure>
        <t>The RTP header information to be set according to this RTP payload 
format is set as follows:</t>
        <dl newline="true" spacing="normal">
          <dt>Marker bit (M): 1 bit</dt>
          <dd>Set for the last packet, in transmission order, among each set of packets that contain NAL units of one access unit. This is in line with the normal use of the M bit in
video formats to allow an efficient playout buffer handling.</dd>
          <dt>Payload Type (PT): 7 bits</dt>
          <dd>The assignment of an RTP payload type for this new packet format
is outside the scope of this document and will not be specified
here.  The assignment of a payload type has to be performed either
through the profile used or in a dynamic way.</dd>
          <dt>Sequence Number (SN): 16 bits</dt>
          <dd>Set and used in accordance with <xref target="RFC3550"/>.</dd>
          <dt>Timestamp: 32 bits</dt>
          <dd><t>The RTP timestamp is set to the sampling timestamp of the content. A 90 kHz clock rate <bcp14>MUST</bcp14> be used.  If the NAL unit has no timing properties of its own (e.g., parameter set and SEI NAL units), the RTP timestamp <bcp14>MUST</bcp14> be set to the RTP timestamp of the coded pictures of the access unit in which the NAL unit (according to Section 7.4.2.4 of <xref target="VVC" />) is included. Receivers <bcp14>MUST</bcp14> use the RTP timestamp for the display process, even when the bitstream contains picture timing SEI messages or decoding unit information SEI messages, as specified in <xref target="VVC"/>.</t>
          <aside><t>Informative note: When picture timing SEI messages are present, the RTP sender is responsible to ensure that the RTP timestamps are consistent with the timing information carried in the picture timing SEI messages.</t></aside>
              </dd>
              <dt>Synchronization source (SSRC): 32 bits</dt>
              <dd>Used to identify the source of the RTP packets.
A single SSRC is used for all parts of a single bitstream.</dd>
        </dl>
      </section>
      <section anchor="PayloadHeaderUsage">
        <name>Payload Header Usage</name>
        <t>The first two bytes of the payload of an RTP packet are referred to
as the payload header.  The payload header consists of the same
fields (F, Z, LayerId, Type, and TID) as the NAL unit header shown
in <xref target="NALUnitHeader"/>, irrespective of the type of the payload structure.</t>
        <t>The TID value indicates (among other things) the relative importance
of an RTP packet, for example, because NAL units belonging to higher
temporal sublayers are not used for the decoding of lower temporal
sublayers.  A lower value of TID indicates a higher importance.
More important NAL units <bcp14>MAY</bcp14> be better protected against transmission
losses than less-important NAL units.</t>
      </section>
      <section anchor="PayloadStructures">
        <name>Payload Structures</name>
        <t>Three different types of RTP packet payload structures are specified.
A receiver can identify the type of an RTP packet payload through the
Type field in the payload header.</t>
        <t>The three different payload structures are as follows:</t>
        <ul spacing="normal">
          <li>Single NAL unit packet: Contains a single NAL unit in the payload,
and the NAL unit header of the NAL unit also serves as the payload
header.  This payload structure is specified in <xref target="SingleNALUnit"/>.</li>
          <li>Aggregation Packet (AP): Contains more than one NAL unit within
one access unit.  This payload structure is specified in <xref target="aps"/>.</li>
          <li>Fragmentation Unit (FU): Contains a subset of a single NAL unit.
This payload structure is specified in <xref target="funits"/>.</li>
        </ul>
        <section anchor="SingleNALUnit">
          <name>Single NAL Unit Packets</name>
          <t>A single NAL unit packet contains exactly one NAL unit and consists
of a payload header, as defined in Table 5 of <xref target="VVC"/> (denoted here as PayloadHdr), 
following with a conditional 16-bit DONL field (in network byte order), and the NAL unit payload data
(the NAL unit excluding its NAL unit header) of the contained NAL
unit, as shown in <xref target="single-nhr"/>.</t>
          <figure anchor="single-nhr">
	    <name>The Structure of a Single NAL Unit Packet</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
   0                   1                   2                   3
   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |           PayloadHdr          |      DONL (conditional)       |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                                                               |
  |                  NAL unit payload data                        |
  |                                                               |
  |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
  |                               :...OPTIONAL RTP padding        |
  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
          <t>The DONL field, when present, specifies the value of the 16 least significant bits of the decoding order number of the contained NAL
unit.  If sprop-max-don-diff (defined in <xref target="optionalParameters"/>) is greater than 0, the DONL field <bcp14>MUST</bcp14> be present, and the variable DON for the
contained NAL unit is derived as equal to the value of the DONL
field.  Otherwise (sprop-max-don-diff is equal to 0), the DONL field <bcp14>MUST NOT</bcp14> be present.</t>
        </section>
        <section anchor="aps">
          <name>Aggregation Packets (APs)</name>
          <t>Aggregation packets (APs) can reduce
packetization overhead for small NAL units, such as most of the non-VCL NAL units, which are often only a few octets in size.</t>
          <t>An AP aggregates NAL units of one access unit, and it <bcp14>MUST NOT</bcp14> contain NAL units from more than one AU. Each NAL unit to be carried in an AP is encapsulated in an aggregation unit.  NAL units aggregated in one AP are included in NAL-unit-decoding order.</t>
          <t>An AP consists of a payload header, as defined in Table 5 of <xref target="VVC"/> (denoted here as PayloadHdr with Type=28), followed by two or more aggregation units, as shown in <xref target="au-hdr"/>.</t>
          <figure anchor="au-hdr">
	    <name>The Structure of an Aggregation Packet</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |    PayloadHdr (Type=28)       |                               |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               |
 |                                                               |
 |             two or more aggregation units                     |
 |                                                               |
 |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :...OPTIONAL RTP padding        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
          <t>The fields in the payload header of an AP are set as follows.  The F bit <bcp14>MUST</bcp14>
be equal to 0 if the F bit of each aggregated NAL unit is equal to
zero; otherwise, it <bcp14>MUST</bcp14> be equal to 1.  The Type field <bcp14>MUST</bcp14> be equal
to 28.</t>
          <t>The value of LayerId <bcp14>MUST</bcp14> be equal to the lowest value of LayerId of
all the aggregated NAL units.  The value of TID <bcp14>MUST</bcp14> be the lowest
value of TID of all the aggregated NAL units.</t>
              <aside><t>Informative note: All VCL NAL units in an AP have the same TID
value since they belong to the same access unit.  However, an AP
may contain non-VCL NAL units for which the TID value in the NAL
unit header may be different than the TID value of the VCL NAL
units in the same AP.</t></aside>
              <aside><t>Informative note: If a system envisions subpicture-level or picture-level modifications, for example, by removing subpictures or pictures of a particular layer, a good design choice on the sender's side would be to aggregate NAL units belonging to only the same subpicture or picture of a particular layer.</t></aside>
          <t>An AP <bcp14>MUST</bcp14> carry at least two aggregation units and can carry as many
aggregation units as necessary; however, the total amount of data in
an AP obviously <bcp14>MUST</bcp14> fit into an IP packet, and the size <bcp14>SHOULD</bcp14> be
chosen so that the resulting IP packet is smaller than the MTU size
in order to avoid IP layer fragmentation.  An AP <bcp14>MUST NOT</bcp14> contain the FUs
specified in <xref target="funits"/>.  APs <bcp14>MUST NOT</bcp14> be nested, i.e., an AP cannot contain another AP.</t>
          <t>The first aggregation unit in an AP consists of a conditional 16-bit
DONL field (in network byte order), followed by 16 bits of unsigned size
information (in network byte order) that indicate the size of the
NAL unit in bytes (excluding these two octets but including the NAL
unit header), followed by the NAL unit itself, including its NAL unit
header, as shown in <xref target="au-first-nhdr"/>.</t>
          <figure anchor="au-first-nhdr">
	    <name>The Structure of the First Aggregation Unit in an AP</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |               :       DONL (conditional)      |   NALU size   |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |   NALU size   |                                               |
 +-+-+-+-+-+-+-+-+         NAL unit                              |
 |                                                               |
 |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
              <aside><t>Informative note: The first octet of <xref target="au-first-nhdr"/> (indicated by the first colon) belongs to a previous aggregation unit. It is depicted to emphasize that aggregation units are octet aligned only. Similarly, the NAL unit carried in the aggregation unit can terminate at the octet boundary.</t></aside>
          <t>The DONL field, when present, specifies the value of the 16 least significant bits of the decoding order number of the aggregated NAL
unit.</t>
          <t>If sprop-max-don-diff is greater than 0, the DONL field <bcp14>MUST</bcp14> be present in an aggregation unit that is the first aggregation unit in an AP, and the variable DON for the aggregated NAL unit is derived as equal to the value of the DONL field, and the variable DON for an aggregation unit that is not the first aggregation unit in an AP-aggregated NAL unit is derived as equal to the DON of the preceding aggregated NAL unit in the same AP plus 1 modulo 65536. Otherwise (sprop-max-don-diff is equal to 0), the DONL field <bcp14>MUST NOT</bcp14> be present in an aggregation unit that is the first aggregation unit in an AP.</t>
          <t>An aggregation unit that is not the first aggregation unit in an AP
will be followed immediately by 16 bits of unsigned size information
(in network byte order) that indicate the
size of the NAL unit in bytes (excluding these two octets but
including the NAL unit header), followed by the NAL unit itself,
including its NAL unit header, as shown in <xref target="au-not-first-nhdr"/>.</t>
          <figure anchor="au-not-first-nhdr">
	    <name>The Structure of an Aggregation Unit That Is Not the First Aggregation Unit in an AP</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |               :       NALU size               |   NAL unit    |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+               |
 |                                                               |
 |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
          <aside><t>Informative note: The first octet of <xref target="au-not-first-nhdr"/> (indicated by the first colon) belongs to a previous aggregation unit. It is depicted to emphasize that aggregation units are octet aligned only. Similarly, the NAL unit carried in the aggregation unit can terminate at the octet boundary.</t></aside>
          <t><xref target="au-wout-donl"/> presents an example of an AP that contains two aggregation
units, labeled as 1 and 2 in the figure, without the DONL field
being present.</t>
          <figure anchor="au-wout-donl">
	    <name>An Example of an AP Packet Containing Two Aggregation Units without the DONL Field</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                          RTP Header                           |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |   PayloadHdr (Type=28)        |         NALU 1 Size           |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |          NALU 1 HDR           |                               |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+         NALU 1 Data           |
 |                   . . .                                       |
 |                                                               |
 +               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |  . . .        | NALU 2 Size                   | NALU 2 HDR    |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 | NALU 2 HDR    |                                               |
 +-+-+-+-+-+-+-+-+              NALU 2 Data                      |
 |                   . . .                                       |
 |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :...OPTIONAL RTP padding        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
          <t><xref target="au-with-donl"/> presents an example of an AP that contains two aggregation
units, labeled as 1 and 2 in the figure, with the DONL field being present.</t>
          <figure anchor="au-with-donl">
	    <name>An Example of an AP Containing Two Aggregation Units with the DONL Field</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                          RTP Header                           |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |   PayloadHdr (Type=28)        |        NALU 1 DONL            |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |          NALU 1 Size          |            NALU 1 HDR         |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                                                               |
 |                 NALU 1 Data   . . .                           |
 |                                                               |
 +        . . .                  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :          NALU 2 Size          |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |          NALU 2 HDR           |                               |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+          NALU 2 Data          |
 |                                                               |
 |        . . .                  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :...OPTIONAL RTP padding        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
        </section>
        <section anchor="funits">
          <name>Fragmentation Units</name>
          <t>Fragmentation Units (FUs) are introduced to enable fragmenting a
single NAL unit into multiple RTP packets, possibly without
cooperation or knowledge of the <xref target="VVC"/> encoder.  A fragment
of a NAL unit consists of an integer number of consecutive octets of
that NAL unit.  Fragments of the same NAL unit <bcp14>MUST</bcp14> be sent in
consecutive order with ascending RTP sequence numbers (with no other
RTP packets within the same RTP stream being sent between the first
and last fragment).</t>
          <t>When a NAL unit is fragmented and conveyed within FUs, it is referred
to as a fragmented NAL unit.  APs <bcp14>MUST NOT</bcp14> be fragmented.  FUs <bcp14>MUST
NOT</bcp14> be nested, i.e., an FU cannot contain a subset of another FU.</t>
          <t>The RTP timestamp of an RTP packet carrying an FU is set to the NALU-
time of the fragmented NAL unit.</t>
          <t>An FU consists of a payload header as defined in Table 5 of <xref target="VVC"/> (denoted here as PayloadHdr with Type=29), an FU header of one octet, a conditional 16-bit DONL field (in network byte order), and an FU payload (as shown in <xref target="fu-payload"/>).</t>
          <figure anchor="fu-payload">
	    <name> The Structure of an FU</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
  0                   1                   2                   3
  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |   PayloadHdr (Type=29)        |   FU header   | DONL (cond)   |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-|
 |   DONL (cond) |                                               |
 |-+-+-+-+-+-+-+-+                                               |
 |                         FU payload                            |
 |                                                               |
 |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 |                               :...OPTIONAL RTP padding        |
 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
]]></artwork>
          </figure>
          <t>The fields in the payload header are set as follows.  The Type field
<bcp14>MUST</bcp14> be equal to 29.  The fields F, LayerId, and TID <bcp14>MUST</bcp14> be equal to
the fields F, LayerId, and TID, respectively, of the fragmented NAL
unit.</t>
          <t>The FU header consists of an S bit, an E bit, an R bit, and a 5-bit FuType
field, as shown in <xref target="fu-hdr"/>.</t>
          <figure anchor="fu-hdr">
	    <name>The Structure of the FU Header</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
                          +---------------+
                          |0|1|2|3|4|5|6|7|
                          +-+-+-+-+-+-+-+-+
                          |S|E|P|  FuType |
                          +---------------+
]]></artwork>
          </figure>
          <t>The semantics of the FU header fields are as follows:</t>
	  <dl newline="true" spacing="normal">
            <dt>S: 1 bit</dt>
            <dd>When set to 1, the S bit indicates the start of a fragmented NAL
unit, i.e., the first byte of the FU payload is also the first
byte of the payload of the fragmented NAL unit.  When the FU
payload is not the start of the fragmented NAL unit payload, the S
bit <bcp14>MUST</bcp14> be set to 0.</dd>
            <dt>E: 1 bit</dt>
            <dd>When set to 1, the E bit indicates the end of a fragmented NAL
unit, i.e., the last byte of the payload is also the last byte of
the fragmented NAL unit.  When the FU payload is not the last
fragment of a fragmented NAL unit, the E bit <bcp14>MUST</bcp14> be set to 0.</dd>
            <dt>P: 1 bit</dt>
            <dd>When set to 1, the P bit indicates the last FU of the last VCL NAL unit of a coded picture, i.e., the last byte of the FU payload is also the last byte of the last VCL NAL unit of the coded picture.  When the FU payload is not the last fragment of the last VCL NAL unit of a coded picture, the P bit <bcp14>MUST</bcp14> be set to 0.</dd>
            <dt>FuType: 5 bits</dt>
            <dd>The field FuType <bcp14>MUST</bcp14> be equal to the field Type of the fragmented
NAL unit.</dd>
            </dl>
          <t>The DONL field, when present, specifies the value of the 16 least significant bits of the decoding order number of the fragmented NAL
unit.</t>
          <t>If sprop-max-don-diff is greater than 0,
and the S bit is equal to 1, the DONL field <bcp14>MUST</bcp14> be present in the
FU, and the variable DON for the fragmented NAL unit is derived as
equal to the value of the DONL field.  Otherwise (sprop-max-don-diff
is equal to 0, or the S bit is equal to 0),
the DONL field <bcp14>MUST NOT</bcp14> be present in the FU.</t>
          <t>A non-fragmented NAL unit <bcp14>MUST NOT</bcp14> be transmitted in one FU, i.e.,
the Start bit and End bit must not both be set to 1 in the same FU
header.</t>
          <t>The FU payload consists of fragments of the payload of the fragmented
NAL unit so that, if the FU payloads of consecutive FUs, starting with
an FU with the S bit equal to 1 and ending with an FU with the E bit
equal to 1, are sequentially concatenated, the payload of the
fragmented NAL unit can be reconstructed.  The NAL unit header of the
fragmented NAL unit is not included as such in the FU payload, but
rather the information of the NAL unit header of the fragmented NAL
unit is conveyed in the F, LayerId, and TID fields of the FU payload
headers of the FUs and the FuType field of the FU header of the FUs.
An FU payload <bcp14>MUST NOT</bcp14> be empty.</t>
          <t>If an FU is lost, the receiver <bcp14>SHOULD</bcp14> discard all following
fragmentation units in transmission order, corresponding to the same
fragmented NAL unit, unless the decoder in the receiver is known to
be prepared to gracefully handle incomplete NAL units.</t>
          <t>A receiver in an endpoint or in a MANE <bcp14>MAY</bcp14> aggregate the first n-1
fragments of a NAL unit to an (incomplete) NAL unit, even if fragment
n of that NAL unit is not received.  In this case, the
forbidden_zero_bit of the NAL unit <bcp14>MUST</bcp14> be set to 1 to indicate a
syntax violation.</t>
        </section>
      </section>
      <section anchor="DON">
        <name>Decoding Order Number</name>
        <t>For each NAL unit, the variable AbsDon is derived, representing the
decoding order number that is indicative of the NAL unit decoding
order.</t>
        <t>Let NAL unit n be the n-th NAL unit in transmission order within an
RTP stream.</t>
        <t>If sprop-max-don-diff is equal to 0, AbsDon[n], the value of AbsDon for NAL unit n, is derived as equal to n.</t>
        <t>Otherwise (sprop-max-don-diff is greater than 0), AbsDon[n] is derived as follows, where DON[n] is the value
of the variable DON for NAL unit n:</t>
        <ul spacing="normal">
          <li>If n is equal to 0 (i.e., NAL unit n is the very first NAL unit 
in transmission order), AbsDon[0] is set equal to DON[0].</li>
          <li>Otherwise (n is greater than 0), the following applies for
derivation of AbsDon[n]:</li>
        </ul>
        <artwork name="" type="" align="left" alt=""><![CDATA[
      If DON[n] == DON[n-1],
         AbsDon[n] = AbsDon[n-1]

      If (DON[n] > DON[n-1] and DON[n] - DON[n-1] < 32768),
         AbsDon[n] = AbsDon[n-1] + DON[n] - DON[n-1]

      If (DON[n] < DON[n-1] and DON[n-1] - DON[n] >= 32768),
         AbsDon[n] = AbsDon[n-1] + 65536 - DON[n-1] + DON[n]

      If (DON[n] > DON[n-1] and DON[n] - DON[n-1] >= 32768),
         AbsDon[n] = AbsDon[n-1] - (DON[n-1] + 65536 - DON[n])

      If (DON[n] < DON[n-1] and DON[n-1] - DON[n] < 32768),
         AbsDon[n] = AbsDon[n-1] - (DON[n-1] - DON[n])
]]></artwork>
        <t>For any two NAL units (m and n), the following applies:</t>
        <ul spacing="normal">
          <li>When AbsDon[n] is greater than AbsDon[m], this indicates that NAL unit n follows NAL unit m in NAL unit decoding order.</li>
          <li>When AbsDon[n] is equal to AbsDon[m], the NAL unit decoding order of the two NAL units can be in either order.</li>
          <li>When AbsDon[n] is less than AbsDon[m], this indicates that NAL unit n precedes NAL unit m in decoding order.</li>
        </ul>
        <aside><t>Informative note: When two consecutive NAL units in the NAL
  unit decoding order have different values of AbsDon, the 
  absolute difference between the two AbsDon values may be 
  greater than or equal to 1.</t></aside>
        <aside><t>Informative note: There are multiple reasons to allow for 
the absolute difference of the values of AbsDon for two 
consecutive NAL units in the NAL unit decoding order to 
be greater than one.  An increment by one is not required, as at the time of
associating values of AbsDon to NAL units, 
it may not be known whether all NAL units are to be 
delivered to the receiver. For example, a gateway might
not forward VCL NAL units of higher sublayers or some
SEI NAL units when there is congestion in the network. In another example, the first intra-coded picture of a pre-encoded clip is transmitted in advance to ensure that it is readily available in the receiver, and when transmitting the first intra-coded picture, the originator 
does not exactly know how many NAL units will be encoded
before the first intra-coded picture of the pre-encoded
clip follows in decoding order. Thus, the values of 
AbsDon for the NAL units of the first intra-coded picture
of the pre-encoded clip have to be estimated when 
they are transmitted, and gaps in values of AbsDon may occur.</t></aside>
      </section>
    </section>
    <section anchor="PacketizationRules">
      <name>Packetization Rules</name>
      <t>The following packetization rules apply:</t>
      <ul spacing="normal">
        <li>If sprop-max-don-diff is greater than 0, the transmission order of NAL units carried in the RTP
stream <bcp14>MAY</bcp14> be different than the NAL unit decoding order. Otherwise (sprop-max-don-diff is equal to 0), the transmission order of NAL units carried in the RTP stream <bcp14>MUST</bcp14> be the same as the NAL unit decoding order.</li>
        <li>A NAL unit of a small size <bcp14>SHOULD</bcp14> be encapsulated in an
aggregation packet together with one or more other NAL units in
order to avoid the unnecessary packetization overhead for small
NAL units.  For example, non-VCL NAL units, such as access unit
delimiters, parameter sets, or SEI NAL units, are typically small 
and can often be aggregated with VCL NAL units without violating 
MTU size constraints.</li>
        <li>Each non-VCL NAL unit <bcp14>SHOULD</bcp14>, when possible from an MTU size match
viewpoint, be encapsulated in an aggregation packet together with
its associated VCL NAL unit, as typically a non-VCL NAL unit would
be meaningless without the associated VCL NAL unit being
available.</li>
        <li>For carrying exactly one NAL unit in an RTP packet, a single NAL
unit packet <bcp14>MUST</bcp14> be used.</li>
      </ul>
    </section>
    <section anchor="DepacketizationProcess">
      <name>De-packetization Process</name>
      <t>The general concept behind de-packetization is to get the NAL units
out of the RTP packets in an RTP stream and pass them to the decoder in the NAL
unit decoding order.</t>
      <t>The de-packetization process is implementation dependent.  Therefore,
the following description should be seen as an example of a suitable
implementation.  Other schemes may be used as well, as long as the
output for the same input is the same as the process described below.
The output is the same when the set of output NAL units and their
order are both identical.  Optimizations relative to the described
algorithms are possible.</t>
      <t>All normal RTP mechanisms related to buffer management apply.  In
particular, duplicated or outdated RTP packets (as indicated by the
RTP sequence number and the RTP timestamp) are removed.  To
determine the exact time for decoding, factors, such as a possible
intentional delay to allow for proper inter-stream synchronization,
<bcp14>MUST</bcp14> be factored in.</t>
      <t>NAL units with NAL unit type values in the range of 0 to 27,
inclusive, may be passed to the decoder.  NAL-unit-like structures
with NAL unit type values in the range of 28 to 31, inclusive, <bcp14>MUST
NOT</bcp14> be passed to the decoder.</t>
      <t>The receiver includes a receiver buffer, which is used to compensate
for transmission delay jitter within individual RTP streams and to reorder NAL units from transmission order to the NAL unit decoding order.  In this section, the
receiver operation is described under the assumption that there is no
transmission delay jitter within an RTP stream. To make a difference from a practical receiver buffer that is also used for compensation of transmission delay jitter, the
receiver buffer is hereafter called the de-packetization buffer in
this section.  Receivers should also prepare for transmission delay
jitter, that is, either reserve separate buffers for transmission
delay jitter buffering and de-packetization buffering or use a
receiver buffer for both transmission delay jitter and de-
packetization. Moreover, receivers should take transmission delay
jitter into account in the buffering operation, e.g., by additional
initial buffering before starting of decoding and playback.</t>
      <t>The de-packetization process extracts the NAL units from the RTP packets in an RTP stream as follows.  When an RTP packet carries a single NAL unit packet, the payload of the RTP packet is extracted as a single NAL unit, excluding the DONL field, i.e., third and fourth bytes, when sprop-max-don-diff is greater than 0.  When an RTP packet carries an aggregation packet, several NAL units are extracted from the payload of the RTP packet.  In this case, each NAL unit corresponds to the part of the payload of each aggregation unit that follows the NALU size field, as described in <xref target="aps"/>.  When an RTP packet carries a Fragmentation Unit (FU), all RTP packets from the first FU (with the S field equal to 1) of the fragmented NAL unit up to the last FU (with the E field equal to 1) of the fragmented NAL unit are collected.  The NAL unit is extracted from these RTP packets by concatenating all FU payloads in the same order as the corresponding RTP packets and appending the NAL unit header with the fields F, LayerId, and TID set to equal the values of the fields F, LayerId, and TID in the payload header of the FUs, respectively, and with the NAL unit type set equal to the value of the field FuType in the FU header of the FUs, as described in <xref target="funits"/>.</t>
      <t>When sprop-max-don-diff is equal to 0, the de-packetization buffer size is zero bytes, and the NAL units carried in the single RTP stream are directly passed to the decoder in their transmission order, which is identical to their decoding order.</t>
<t>When sprop-max-don-diff is greater than 0, the process described in the remainder of this section
applies.</t>
      <t>There are two buffering states in the receiver: initial buffering and
buffering while playing.  Initial buffering starts when the reception
is initialized.  After initial buffering, decoding and playback are
started, and the buffering-while-playing mode is used.</t>
      <t>Regardless of the buffering state, the receiver stores incoming NAL units in reception order into the de-packetization buffer.  NAL units carried in RTP packets are stored in the de-packetization
buffer individually, and the value of AbsDon is calculated and stored for each NAL unit.</t>
      <t>Initial buffering lasts until the difference between the greatest and smallest AbsDon values of the NAL units in the de-packetization buffer is greater than or equal to the value of sprop-max-don-diff.</t>
      <t>After initial buffering, whenever the difference between the greatest and smallest AbsDon values of the NAL units in the de-packetization buffer is greater than or equal to the value of sprop-max-don-diff, the following operation is repeatedly applied until this difference is smaller than sprop-max-don-diff:</t>
      <t indent="3">The NAL unit in the de-packetization buffer with the smallest
value of AbsDon is removed from the de-packetization buffer and
passed to the decoder.</t>
      <t>When no more NAL units are flowing into the de-packetization buffer,
all NAL units remaining in the de-packetization buffer are removed
from the buffer and passed to the decoder in the order of increasing
AbsDon values.</t>
    </section>
    <section anchor="PayloadFormatParameters">
      <name>Payload Format Parameters</name>
      <t>This section specifies the optional parameters.
      A mapping of the parameters with Session Description Protocol (SDP) <xref target="RFC8866"/> is also provided for applications that use SDP.</t>
      <t>Parameters starting with the string "sprop" for stream properties can be used by a sender to provide a receiver with the properties of the stream that is or will be sent. The media sender (and not the receiver) selects whether, and with what values, "sprop" parameters are being sent. This uncommon characteristic of the "sprop" parameters may not be intuitive in the context of some signaling protocol concepts, especially with offer/answer.  Please see <xref target="sdpoa"/> for guidance specific to the use of sprop parameters in the offer/answer case.</t>
      <section anchor="oparams">
        <name>Media Type Registration</name>
        <t>The receiver <bcp14>MUST</bcp14> ignore any parameter unspecified in this memo.</t>
	<dl newline="false" spacing="normal">
          <dt>Type name:</dt>
	  <dd>video</dd>
          <dt>Subtype name:</dt>
	  <dd>H266</dd>
          <dt>Required parameters:</dt>
	  <dd>N/A</dd>
          <dt>Optional parameters:</dt>
          <dd>profile-id, tier-flag, sub-profile-id, interop-constraints, level-id, sprop-sublayer-id, sprop-ols-id, recv-sublayer-id, recv-ols-id, max-recv-level-id, sprop-dci, sprop-vps, sprop-sps, sprop-pps, sprop-sei, max-lsr, max-fps, sprop-max-don-diff, sprop-depack-buf-bytes, depack-buf-cap (refer to <xref target="optionalParameters"/> for definitions).</dd>
          <dt>Encoding considerations:</dt>
          <dd>This type is only defined for transfer via RTP <xref target="RFC3550"/>.</dd>
          <dt>Security considerations:</dt>
          <dd>See <xref target="Security"/> of RFC 9328.</dd>
          <dt>Interoperability considerations:</dt>
	  <dd>N/A</dd>
          <dt>Published specification:</dt>
          <dd>Please refer to RFC 9328 and VVC coding specification <xref target="VVC"/>.</dd>
          <dt>Applications that use this media type:</dt>
          <dd>Any application that relies on VVC-based video services over RTP</dd>
          <dt>Fragment identifier considerations:</dt>
	  <dd>N/A</dd>
          <dt>Additional information:</dt>
	  <dd>N/A</dd>
          <dt>Person &amp; email address to contact for further information:</dt>
          <dd><br/>Stephan Wenger (stewe@stewe.org)</dd>
          <dt>Intended usage:</dt>
	  <dd>COMMON</dd>
          <dt>Restrictions on usage:</dt>
	  <dd>N/A</dd>
          <dt>Author:</dt>
	  <dd>See Authors' Addresses section of RFC 9328.</dd>
          <dt>Change controller:</dt>
          <dd>IETF &lt;avtcore@ietf.org&gt;</dd>
        </dl>
      </section>
      <section anchor="optionalParameters">
        <name>Optional Parameters Definition</name>
	<dl newline="true" spacing="normal">
          <dt>profile-id, tier-flag, sub-profile-id, interop-constraints, and level-id:</dt>
          <dd><t>These parameters indicate the profile, the tier, the default level, the sub-profile, and some constraints of the bitstream carried by the RTP stream, or a specific set of the profile, the tier, the default level, the sub-profile, and some constraints the receiver supports.</t>
            <t>The subset of coding tools that may have been used to generate the bitstream or that the receiver supports, as well as some additional constraints, are indicated collectively by profile-id, sub-profile-id, and interop-constraints.</t>
            <aside><t>Informative note: There are 128 values of profile-id.  The subset of coding tools identified by profile-id can be further constrained with up to 255 instances of sub-profile-id.  In addition, 68 bits included in interop-constraints, which can be extended up to 324 bits, provide means to further restrict tools from existing profiles.  To be able to support this fine-granular signaling of coding-tool subsets with profile-id, sub-profile-id, and interop-constraints, it would be safe to require symmetric use of these parameters in SDP offer/answer unless recv-ols-id is included in the SDP answer for choosing one of the layers offered.</t></aside>
            <t>The tier is indicated by tier-flag.  The default level is indicated by level-id.  The tier and the default level specify the limits on values of syntax elements or arithmetic combinations of values of syntax elements that are followed when generating the bitstream or that the receiver supports.</t>
            <t>In SDP offer/answer, when the SDP answer does not include the recv-ols-id parameter that is less than the sprop-ols-id parameter in the SDP offer, the following applies:</t>
            <ul spacing="normal">
              <li>The tier-flag, profile-id, sub-profile-id, and interop-constraints parameters <bcp14>MUST</bcp14> be used symmetrically, i.e., the value of each of these parameters in the offer <bcp14>MUST</bcp14> be the same as that in the answer, either explicitly signaled or implicitly inferred.</li>

              <li>The level-id parameter is changeable as long as the highest level indicated by the answer is either equal to or lower than that in the offer.  Note that the highest level higher than level-id in the offer for receiving can be included as max-recv-level-id.</li>
            </ul>
            <t>In SDP offer/answer, when the SDP answer does include the recv-ols-id parameter that is less than the sprop-ols-id parameter in the SDP offer, the set of tier-flag, profile-id, sub-profile-id, interop-constraints, and level-id parameters included in the answer <bcp14>MUST</bcp14> be consistent with that for the chosen output layer set as indicated in the SDP offer, with the exception that the level-id parameter in the SDP answer is changeable as long as the highest level indicated by the answer is either lower than or equal to that in the offer.</t>
            <t>More specifications of these parameters, including how they relate to syntax elements specified in <xref target="VVC"/>, are provided below.</t>
          </dd>
        <dt>profile-id:</dt>
        <dd>
            <t>When profile-id is not present, a value of 1 (i.e., the Main 10 profile) <bcp14>MUST</bcp14> be inferred.</t>
            <t>When used to indicate properties of a bitstream, profile-id is derived from the general_profile_idc syntax element that applies to the bitstream in an instance of the profile_tier_level( ) syntax structure.</t>
            <t>VVC bitstreams transported over RTP using the technologies of this memo <bcp14>SHOULD</bcp14> contain only a single profile_tier_level( ) structure in the DCI, unless the sender can assure that a receiver can correctly decode the VVC bitstream, regardless of which profile_tier_level( ) structure contained in the DCI was used for deriving profile-id and other parameters for the SDP offer/answer exchange.</t>
            <t>As specified in <xref target="VVC"/>, a profile_tier_level( ) syntax structure may be contained in an SPS NAL unit, and one or more profile_tier_level( ) syntax structures may be contained in a VPS NAL unit and in a DCI NAL unit.  One of the following three cases applies to the container NAL unit of the profile_tier_level( ) syntax structure containing syntax elements used to derive the values of profile-id, tier-flag, level-id, sub-profile-id, or interop-constraints:</t>
	    <ol type="1">
	      <li>The container NAL unit is an SPS, the bitstream is a single-layer bitstream, and the profile_tier_level( ) syntax structures in all SPSs referenced by the CVSs in the bitstream have the same values respectively for those profile_tier_level( ) syntax elements.</li>
	      <li>The container NAL unit is a VPS, the profile_tier_level( ) syntax structure is the one in the VPS that applies to the OLS corresponding to the bitstream, and the profile_tier_level( ) syntax structures applicable to the OLS corresponding to the bitstream in all VPSs referenced by the CVSs in the bitstream have the same values respectively for those profile_tier_level( ) syntax elements.</li>
	      <li>The container NAL unit is a DCI NAL unit, and the profile_tier_level( ) syntax structures in all DCI NAL units in the bitstream have the same values respectively for those profile_tier_level( ) syntax elements.</li>
	    </ol>
            <t><xref target="VVC"/> allows for multiple profile_tier_level( ) structures in a DCI NAL unit, which may contain different values for the syntax elements used to derive the values of profile-id, tier-flag, level-id, sub-profile-id, or interop-constraints in the different entries.  However, herein defined is only a single profile-id, tier-flag, level-id, sub-profile-id, or interop-constraints.  When signaling these parameters and a DCI NAL unit is present with multiple profile_tier_level( ) structures, these values <bcp14>SHOULD</bcp14> be the same as the first profile_tier_level structure in the DCI, unless the sender has ensured that
the receiver can decode the bitstream when a different value is chosen.</t>
          </dd>
        <dt>tier-flag, level-id:</dt>
        <dd>
            <t>The value of tier-flag <bcp14>MUST</bcp14> be in the range of 0 to 1, inclusive.  The value of level-id <bcp14>MUST</bcp14> be in the range of 0 to 255, inclusive.</t>
            <t>If the tier-flag and level-id parameters are used to indicate properties of a bitstream, they indicate the tier and the highest level the bitstream complies with.</t>
            <t>If the tier-flag and level-id parameters are used for capability exchange, the following applies.  If max-recv-level-id is not present, the default level defined by level-id indicates the highest level the codec wishes to support. Otherwise, max-recv-level-id indicates the highest level the codec supports for receiving.  For either receiving or sending, all levels that are lower than the highest level supported <bcp14>MUST</bcp14> also be supported.</t>
            <t>If no tier-flag is present, a value of 0 <bcp14>MUST</bcp14> be inferred; if no level-id is present, a value of 51 (i.e., level 3.1) <bcp14>MUST</bcp14> be inferred.</t>
            <aside><t>Informative note:  The level values currently defined in the VVC specification are in the form of "majorNum.minorNum", and the value of the level-id for each of the levels is equal to majorNum * 16 + minorNum * 3.  It is expected that, if any levels are defined in the future, the same convention will be used, but this cannot be guaranteed.</t></aside>
            <t>When used to indicate properties of a bitstream, the tier-flag and level-id parameters are derived respectively from the syntax element general_tier_flag, and the syntax element general_level_idc or sub_layer_level_idc[j], that apply to the bitstream in an instance of the profile_tier_level( ) syntax structure.</t>
            <t>If the tier-flag and level-id are derived from the profile_tier_level( ) syntax structure in a DCI NAL unit, the following applies:</t>
            <ul spacing="normal">
              <li>tier-flag = general_tier_flag</li>
              <li>level-id = general_level_idc</li>
            </ul>
            <t>Otherwise, if the tier-flag and level-id are derived from the profile_tier_level( ) syntax structure in an SPS or VPS NAL unit, and the bitstream contains the highest sublayer representation in the OLS corresponding to the bitstream, the following applies:</t>
            <ul spacing="normal">
              <li>tier-flag = general_tier_flag</li>
              <li>level-id = general_level_idc</li>
            </ul>
            <t>Otherwise, if the tier-flag and level-id are derived from the profile_tier_level( ) syntax structure in an SPS or VPS NAL unit, and the bitstream does not contain the highest sublayer representation in the OLS corresponding to the bitstream, the following applies, with j being the value of the sprop-sublayer-id parameter:</t>
            <ul spacing="normal">
              <li>tier-flag = general_tier_flag</li>
              <li>level-id = sub_layer_level_idc[j]</li>
            </ul>
          </dd>
        <dt>sub-profile-id:</dt>
        <dd><t>The value of the parameter is a comma-separated (',') list of data using base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representation without "==" padding.</t>
        <t>When used to indicate properties of a bitstream, sub-profile-id is derived from each of the ptl_num_sub_profiles general_sub_profile_idc[i] syntax elements that apply to the bitstream in a profile_tier_level( ) syntax structure.</t></dd>
        <dt>interop-constraints:</dt>
        <dd><t>A base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />)
	representation of the
 data that includes the ptl_frame_only_constraint_flag syntax element, 
 the ptl_multilayer_enabled_flag syntax element, and the 
 general_constraints_info( ) syntax structure that apply to the
 bitstream in an instance of the profile_tier_level( ) syntax
 structure.</t>
            <t>If the interop-constraints parameter is not present, the following <bcp14>MUST</bcp14> be inferred:</t>
            <ul spacing="normal">
              <li>ptl_frame_only_constraint_flag = 1</li>
              <li>ptl_multilayer_enabled_flag = 0</li>
              <li>gci_present_flag in the general_constraints_info( ) syntax structure = 0</li>
            </ul>
            <t>Using interop-constraints for capability exchange results in a requirement on any bitstream to be compliant with the interop-constraints.</t>
          </dd>
        <dt>sprop-sublayer-id:</dt>
        <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to indicate the highest allowed value of TID in the bitstream.  When not present, the value of sprop-sublayer-id is inferred to be equal to 6.</t>
            <t>The value of sprop-sublayer-id <bcp14>MUST</bcp14> be in the range of 0 to 6, inclusive.</t>
          </dd>
        <dt>sprop-ols-id:</dt>
        <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to indicate the OLS that the bitstream applies to.  When not present, the value of sprop-ols-id is inferred to be equal to TargetOlsIdx, as specified in Section 8.1.1 of <xref target="VVC"/>. If this optional parameter is present, sprop-vps <bcp14>MUST</bcp14> also be present or its content <bcp14>MUST</bcp14> be known a priori at the receiver.</t>
            <t>The value of sprop-ols-id <bcp14>MUST</bcp14> be in the range of 0 to 256, inclusive.</t>
            <aside><t>Informative note: VVC allows having up to 257 output layer sets indicated in the VPS, as the number of output layer sets minus 2 is indicated with a field of 8 bits.</t></aside>
              </dd>
              <dt>recv-sublayer-id:</dt>
              <dd><t>This parameter <bcp14>MAY</bcp14> be used to signal a receiver's choice of the offered or declared sublayer representations in sprop-vps and sprop-sps. The value of recv-sublayer-id indicates the TID of the highest sublayer that a receiver supports.  When not present, the value of recv-sublayer-id is inferred to be equal to the value of the sprop-sublayer-id parameter in the SDP offer.</t>
              <t>The value of recv-sublayer-id <bcp14>MUST</bcp14> be in the range of 0 to 6, inclusive.</t></dd>
              <dt>recv-ols-id:</dt>
              <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to signal a receiver's choice of the offered or declared output layer sets in sprop-vps.  The value of recv-ols-id indicates the OLS index of the bitstream that a receiver supports.  When not present, the value of recv-ols-id is inferred to be equal to the value of the sprop-ols-id parameter inferred from or indicated in the SDP offer.  When present, the value of recv-ols-id must be included only when sprop-ols-id was received and must refer to an output layer set in the VPS that includes no layers other than all or a subset of the layers of the OLS referred to by sprop-ols-id.  If this optional parameter is present, sprop-vps must have been received or its content must be known a priori at the receiver.</t>
            <t>The value of recv-ols-id <bcp14>MUST</bcp14> be in the range of 0 to 256, inclusive.</t>
          </dd>
          <dt>max-recv-level-id:</dt>
          <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to indicate the highest level a receiver supports.</t>
            <t>The value of max-recv-level-id <bcp14>MUST</bcp14> be in the range of 0 to 255, inclusive.</t>
            <t>When max-recv-level-id is not present, the value is inferred to be equal to level-id.</t>
            <t>max-recv-level-id <bcp14>MUST NOT</bcp14> be present when the highest level the receiver supports is not higher than the default level.</t>
          </dd>
          <dt>sprop-dci:</dt>
          <dd>This parameter <bcp14>MAY</bcp14> be used to convey a decoding capability information NAL unit of the bitstream for out-of-band transmission.  The parameter <bcp14>MAY</bcp14> also be used for capability exchange.
	  The value of the parameter is a base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representation of the decoding capability information NAL unit, as specified in Section 7.3.2.1 of <xref target="VVC"/>.</dd>
          <dt>sprop-vps:</dt>
          <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to convey any video parameter set to the NAL unit of the bitstream for out-of-band transmission of video parameter sets.  The parameter <bcp14>MAY</bcp14> also be used for capability exchange and to indicate substream characteristics (i.e., properties of output layer sets and sublayer representations, as defined in <xref target="VVC"/>). The value of the parameter is a comma-separated (',') list of base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representations of the video parameter set NAL units, as specified in Section 7.3.2.3 of <xref target="VVC"/>.</t>
            <t>The sprop-vps parameter <bcp14>MAY</bcp14> contain one or more than one video parameter set NAL units. However, all other video parameter sets contained in the sprop-vps parameter <bcp14>MUST</bcp14> be consistent with the first video parameter set in the sprop-vps parameter. A video parameter set vpsB is said to be consistent with another video parameter set vpsA if the number of OLSs in vpsA and vpsB are the same and any decoder that conforms to the profile, tier, level, and constraints indicated by the data starting from the syntax element general_profile_idc to the syntax structure general_constraints_info(), inclusive, in the  profile_tier_level( ) syntax structure corresponding to any OLS with index olsIdx in vpsA can decode any CVS(s) referencing vpsB when TargetOlsIdx is equal to olsIdx that conforms to the profile, tier, level, and constraints indicated by the data starting from the syntax element general_profile_idc to the syntax structure general_constraints_info(), inclusive, in the  profile_tier_level( ) syntax structure corresponding to the OLS with index TargetOlsIdx in vpsB.</t>
          </dd>
          <dt>sprop-sps:</dt>
          <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to convey sequence parameter set NAL units of the bitstream for out-of-band transmission of sequence parameter sets.  The value of the parameter is a comma-separated (',') list of base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representations of the sequence parameter set NAL units, as specified in Section 7.3.2.4 of <xref target="VVC"/>.</t>
            <t>A sequence parameter set spsB is said to be consistent with  another sequence parameter set spsA if any decoder that conforms to the profile, tier, level, and constraints indicated by the data starting from the syntax element general_profile_idc to the syntax structure general_constraints_info(), inclusive, in the profile_tier_level( ) syntax structure in spsA can decode any  CLVS(s) referencing spsB that conforms to the profile, tier, level, and constraints indicated by the data starting from the syntax element general_profile_idc to the syntax structure general_constraints_info(), inclusive, in the profile_tier_level( ) syntax structure in spsB.</t>
          </dd>
          <dt>sprop-pps:</dt>
          <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to convey picture parameter set NAL units of the bitstream for out-of-band transmission of picture parameter sets.  The value of the parameter is a comma-separated (',') list of base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representations of the picture parameter set NAL units, as specified in Section 7.3.2.5 of <xref target="VVC"/>.</t>
          </dd>
          <dt>sprop-sei:</dt>
          <dd>
            <t>This parameter <bcp14>MAY</bcp14> be used to convey one or more SEI messages that describe bitstream characteristics.  When present, a decoder can rely on the bitstream characteristics that are described in the SEI messages for the entire duration of the session, independently from the persistence scopes of the SEI messages, as specified in <xref target="VSEI"/>.</t>
            <t>The value of the parameter is a comma-separated (',') list of base64 encoding (<xref target="RFC4648" section="4" sectionFormat="of" />) representations of SEI NAL units, as specified in <xref target="VSEI"/>.</t>
            <aside><t>Informative note: Intentionally, no list of applicable or inapplicable SEI messages is specified here.  Conveying certain SEI messages in sprop-sei may be sensible in some application scenarios and meaningless in others.  However, a few examples are described below:</t>
            <t>In an environment where the bitstream was created from film-based source material, and no splicing is going to occur during the lifetime of the session, the film grain characteristics SEI message is likely meaningful, and sending it in sprop-sei, rather than in the bitstream at each entry point, may help with saving bits and allows one to configure the renderer only once, avoiding unwanted artifacts.</t>
	    <t>Examples for SEI messages that would be meaningless to be conveyed in sprop-sei include the decoded picture hash SEI message (it is close to impossible that all decoded pictures have the same hashtag) or the filler payload SEI message (as there is no point in just having more bits in SDP).</t>
	    </aside>
          </dd>
          <dt>max-lsr:</dt>
          <dd>
            <t>The max-lsr <bcp14>MAY</bcp14> be used to signal the capabilities of a receiver implementation and <bcp14>MUST NOT</bcp14> be used for any other purpose. The value of max-lsr is an integer indicating the maximum processing rate in units of luma samples per second.  The max-lsr parameter signals that the receiver is capable of decoding video at a higher rate than is required by the highest level.</t>
            <aside><t>Informative note: When the <bcp14>OPTIONAL</bcp14> media type parameters are
	    used to signal the properties of a bitstream, and max-lsr is
	    not present, the values of tier-flag, profile-id, sub-profile-id,
	    interop-constraints, and level-id must always be such that
	    the bitstream complies fully with the specified profile,
	    sub-profile, tier, level, and interop-constraints.</t></aside>
            <t>When max-lsr is signaled, the receiver <bcp14>MUST</bcp14> be able to decode bitstreams that conform to the highest level, with the exception that the MaxLumaSr value in Table A.3 of <xref target="VVC"/> for the highest level is replaced with the value of max-lsr.  Senders <bcp14>MAY</bcp14> use this knowledge to send pictures of a given size at a higher picture rate than is indicated in the highest level.</t>
            <t>When not present, the value of max-lsr is inferred to be equal to the value of MaxLumaSr given in Table A.3 of <xref target="VVC"/> for the highest level.</t>
            <t>The value of max-lsr <bcp14>MUST</bcp14> be in the range of MaxLumaSr to 16 * MaxLumaSr, inclusive, where MaxLumaSr is given in Table A.3 of <xref target="VVC"/> for the highest level.</t>
          </dd>
          <dt>max-fps:</dt>
          <dd>
            <t>The value of max-fps is an integer indicating the maximum picture rate in units of pictures per 100 seconds that can be effectively processed by the receiver.  The max-fps parameter <bcp14>MAY</bcp14> be used to signal that the receiver has a constraint in that it is not capable of processing video effectively at the full picture rate that is implied by the highest level and, when present, max-lsr.</t>
            <t>The value of max-fps is not necessarily the picture rate at which the maximum picture size can be sent; it constitutes a constraint on maximum picture rate for all resolutions.</t>
            <aside><t>Informative note: The max-fps parameter is semantically different from max-lsr in that max-fps is used to signal a constraint, lowering the maximum picture rate from what is implied by other parameters.</t></aside>
            <t>The encoder <bcp14>MUST</bcp14> use a picture rate equal to or less than this value.  In cases where the max-fps parameter is absent, the encoder is free to choose any picture rate according to the highest level and any signaled optional parameters.</t>
            <t>The value of max-fps <bcp14>MUST</bcp14> be smaller than or equal to the full picture rate that is implied by the highest level and, when present, max-lsr.</t>
          </dd>
          <dt>sprop-max-don-diff:</dt>
          <dd>
            <t>If there is no NAL unit naluA that is followed in transmission order by any NAL unit preceding naluA in decoding order (i.e., the transmission order of the NAL units is the same as the decoding order), the value of this parameter <bcp14>MUST</bcp14> be equal to 0.</t>
            <t>Otherwise, this parameter specifies the maximum absolute difference between the decoding order number (i.e., AbsDon) values of any two NAL units naluA and naluB, where naluA follows naluB in decoding order and precedes naluB in transmission order.</t>
            <t>The value of sprop-max-don-diff <bcp14>MUST</bcp14> be an integer in the range of 0 to 32767, inclusive.</t>
            <t>When not present, the value of sprop-max-don-diff is inferred to be equal to 0.</t>
          </dd>
          <dt>sprop-depack-buf-bytes:</dt>
          <dd>
            <t>This parameter signals the required size of the de-packetization buffer in units of bytes.  The value of the parameter <bcp14>MUST</bcp14> be greater than or equal to the maximum buffer occupancy (in units of bytes) of the de-packetization buffer, as specified in <xref target="DepacketizationProcess"/>.</t>
            <t>The value of sprop-depack-buf-bytes <bcp14>MUST</bcp14> be an integer in the range of 0 to 4294967295, inclusive.</t>
            <t>When sprop-max-don-diff is present and greater than 0, this parameter <bcp14>MUST</bcp14> be present and the value <bcp14>MUST</bcp14> be greater than 0.  When not present, the value of sprop-depack-buf-bytes is inferred to be equal to 0.</t>
            <aside><t>Informative note: The value of sprop-depack-buf-bytes indicates the required size of the de-packetization buffer only.  When network jitter can occur, an appropriately sized jitter buffer has to be available as well.</t></aside>
          </dd>
          <dt>depack-buf-cap:</dt>
          <dd>
            <t>This parameter signals the capabilities of a receiver implementation and indicates the amount of de-packetization buffer space in units of bytes that the receiver has available for reconstructing the NAL unit decoding order from NAL units carried in the RTP stream.  A receiver is able to handle any RTP stream for which the value of the sprop-depack-buf-bytes parameter is smaller than or equal to this parameter.</t>
            <t>When not present, the value of depack-buf-cap is inferred to be equal to 4294967295.  The value of depack-buf-cap <bcp14>MUST</bcp14> be an integer in the range of 1 to 4294967295, inclusive.</t>
            <aside><t>Informative note: depack-buf-cap indicates the maximum possible size of the de-packetization buffer of the receiver only, without allowing for network jitter.</t></aside>
              </dd>
            </dl>
      </section>
      <section anchor="sdp-parameters">
        <name>SDP Parameters</name>
        <t>The receiver <bcp14>MUST</bcp14> ignore any parameter unspecified in this memo.</t>
        <section anchor="mapping-of-payload-type-parameters-to-sdp">
          <name>Mapping of Payload Type Parameters to SDP</name>
          <t>The media type video/H266 string is mapped to fields in the Session 
Description Protocol (SDP) <xref target="RFC8866"/> as follows:</t>
          <ul spacing="normal">
            <li>The media name in the "m=" line of SDP <bcp14>MUST</bcp14> be video.</li>
            <li>The encoding name in the "a=rtpmap" line of SDP <bcp14>MUST</bcp14> be H266 (the media subtype).</li>
            <li>The clock rate in the "a=rtpmap" line <bcp14>MUST</bcp14> be 90000.</li>
            <li>The <bcp14>OPTIONAL</bcp14> parameters profile-id, tier-flag, sub-profile-id, interop-constraints, level-id, sprop-sublayer-id, sprop-ols-id, recv-sublayer-id, recv-ols-id, max-recv-level-id, max-lsr, max-fps, sprop-max-don-diff, sprop-depack-buf-bytes, and depack-buf-cap, when present, <bcp14>MUST</bcp14> be included in the "a=fmtp" line of SDP.  The fmtp line is expressed as a media type string, in the form of a semicolon-separated list of parameter=value pairs.</li>
            <li><t>The <bcp14>OPTIONAL</bcp14> parameters sprop-vps, sprop-sps, sprop-pps, sprop-sei, and sprop-dci, when present, <bcp14>MUST</bcp14> be included in the "a=fmtp" line of SDP or conveyed using the "fmtp" source attribute as specified in <xref target="RFC5576" section="6.3" sectionFormat="of" />. For a particular media format (i.e., RTP payload type), sprop-vps, sprop-sps, sprop-pps, sprop-sei, or sprop-dci <bcp14>MUST NOT</bcp14> be both included in the "a=fmtp" line of SDP and conveyed using the "fmtp" source attribute.  When included in the "a=fmtp" line of SDP, those parameters are expressed as a media type string, in the form of a semicolon-separated list of parameter=value pairs.  When conveyed in the "a=fmtp" line of SDP for a particular payload type, the parameters sprop-vps, sprop-sps, sprop-pps, sprop-sei, and sprop-dci <bcp14>MUST</bcp14> be applied to each SSRC with the payload type.  When conveyed using the "fmtp" source attribute, these parameters are only associated with the given source and payload type as parts of the "fmtp" source attribute.</t>
                </li>
              </ul>	    
              <aside><t>Informative note: Conveyance of sprop-vps, sprop-sps, and sprop-pps using the "fmtp" source attribute allows for out-of-band transport of parameter sets in topologies like Topo-Video-switch-MCU, as specified in <xref target="RFC7667"/>.</t></aside>
          <t>A general usage of media representation in SDP is as follows:</t>
          <artwork name="" type="" align="left" alt=""><![CDATA[
        m=video 49170 RTP/AVP 98
        a=rtpmap:98 H266/90000
        a=fmtp:98 profile-id=1;
          sprop-vps=<video parameter sets data>;
          sprop-sps=<sequence parameter set data>;
          sprop-pps=<picture parameter set data>;
]]></artwork>
          <t>A SIP offer/answer exchange wherein both parties are expected to both send and receive could look like the following.  Only the media codec-specific parts of the SDP are shown.  Some lines are wrapped due to text constraints.</t>
          <artwork name="" type="" align="left" alt=""><![CDATA[
  Offerer->Answerer:
        m=video 49170 RTP/AVP 98
        a=rtpmap:98 H266/90000
        a=fmtp:98 profile-id=1; level_id=83;
]]></artwork>
          <t>The above represents an offer for symmetric video communication using <xref target="VVC"/> and its payload specification at the main profile and level 5.1 (and as the levels are downgradable, all lower levels).  Informally speaking, this offer tells the receiver of the offer that the sender is willing to receive up to 4Kp60 resolution at the maximum bitrates specified in <xref target="VVC"/>.  At the same time, if this offer were accepted "as is", the offer can expect that the answerer would be able to receive and properly decode H.266 media up to and including level 5.1.</t>
          <artwork name="" type="" align="left" alt=""><![CDATA[
  Answerer->Offerer:
        m=video 49170 RTP/AVP 98
        a=rtpmap:98 H266/90000
        a=fmtp:98 profile-id=1; level_id=67
]]></artwork>
          <t>With this answer to the offer above, the system receiving the offer advises the offerer that it is incapable of handing H.266 at level 5.1 but is capable of decoding 1080p60.  As H.266 video codecs must support decoding at all levels below the maximum level they implement, the resulting user experience would likely be that both systems send video at 1080p60.  However, nothing prevents an encoder from further downgrading its sending to, for example, 720p30 if it were short of cycles or bandwidth or for other reasons.</t>
        </section>
        <section anchor="sdpoa">
          <name>Usage with SDP Offer/Answer Model</name>
          <t>This section describes the negotiation of unicast messages using the offer/answer model as described in <xref target="RFC3264"/> and its updates.  The section is split into subsections, covering a) media format configurations not involving non-temporal scalability; b) scalable media format configurations; c) the description of the use of those parameters not involving the media configuration itself but rather the parameters of the payload format design; and d) multicast.</t>
          <section anchor="non-scalable-media-format-configuration">
            <name>Non-scalable Media Format Configuration</name>
            <t>A non-scalable VVC media configuration is such a configuration where no non-temporal scalability mechanisms are allowed.  In <xref target="VVC"/> version 1, it is implied that general_profile_idc indicates one of the following profiles: Main 10, Main 10 Still Picture, Main 10 4:4:4, or Main 10 4:4:4 Still Picture, with general_profile_idc values of 1, 65, 33, and 97, respectively.  Note that non-scalable media configurations include temporal scalability inline with VVC's design philosophy and profile structure.</t>
            <t>The following limitations and rules pertaining to the media configuration apply:</t>
            <ul spacing="normal">
              <li><t>The parameters identifying a media format configuration for VVC are profile-id, tier-flag, sub-profile-id, level-id, and interop-constraints.  These media configuration parameters, except level-id, <bcp14>MUST</bcp14> be used symmetrically.</t>
                <t>The answerer <bcp14>MUST</bcp14> structure its answer according to one of the following three options:</t>
		<ol spacing="normal">
		  <li>maintain all configuration parameters with the values remaining the same as in the offer for the media format (payload type), with the exception that the value of level-id is changeable as long as the highest level indicated by the answer is not higher than that indicated by the offer;</li>
		  <li>include in the answer the recv-sublayer-id parameter, with a value less than the sprop-sublayer-id parameter in the offer, for the media format (payload type), and maintain all configuration parameters with the values remaining the same as in the offer for the media format (payload type), with the exception that the value of level-id is changeable as long as the highest level indicated by the answer is not higher than the level indicated by sprop-sps or sprop-vps in offer for the chosen sublayer representation; or</li>
		  <li>remove the media format (payload type) completely (when one or more of the parameter values are not supported).</li>
		</ol>
	      </li>
	    </ul>
            <aside><t>Informative note: The above requirement for symmetric use does not apply for level-id and does not apply for the other bitstream or RTP stream properties and capability parameters, as described in <xref target="payloadformatconfig"/> below.</t></aside>
	    <ul spacing="normal">
              <li>To simplify handling and matching of these configurations, the same RTP payload type number used in the offer <bcp14>SHOULD</bcp14> also be used in the answer, as specified in <xref target="RFC3264"/>.</li>
              <li><t>The same RTP payload type number used in the offer for the media subtype H266 <bcp14>MUST</bcp14> be used in the answer when the answer includes recv-sublayer-id.  When the answer does not include recv-sublayer-id, the answer <bcp14>MUST NOT</bcp14> contain a payload type number used in the offer for the media subtype H266 unless the configuration is exactly the same as in the offer or the configuration in the answer only differs from that in the offer with a different value of level-id.  The answer <bcp14>MAY</bcp14> contain the recv-sublayer-id parameter if a VVC bitstream contains multiple operation points (using temporal scalability and sublayers) and sprop-sps or sprop-vps is included in the offer where information of sublayers are present in the first sequence parameter set or video parameter set contained in sprop-sps or sprop-vps, respectively.  If sprop-sps or sprop-vps is provided in an offer, an answerer <bcp14>MAY</bcp14> select a particular operation point indicated in the first sequence parameter set or video parameter set contained in sprop-sps or sprop-vps, respectively.  When the answer includes a recv-sublayer-id that is less than a sprop-sublayer-id in the offer, the following applies:</t>
            <ol spacing="normal">
              <li>When the sprop-sps parameter is present, all sequence parameter sets contained in the sprop-sps parameter in the
SDP answer and all sequence parameter sets sent in-band for either the offerer-to-answerer direction or the answerer-to-offerer direction <bcp14>MUST</bcp14> be consistent with the first sequence parameter set in the sprop-sps parameter of the offer (see the semantics of sprop-sps in <xref target="oparams"/> of this document on one sequence parameter set being consistent with another sequence parameter set).</li>
              <li>When the sprop-vps parameter is present, all video parameter sets contained in the sprop-vps parameter in the
SDP answer and all video parameter sets sent in-band for either the offerer-to-answerer direction or the answerer-to-offerer direction <bcp14>MUST</bcp14> be consistent with the first video parameter set in the sprop-vps parameter of the offer (see the semantics of sprop-vps in <xref target="oparams"/> of this document on one video parameter set being consistent with another video parameter set).</li>
              <li>The bitstream sent in either direction <bcp14>MUST</bcp14> conform to the profile, tier, level, and constraints of the chosen sublayer representation, as indicated by the profile_tier_level( ) syntax structure in the first sequence parameter set in the sprop-sps parameter or by the first profile_tier_level( ) syntax structure in the first video parameter set in the sprop-vps parameter of the offer.</li>
            </ol>
              </li>
            </ul>	    
            <aside><t>Informative note: When an offerer receives an answer that does not include recv-sublayer-id, it has to compare payload types not declared in the offer based on the media type (i.e., video/H266) and the above media configuration parameters with any payload types it has already declared.  This will enable it
to determine whether the configuration in question is new or if it is equivalent to configuration already offered, since a different payload type number may be used in the answer.  The ability to perform operation point selection enables a receiver to utilize the temporal scalable nature of a VVC bitstream.</t></aside>
          </section>
          <section anchor="scalable-media-format-configuration">
            <name>Scalable Media Format Configuration</name>
            <t>A scalable VVC media configuration is such a configuration where non-temporal scalability mechanisms are allowed.  In <xref target="VVC"/> version 1, it is  implied that general_profile_idc indicates one of the following profiles: Multilayer Main 10 and Multilayer Main 10 4:4:4, with general_profile_idc values of 17 and 49, respectively.</t>
            <t>The following limitations and rules pertaining to the media configuration apply.  They are listed in an order that would be logical for an implementation to follow:</t>
            <ul spacing="normal">
              <li>The parameters identifying a media format configuration for scalable VVC are profile-id, tier-flag, sub-profile-id, level-id, interop-constraints, and sprop-vps.  These media configuration parameters, except level-id, <bcp14>MUST</bcp14> be used symmetrically, except as noted below.</li>
              <li>The answerer <bcp14>MAY</bcp14> include a level-id that <bcp14>MUST</bcp14> be lower than or equal to the level-id indicated in the offer (either expressed by level-id in the offer or implied by the default level, as specified in <xref target="oparams"/>).</li>
              <li>When sprop-ols-id is present in an offer, sprop-vps <bcp14>MUST</bcp14> also be present in the same offer and include at least one valid VPS so to allow the answerer to meaningfully interpret sprop-ols-id and select recv-ols-id (see below).</li>
              <li><t>The answerer <bcp14>MUST NOT</bcp14> include recv-ols-id unless the offer includes sprop-ols-id. When present, recv-ols-id <bcp14>MUST</bcp14> indicate a supported output layer set in the VPS that includes no layers other than all or a subset of the layers of the OLS referred to by sprop-ols-id.  If unable, the answerer <bcp14>MUST</bcp14> remove the media format.</t></li>
	    </ul>
              <aside><t>Informative note: If an offerer wants to offer more than one output layer set, it can do so by offering multiple VVC media with different payload types.</t></aside>
	      <ul spacing="normal">
              <li>The offerer <bcp14>MAY</bcp14> include sprop-sublayer-id, which indicates the highest allowed value of TID in the bitstream.  The answerer <bcp14>MAY</bcp14> include recv-sublayer-id, which can be used to reduce the number of sublayers from the value of sprop-sublayer-id.</li>
              <li>When the answerer includes recv-ols-id and configuration parameters profile-id, tier-flag, sub-profile-id, level-id, and interop-constraints, it <bcp14>MUST</bcp14> use the configuration parameter values as signaled in the sprop-vps for the operating point with the largest number of sublayers for the chosen output layer set, with the exception that the value of level-id is changeable as long as the highest level indicated by the answer is not higher than the level indicated by sprop-vps in offer for the operating point with the largest number of sublayers for the chosen output layer set.</li>
            </ul>
          </section>
          <section anchor="payloadformatconfig">
            <name>Payload Format Configuration</name>
            <t>The following limitations and rules pertain to the configuration of the payload format buffer management mostly and apply to both scalable and non-scalable VVC.</t>
            <ul spacing="normal">
              <li><t>The parameters sprop-max-don-diff and sprop-depack-buf-bytes describe the properties of an RTP stream that the offerer or the answerer is sending for the media format configuration.  This differs from the normal usage of the offer/answer parameters; normally, such parameters declare the properties of the bitstream or RTP stream that the offerer or the answerer is able to receive.  When dealing with VVC, the offerer assumes that the answerer will be able to receive media encoded using the configuration being offered.</t></li>
	    </ul>
            <aside><t>Informative note:  The above parameters apply for any RTP stream, when present, sent by a declaring entity with the same configuration.  In other words, the applicability of the above parameters to RTP streams depends on the source endpoint. Rather than being bound to the payload type, the values may have to be applied to another payload type when being sent, as they apply for the configuration.</t></aside>
	      <ul spacing="normal">
              <li>The capability parameter max-lsr <bcp14>MAY</bcp14> be used to declare further capabilities of the offerer or answerer for receiving. It <bcp14>MUST NOT</bcp14> be present when the direction attribute is sendonly.</li>
              <li>The capability parameter max-fps <bcp14>MAY</bcp14> be used to declare lower capabilities of the offerer or answerer for receiving.  It <bcp14>MUST NOT</bcp14> be present when the direction attribute is sendonly.</li>
              <li>When an offerer offers an interleaved stream, indicated by the presence of sprop-max-don-diff with a value larger than zero, the offerer <bcp14>MUST</bcp14> include the size of the de-packetization buffer sprop-depack-buf-bytes.</li>
              <li>To enable the offerer and answerer to inform each other about their capabilities for de-packetization buffering in receiving RTP streams, both parties are <bcp14>RECOMMENDED</bcp14> to include depack-buf-cap.</li>
              <li>The parameters sprop-dci, sprop-vps, sprop-sps, or sprop-pps, when present (included in the "a=fmtp" line of SDP or conveyed using the "fmtp" source attribute, as specified in <xref target="RFC5576" section="6.3" sectionFormat="of" />), are used for out-of-band transport of the parameter sets (DCI, VPS, SPS, or PPS, respectively).</li>
              <li>The answerer <bcp14>MAY</bcp14> use either out-of-band or in-band transport of parameter sets for the bitstream it is sending, regardless of whether out-of-band parameter sets transport has been used in the offerer-to-answerer direction.  Parameter sets included in an answer are independent of those parameter sets included in the offer, as they are used for decoding two different bitstreams; one from the answerer to the offerer and the other in the opposite direction.  In case some RTP packets are sent before the SDP offer/answer settles down, in-band parameter sets <bcp14>MUST</bcp14> be used for those RTP stream parts sent before the SDP offer/answer.</li>
              <li><t>The following rules apply to transport of parameter sets in the offerer-to-answerer direction.</t>
              <ul spacing="normal">
                <li>An offer <bcp14>MAY</bcp14> include sprop-dci, sprop-vps, sprop-sps, and/or sprop-pps. If none of these parameters are present in the offer, then only in-band transport of parameter sets is used.</li>
                <li>If the level to use in the offerer-to-answerer direction is equal to the default level in the offer, the answerer <bcp14>MUST</bcp14> be prepared to use the parameter sets included in sprop-vps, sprop-sps, and sprop-pps (either included in the "a=fmtp" line of SDP or conveyed using the "fmtp" source attribute) for decoding the incoming bitstream, e.g., by passing these parameter set NAL units to the video decoder before passing any NAL units carried in the RTP streams.  Otherwise, the answerer <bcp14>MUST</bcp14> ignore sprop-vps, sprop-sps, and sprop-pps (either included in the "a=fmtp" line of SDP or conveyed using the "fmtp" source attribute) and the offerer <bcp14>MUST</bcp14> transmit parameter sets in-band.</li>
                </ul>
              </li>
              <li><t>The following rules apply to transport of parameter sets in the answerer-to-offerer direction.</t>
                <ul spacing="normal">
                  <li>An answer <bcp14>MAY</bcp14> include sprop-dci, sprop-vps, sprop-sps, and/or sprop-pps. If none of these parameters are present in the answer, then only in-band transport of parameter sets is used.</li>
                  <li>The offerer <bcp14>MUST</bcp14> be prepared to use the parameter sets included in sprop-vps, sprop-sps, and sprop-pps (either included in the "a=fmtp" line of SDP or conveyed using the "fmtp" source attribute) for decoding the incoming bitstream, e.g., by passing these parameter set NAL units to the video decoder before passing any NAL units carried in the RTP streams.</li>
                </ul>
              </li>
              <li>When sprop-dci, sprop-vps, sprop-sps, and/or sprop-pps are conveyed using the "fmtp" source attribute, as specified in <xref target="RFC5576" section="6.3" sectionFormat="of" />, the receiver of the parameters <bcp14>MUST</bcp14> store the parameter sets
included in sprop-dci, sprop-vps, sprop-sps, and/or sprop-pps and associate them with the source given as part of the "fmtp" source attribute. Parameter sets associated with one source (given as part of the "fmtp" source attribute) <bcp14>MUST</bcp14> only be used to decode NAL units conveyed in RTP packets from the same source (given as part of the "fmtp" source attribute).  When this mechanism is in use, SSRC collision detection and resolution <bcp14>MUST</bcp14> be performed as specified in <xref target="RFC5576"/>.</li>
            </ul>
            <t><xref target="parameters"/> lists the interpretation of all the parameters that <bcp14>MAY</bcp14> be
used for the various combinations of offer, answer, and direction
attributes.</t>
        <figure anchor="parameters">
	  <name>Interpretation of Parameters for Various Combinations                                  
      of Offers, Answers, and Direction Attributes, with and without recv-ols-id.</name>
            <artwork name="" type="" align="left" alt=""><![CDATA[
                                    sendonly --+
            answer: recvonly, recv-ols-id --+  |
              recvonly w/o recv-ols-id --+  |  |
      answer: sendrecv, recv-ols-id --+  |  |  |
        sendrecv w/o recv-ols-id --+  |  |  |  |
                                   |  |  |  |  |
profile-id                         C  D  C  D  P
tier-flag                          C  D  C  D  P
level-id                           D  D  D  D  P
sub-profile-id                     C  D  C  D  P
interop-constraints                C  D  C  D  P
max-recv-level-id                  R  R  R  R  -
sprop-max-don-diff                 P  P  -  -  P
sprop-depack-buf-bytes             P  P  -  -  P
depack-buf-cap                     R  R  R  R  -
max-lsr                            R  R  R  R  -
max-fps                            R  R  R  R  -
sprop-dci                          P  P  -  -  P
sprop-sei                          P  P  -  -  P
sprop-vps                          P  P  -  -  P
sprop-sps                          P  P  -  -  P
sprop-pps                          P  P  -  -  P
sprop-sublayer-id                  P  P  -  -  P
recv-sublayer-id                   O  O  O  O  -
sprop-ols-id                       P  P  -  -  P
recv-ols-id                        X  O  X  O  -

Legend:

 C: configuration for sending and receiving bitstreams
 D: changeable configuration, same as C, except possible
    to answer with a different but consistent value (see the
    semantics of the six parameters related to profile, tier,
    and level on these parameters being consistent)
 P: properties of the bitstream to be sent
 R: receiver capabilities
 O: operation point selection
 X: MUST NOT be present
 -: not usable, when present MUST be ignored
]]></artwork>
	</figure>
            <t>Parameters used for declaring receiver capabilities are, in general,
downgradable, i.e., they express the upper limit for a sender's
possible behavior.  Thus, a sender <bcp14>MAY</bcp14> select to set its encoder
using only lower/lesser or equal values of these parameters.</t>
            <t>When the answer does not include a recv-ols-id that is less
than the sprop-ols-id in the offer, parameters declaring a
configuration point are not changeable, with the exception of the
level-id parameter for unicast usage, and these parameters express
values a receiver expects to be used and <bcp14>MUST</bcp14> be used verbatim in the
answer as in the offer.</t>
            <t>When a sender's capabilities are declared with the configuration
parameters, these parameters express a configuration that is
acceptable for the sender to receive bitstreams.  In order to achieve
high interoperability levels, it is often advisable to offer multiple
alternative configurations.  It is impossible to offer multiple
configurations in a single payload type.  Thus, when multiple
configuration offers are made, each offer requires its own RTP
payload type associated with the offer.  However, it is possible to
offer multiple operation points using one configuration in a single
payload type by including sprop-vps in the offer and recv-ols-id in the answer.</t>
            <t>An implementation <bcp14>SHOULD</bcp14> be able to understand all media type parameters
(including all optional media type parameters), even if it doesn't support 
the functionality related to the parameter.  This, in conjunction with proper 
application logic in the implementation, allows the implementation, 
after having received an offer, to create an answer by potentially downgrading 
one or more of the optional parameters to the point where the implementation 
can cope, leading to higher chances of interoperability beyond the most basic 
interop points (for which, as described above, no optional parameters are necessary).</t>
                <aside><t>Informative note: In implementations of previous H.26x payload formats, it was 
occasionally observed that implementations were incapable of parsing most (or all) 
of the optional parameters.  As a result, the offer/answer exchange resulted in a
baseline performance (using the default values for the optional parameters) with 
the resulting suboptimal user experience.  However, there are valid reasons to forego 
the implementation complexity of implementing the parsing of some or all of the optional 
parameters, for example, when there is predetermined knowledge, not negotiated by an 
SDP-based offer/answer process, of the capabilities of the involved systems 
(walled gardens, baseline requirements defined in application standards higher up in the stack, and similar).</t></aside>
            <t>An answerer <bcp14>MAY</bcp14> extend the offer with additional media format
configurations.  However, to enable their usage, in most cases, a
second offer is required from the offerer to provide the bitstream
property parameters that the media sender will use.  This also has
the effect that the offerer has to be able to receive this media
format configuration, not only to send it.</t>
          </section>
        </section>
        <section anchor="multicast">
          <name>Multicast</name>
          <t>For bitstreams being delivered over multicast, the following rules apply:</t>
          <ul spacing="normal">
            <li>The media format configuration is identified by profile-id, tier-flag, sub-profile-id, level-id, and interop-constraints.  These media format configuration parameters, including level-id, <bcp14>MUST</bcp14> be used symmetrically; that is, the answerer <bcp14>MUST</bcp14> either maintain all configuration parameters or remove the media format (payload type) completely.  Note that this implies that the level-id for offer/answer in multicast is not changeable.</li>
            <li>To simplify the handling and matching of these configurations, the same RTP payload type number used in the offer <bcp14>SHOULD</bcp14> also be used in the answer, as specified in <xref target="RFC3264"/>.  An answer <bcp14>MUST NOT</bcp14> contain a payload type number used in the offer unless the configuration is the same as in the offer.</li>
            <li>Parameter sets received <bcp14>MUST</bcp14> be associated with the originating source and <bcp14>MUST</bcp14> only be used in decoding the incoming bitstream from the same source.</li>
            <li>The rules for other parameters are the same as above for unicast as long as the three above rules are obeyed.</li>
          </ul>
        </section>
        <section anchor="usage-in-declarative-session-descriptions">
          <name>Usage in Declarative Session Descriptions</name>
          <t>When VVC over RTP is offered with SDP in a declarative style, as in Real Time Streaming Protocol (RTSP) <xref target="RFC7826"/> or Session Announcement Protocol (SAP) <xref target="RFC2974"/>, the following considerations are necessary.</t>
          <ul spacing="normal">
            <li><t>All parameters capable of indicating both bitstream properties and receiver capabilities are used to indicate only bitstream properties.  For example, in this case, the parameters profile-id, 
tier-id, and level-id declare the values used by the bitstream, not the capabilities for receiving bitstreams.  As a result, the following interpretation of the parameters <bcp14>MUST</bcp14> be used:</t>
              <ul spacing="normal">
                <li><t>Declaring actual configuration or bitstream properties:</t>
                  <ul spacing="normal">
                    <li>profile-id</li>
                    <li>tier-flag</li>
                    <li>level-id</li>
                    <li>interop-constraints</li>
                    <li>sub-profile-id</li>
                    <li>sprop-dci</li>
                    <li>sprop-vps</li>
                    <li>sprop-sps</li>
                    <li>sprop-pps</li>
                    <li>sprop-max-don-diff</li>
                    <li>sprop-depack-buf-bytes</li>
                    <li>sprop-sublayer-id</li>
                    <li>sprop-ols-id</li>
                    <li>sprop-sei</li>
                  </ul>
                </li>
                <li>
                  <t>Not usable (when present, they <bcp14>MUST</bcp14> be ignored):</t>
                  <ul spacing="normal">
                    <li>max-lsr</li>
                    <li>max-fps</li>
                    <li>max-recv-level-id</li>
                    <li>depack-buf-cap</li>
                    <li>recv-sublayer-id</li>
                    <li>recv-ols-id</li>
                  </ul>
                </li>
                <li>A receiver of the SDP is required to support all parameters and values of the parameters provided; otherwise, the receiver <bcp14>MUST</bcp14> reject (RTSP) or not participate in (SAP) the session.  It falls on the creator of the session to use values that are expected to be supported by the receiving application.</li>
              </ul>
            </li>
          </ul>
        </section>
        <section anchor="considerations-for-parameter-sets">
          <name>Considerations for Parameter Sets</name>
          <t>When out-of-band transport of parameter sets is used, parameter sets <bcp14>MAY</bcp14> still be additionally transported in-band unless explicitly disallowed by an application, and some of these additional parameter sets may update some of the out-of-band transported parameter sets. An update of a parameter set refers to the sending of a parameter set of the same type using the same parameter set ID but with different values for at least one other parameter of the parameter set.</t>
        </section>
      </section>
    </section>
    <section anchor="FeedbackMessage">
      <name>Use with Feedback Messages</name>
      <t>The following subsections define the use of the Picture Loss
Indication (PLI) and Full Intra Request (FIR) feedback
messages with <xref target="VVC"/>.  The PLI is defined in
<xref target="RFC4585"/>, and the FIR message is defined in <xref target="RFC5104"/>.
In accordance with this memo, unlike <xref target="HEVC"/>, a sender <bcp14>MUST NOT</bcp14> send Slice Loss Indication (SLI) or Reference Picture Selection Indication (RPSI), and a receiver <bcp14>SHOULD</bcp14> ignore RPSI and treat a received SLI as a PLI.</t>
      <section anchor="PLI">
        <name>Picture Loss Indication (PLI)</name>
        <t>As specified in <xref target="RFC4585" section="6.3.1" sectionFormat="of" />, the reception of a PLI by a
media sender indicates "the loss of an undefined amount of coded
video data belonging to one or more pictures".  Without having any
specific knowledge of the setup of the bitstream (such as use and
location of in-band parameter sets, non-IRAP decoder refresh points,
picture structures, and so forth), a reaction to the reception of a
PLI by a VVC sender <bcp14>SHOULD</bcp14> be to send an IRAP picture and relevant
parameter sets, potentially with sufficient redundancy so to ensure
correct reception.  However, sometimes information about the
bitstream structure is known.
For example, such information can be parameter sets that have been conveyed out of band through mechanisms not defined in this document and that are known to stay static for the duration of the session. In that case, it is obviously unnecessary
to send them in-band as a result of the reception of a PLI.  Other
examples could be devised based on a priori knowledge of different
aspects of the bitstream structure.  In all cases, the timing and
congestion control mechanisms of <xref target="RFC4585"/> <bcp14>MUST</bcp14> be observed.</t>
      </section>
      <section anchor="FIR">
        <name>Full Intra Request (FIR)</name>
        <t>The purpose of the FIR message is to force an encoder to send an 
independent decoder refresh point as soon as possible
while observing applicable congestion-control-related constraints, 
such as those set out in <xref target="RFC8082"/>.</t>
        <t>Upon reception of a FIR, a sender <bcp14>MUST</bcp14> send an IDR picture.
Parameter sets <bcp14>MUST</bcp14> also be sent, except when there is a priori
knowledge that the parameter sets have been correctly established.  A
typical example for that is an understanding between the sender and
receiver, established by means outside this document, that parameter
sets are exclusively sent out of band.</t>
      </section>
    </section>
    <section anchor="Security">
      <name>Security Considerations</name>
      <t>The scope of this section is limited to the
payload format itself and to one feature of <xref target="VVC"/> that may pose a
particularly serious security risk if implemented naively.  The
payload format, in isolation, does not form a complete system.
Implementers are advised to read and understand relevant security-related documents, especially those pertaining to RTP (see the
Security Considerations section in <xref target="RFC3550"/>) and the security of
the call-control stack chosen (that may make use of the media type
registration of this memo).  Implementers should also consider known
security vulnerabilities of video coding and decoding implementations
in general and avoid those.</t>
      <t>Within this RTP payload format, and with the exception of the user
data SEI message as described below, no security threats other than
those common to RTP payload formats are known.  In other words,
neither the various media-plane-based mechanisms nor the signaling
part of this memo seem to pose a security risk beyond those common
to all RTP-based systems.</t>
      <t>RTP packets using the payload format defined in this specification
are subject to the security considerations discussed in the RTP
specification <xref target="RFC3550"/> and in any applicable RTP profile, such as
RTP/AVP <xref target="RFC3551"/>, RTP/AVPF <xref target="RFC4585"/>, RTP/SAVP <xref target="RFC3711"/>, 
or RTP/SAVPF <xref target="RFC5124"/>.  However, as "Securing the RTP Framework: 
Why RTP Does Not Mandate a Single Media Security Solution" <xref target="RFC7202"/>
discusses, it is not an RTP payload format's responsibility to
discuss or mandate what solutions are used to meet the basic security
goals, like confidentiality, integrity, and source authenticity for RTP
in general.  This responsibility lays on anyone using RTP in an
application.  They can find guidance on available security mechanisms
and important considerations in "Options for Securing RTP Sessions"
<xref target="RFC7201"/>. The rest of this section discusses the security
impacting properties of the payload format itself.</t>
      <t>Because the data compression used with this payload format is applied
end to end, any encryption needs to be performed after compression.
A potential denial-of-service threat exists for data encodings using
compression techniques that have non-uniform receiver-end
computational load.  The attacker can inject pathological datagrams
into the bitstream that are complex to decode and that cause the
receiver to be overloaded.  <xref target="VVC"/> is particularly vulnerable to such
attacks, as it is extremely simple to generate datagrams containing
NAL units that affect the decoding process of many future NAL units.
Therefore, the usage of data origin authentication and data integrity 
protection of at least the RTP packet is <bcp14>RECOMMENDED</bcp14> but NOT <bcp14>REQUIRED</bcp14>
based on the thoughts of <xref target="RFC7202"/>.</t>
      <t>Like HEVC <xref target="RFC7798"/>, <xref target="VVC"/> includes a user data Supplemental
Enhancement Information (SEI) message.  This SEI message allows
inclusion of an arbitrary bitstring into the video bitstream.  Such a
bitstring could include JavaScript, machine code, and other active
content.  <xref target="VVC"/> leaves the handling of this SEI message to the
receiving system.  In order to avoid harmful side effects of
the user data SEI message, decoder implementations cannot naively
trust its content.  For example, it would be a bad and insecure
implementation practice to forward any JavaScript a decoder
implementation detects to a web browser.  The safest way to deal with
user data SEI messages is to simply discard them, but that can have
negative side effects on the quality of experience by the user.</t>
      <t>End-to-end security with authentication, integrity, or
confidentiality protection will prevent a MANE from performing media-
aware operations other than discarding complete packets.  In the case
of confidentiality protection, it will even be prevented from
discarding packets in a media-aware way.  To be allowed to perform
such operations, a MANE is required to be a trusted entity that is
included in the security context establishment. This on-path inclusion of the MANE forgoes end-to-end security guarantees for the end points.</t>
    </section>
    <section anchor="CC">
      <name>Congestion Control</name>
      <t>Congestion control for RTP <bcp14>SHALL</bcp14> be used in accordance with RTP
<xref target="RFC3550"/> and with any applicable RTP profile, e.g., AVP <xref target="RFC3551"/> or AVPF <xref target="RFC4585"/>.
If best-effort service is being used, an additional requirement is
that users of this payload format <bcp14>MUST</bcp14> monitor packet loss to ensure
that the packet loss rate is within an acceptable range.  Packet loss
is considered acceptable if a TCP flow across the same network path
and experiencing the same network conditions would achieve an
average throughput, measured on a reasonable timescale, that is not
less than all RTP streams combined are achieved.  This condition can
be satisfied by implementing congestion-control mechanisms to adapt
the transmission rate, by implementing the number of layers subscribed for a layered
multicast session, or by arranging for a receiver to leave the
session if the loss rate is unacceptably high.</t>
      <t>The bitrate adaptation necessary for obeying the congestion control
principle is easily achievable when real-time encoding is used, for
example, by adequately tuning the quantization parameter.
However, when pre-encoded content is being transmitted, bandwidth
adaptation requires the pre-coded bitstream to be tailored for such
adaptivity.  The key mechanisms available in <xref target="VVC"/> are temporal
scalability and spatial/SNR scalability.  A media sender can remove
NAL units belonging to higher temporal sublayers (i.e., those NAL
units with a high value of TID) or higher spatio-SNR layers until the sending bitrate drops to
an acceptable range.</t>
      <t>The mechanisms mentioned above generally work within a defined profile and level;
therefore no renegotiation of the channel is required.  Only
when non-downgradable parameters (such as profile) are required to be
changed does it become necessary to terminate and restart the RTP
stream(s).  This may be accomplished by using different RTP payload
types.</t>
      <t>MANEs <bcp14>MAY</bcp14> remove certain unusable packets from the RTP stream when
that RTP stream was damaged due to previous packet losses.  This can
help reduce the network load in certain special cases.  For example,
MANEs can remove those FUs where the leading FUs belonging to the
same NAL unit have been lost or those dependent slice segments when
the leading slice segments belonging to the same slice have been
lost, because the trailing FUs or dependent slice segments are
meaningless to most decoders.  MANE can also remove higher temporal
scalable layers if the outbound transmission (from the MANE's
viewpoint) experiences congestion.</t>
    </section>
    <section anchor="iana-considerations">
      <name>IANA Considerations</name>
      <t>A new media type has been registered with IANA; see <xref target="oparams"/>. </t>
    </section>
  </middle>
  <back>
    <references>
      
      <name>References</name>
      <references>
        <name>Normative References</name>
        <reference anchor="VVC" target="http://www.itu.int/rec/T-REC-H.266">
          <front>
            <title>Versatile Video Coding</title>
            <author>
              <organization>ITU-T</organization>
            </author>
            <date month="April" year="2022"/>
          </front>
	  <seriesInfo name="ITU-T Recommendation" value="H.266"/>
        </reference>

        <reference anchor="ISO23090-3" target="https://www.iso.org/standard/73022.html">
          <front>
            <title>Information technology - Coded representation of immersive media - Part 3: Versatile video coding</title>
            <author>
              <organization>International Organization for Standardization</organization>
            </author>
            <date month="September" year="2022"/>
          </front>
	  <seriesInfo name="ISO/IEC" value="23090-3:2022"/>
        </reference>

        <reference anchor="VSEI" target="https://www.itu.int/rec/T-REC-H.274">
          <front>
            <title>Versatile supplemental enhancement information messages for coded video bitstreams</title>
            <author>
              <organization>ITU-T</organization>
            </author>
            <date month="May" year="2022"/>
          </front>
	  <seriesInfo name="ITU-T Recommendation" value="H.274"/>
        </reference>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2119.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.3550.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.3551.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.3711.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8866.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.4585.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.5104.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.5124.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8174.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.8082.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.3264.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.4648.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.5576.xml"/>
      </references>
      <references>
        <name>Informative References</name>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7656.xml"/>

        <reference anchor="CABAC">
          <front>
            <title>Transform coefficient coding in HEVC</title>
            <author>
              <organization>Sole, J., et al.</organization>
            </author>
            <date year="2012" month="December"/>
          </front>
	  <refcontent>IEEE Transactions on Circuits and Systems for Video Technology</refcontent>
          <seriesInfo name="DOI" value="10.1109/TCSVT.2012.2223055"/>
        </reference>

        <reference anchor="MPEG2S">
          <front>
            <title>Information technology - Generic coding of moving pictures and associated audio information - Part 1: Systems</title>
            <author>
              <organization>International Organization for Standardization</organization>
            </author>
            <date month="September" year="2022"/>
          </front>
	  <seriesInfo name="ISO/IEC" value="13818-1:2022"/>
        </reference>

        <reference anchor="HEVC" target="https://www.itu.int/rec/T-REC-H.265">
          <front>
            <title>High efficiency video coding</title>
            <author>
              <organization>ITU-T</organization>
            </author>
            <date month="August" year="2021"/>
          </front>
	  <seriesInfo name="ITU-T Recommendation" value="H.265"/>
        </reference>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6184.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.6190.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7201.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7202.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7798.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.2974.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7826.xml"/>
        <xi:include href="https://bib.ietf.org/public/rfc/bibxml/reference.RFC.7667.xml"/>
      </references>
    </references>
    <section anchor="acknowledgements" numbered="false">
      <name>Acknowledgements</name>
      <t><contact fullname="Dr. Byeongdoo Choi"/> is thanked for the video-codec-related technical 
discussion and other aspects in this memo. <contact fullname="Xin Zhao"/> and <contact fullname="Dr. Xiang Li"/>
are thanked for their contributions on <xref target="VVC"/> specification descriptive content. 
<contact fullname="Spencer Dawkins"/> is thanked for his valuable review comments that led to great 
improvements of this memo. Some parts of this specification share text with the RTP payload
format for HEVC <xref target="RFC7798"/>.  We thank the authors of that
specification for their excellent work.</t>
    </section>
  </back>
</rfc>
